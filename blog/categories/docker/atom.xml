<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Marcelo Cavalcante Rocha ~]]></title>
  <link href="https://kalib.github.io/blog/categories/docker/atom.xml" rel="self"/>
  <link href="https://kalib.github.io/"/>
  <updated>2018-11-03T19:22:05-04:00</updated>
  <id>https://kalib.github.io/</id>
  <author>
    <name><![CDATA[Marcelo Cavalcante Rocha - Kalib]]></name>
    
  </author>
  <generator uri="https://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Introdução ao Terraform]]></title>
    <link href="https://kalib.github.io/blog/2018/10/29/introducao-ao-terraform/"/>
    <updated>2018-10-29T21:35:00-04:00</updated>
    <id>https://kalib.github.io/blog/2018/10/29/introducao-ao-terraform</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/terraform-integrations.png" title="&lsquo;Terraform&rsquo;" ></p>

<h2>Terraform &ndash; Uma robusta opção para Infraestrutura como Código</h2>

<p><strong>A</strong> Hashicorp é uma empresa de bastante destaque no meio DevOps por ter criado várias soluções de automação, que englobam uma série de funcionalidades, como o <a href="https://packer.io">Packer</a> para criação de imagens de forma automatizada, conforme apresentado nestes dois posts  do blog (<a href="https://blog.marcelocavalcante.net/blog/2018/07/30/automatizando-a-criacao-de-imagens-com-packer/">1</a>, <a href="https://blog.marcelocavalcante.net/blog/2018/08/11/criando-uma-imagem-aws-ec2-com-packer-e-puppet/">2</a>), <a href="https://vagrant.io">Vagrant</a>, para provisionamento simples e rápido de máquinas, <a href="https://vaultproject.io">Vault</a>, para gerenciamento de senhas/segredos (<em>secrets</em>), <a href="https://consul.io">Consul</a>, para descoberta de serviços, <a href="nomadproject.io">Nomad</a>, para agendamento e automação de deployments, e o <a href="https://terraform.io">Terraform</a>, foco principal deste post, uma robusta ferramenta para criação de infraestrutura como código, ou <em>infrastructure as cdode</em>.</p>

<p><strong>C</strong>aso você não possua uma ideia muito clara de qual a idea por trás do conceito de infraestrutura como código, ou mesmo quais as vantagens de se utilizar esta metodologia de gerenciamento/criação de infraestrutura, sugiro que leia meu <a href="https://blog.marcelocavalcante.net/blog/2018/10/22/infraestrutura-como-codigo-com-terraform/">post anterior</a>, no qual explico alguns dos principais benefícios desta prática, bem como uma breve apresentação do Terraform.</p>

<p><strong>D</strong>e forma resumida, o Terraform é uma ferramenta disponível em formatos Open Source ou Enterprise, cujo intuito é permitir a criação de infraestrutura como código, possibilitando o controle de versões. Suporta diversos provedores tais como AWS, OpenStack, Azure, GCP, etc.</p>

<p><strong>U</strong>ma de suas principais características é a idempotência, termo muito utilizado na matemática ou em ciência da computação para indicar a propriedade que algumas operações têm de poderem ser aplicadas várias vezes sem que o valor do resultado se altere após a aplicação inicial. Ou seja, uma vez aplicado o seu código terraform, você poderá aplicá-lo quantas vezes desejar e nenhuma alteração será feita em sua infraestrutura, a menos que você tenha de fato alterado algo em seu código.</p>

<p><strong>O</strong> Terraform utiliza uma linguagem de alto nível e fácil de se reutilizar, uma vez que podemos criar módulos e utilizar estes módulos em diversos projetos distintos, mesmo que tenhamos módulos em repositórios também distintos.</p>

<p><strong>A</strong> ideia de possuir um &ldquo;plano&rdquo; de execução nos ajuda a identificar falhas em nosso código mais rapidamente, bem como prevenir problemas em nossa infraestrutura, visto que podemos ter uma visão geral de tudo o que será aplicado em nossa infra antes mesmo da execução real de nosso código, nos permitindo ter a certeza de que todas as alterações serão de fato intencionais.</p>

<p><strong>S</strong>empre digo que a melhor forma de se aprender uma nova tecnologia é colocando a mão na massa, portanto vamos escrever algumas linhas de código para entendermos as funcionalidades básicas bem como a sintaxe de código utilizada pelo Terraform.</p>

<p><strong>A</strong>ntes de pensarmos em cenários mais complexos devemos entender o básico, no entanto eu sempre gostei de ver algum resultado como forma de ter uma motivação real para meus estudos. Nunca gostei de apenas ler e escrever códigos que não resultam em nada, e acredito que todos devam sentir a mesma insatisfação ao não ter um uso real e prático para o que quer que esteja estudando.</p>

<p><strong>S</strong>eguindo esta ideia, antes de pensarmos em cenários mais complexos, vamos iniciar pelo básico, porém com algum resultado prático. A ideia para este post é termos um jogo clássico do Mario rodando em um container Docker que seja acessível através de nosso browser.</p>

<h2>Instalação</h2>

<p><strong>P</strong>ara este post precisaremos ter três aplicativos instalados:</p>

<ol>
<li>Um navegador ou browser qualquer; (Imagino que você já tenha algum&hellip;)</li>
<li>Docker;</li>
<li>Terraform</li>
</ol>


<h3>Docker</h3>

<p><strong>O</strong> processo de instalação do Docker varia de acordo com o seu sistema operacional. Caso queira maiores detalhes sobre sua instalação, bem como uma explicação introdutória de como ele funciona, você pode visitar <a href="https://blog.marcelocavalcante.net/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">este outro post</a>, embora você não precise ter nenhum conhecimento sobre Docker para seguir as instruções deste tutorial, visto que utilizaremos o Terraform para criar nosso container.</p>

<p><strong>N</strong>o <em>Archlinux</em> a instalação pode ser feita através do pacman:</p>

<p>```</p>

<h1>pacman install docker</h1>

<p>```</p>

<p><strong>N</strong>o <em>Windows</em> a instalação pode ser feita através do binário disponível no site oficial: (<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows">https://store.docker.com/editions/community/docker-ce-desktop-windows</a>)</p>

<p><strong>N</strong>o <em>OS X</em>, você também pode baixar o binário diretamente no site oficial, (<a href="https://store.docker.com/editions/community/docker-ce-desktop-mac">https://store.docker.com/editions/community/docker-ce-desktop-mac</a>) ou através do brew:</p>

<p><code>
brew install docker
</code></p>

<h3>Terraform</h3>

<p><strong>A</strong> instalação do Terraform é tão simples quanto a do Docker.</p>

<p><strong>N</strong>o <em>Archlinux</em> a instalação pode ser feita através do pacman:</p>

<p>```</p>

<h1>pacman -S terraform</h1>

<p>```</p>

<p><strong>N</strong>o <em>Windows</em> e no <em>OS X</em> a instalação pode ser feita através do binário disponível no site oficial do Terraform: (<a href="https://www.terraform.io/downloads.html">https://www.terraform.io/downloads.html</a>)</p>

<p><strong>O</strong>utra opção para OS X é através do brew:</p>

<p><code>
brew install terraform
</code></p>

<h2>Verificando a instalação</h2>

<p><strong>U</strong>ma vez que você tenha instalado ambos, certifique-se de que a instalação foi bem sucedida e de que o serviço Docker esteja rodando em seu sistema. Para isto, abra algum terminal, console ou prompt do CMD (para usuários Windows) e digite o seguinte:</p>

<p>1- Para termos certeza de que o Terraform está instalado e funcionando:
<code>
terraform -version
</code></p>

<p>Você deverá receber algum resultado com a versão do seu Terraform, similar a este:</p>

<p><code>
Terraform v0.11.10
</code></p>

<p>2- Para termos certeza de que o Docker está devidamente instalado e rodando, digite:
<code>
docker ps
</code></p>

<p>Você deverá receber algum resultado parecido com o seguinte:</p>

<p><code>
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></p>

<p><strong>N</strong>ão se assuste ou dê importância para este resultado do comando Docker, ele apenas indica o status atual de seu Docker, informando se você possui algum container rodando ou não. Caso você tenha acabado de instalar o mesmo ou iniciado o serviço do Docker, você provavelmente não terá nenhum container rodando.</p>

<p><strong>C</strong>aso o retorno de seu Docker ou Terraform não seja similar aos que apresentei acima, verifique se a instalação foi realmente bem sucedida ou, no caso do Docker, verifique se o mesmo está rodando, afinal ele não apenas precisa ser instalado, mas precisa estar rodando, diferentemente do Terraform que apenas precisa ser instalado.</p>

<h2>Iniciando nosso projeto</h2>

<p><img class="center" src="/imgs/mariodocker.png" title="&lsquo;Super Mario&rsquo;" ></p>

<h3>Escopo</h3>

<p><strong>O</strong> primeiro passo de qualquer projeto é identificar alguma espécie de esboço ou escopo para o mesmo.</p>

<p><strong>O</strong> que queremos para o nosso projeto é:</p>

<ol>
<li>Ter um jogo web do Mario;</li>
<li>Queremos que ele rode em um container, pois queremos uma aplicação em uma infraestrutura moderna e que possa ser capaz de rodar em qualquer local, seja em um servidor físico local, uma VM ou mesmo um provedor na nuvem, como AWS, GCP, Azure, etc.;</li>
<li>Como não sabemos onde ou como iremos fazer o deployment deste container, queremos fazer com que seja algo automatizado e portável para facilitar futuros planos, portanto queremos criar este container com o Terraform, para que possamos gerenciar nosso código, versionar, etc.</li>
<li>Não escreveremos a aplicação em si. O jogo do Mario já existe e uma imagem para Docker já está disponível para o mesmo através do seguinte link: (<a href="https://hub.docker.com/r/pengbai/docker-supermario/">https://hub.docker.com/r/pengbai/docker-supermario/</a>) (Mas nós não precisamos nos precoupar com isto agora, pois o Terraform vai cuidar de baixar a imagem para nós. ;])</li>
<li>A aplicação deverá estar acessível via browser local para que possamos ao menos garantir que o jogo está de fato funcionando.</li>
</ol>


<p><strong>E</strong>ste será o nosso escopo básico, portanto vamos começar nosso código.</p>

<h3>Projeto</h3>

<p><strong>O</strong> recurso mais básico em um código ou módulo Terraform é o <em>resource</em>, ou recurso. O Terraform suporta centenas de recursos diferentes, dentre eles o <em>docker_image</em>, que será o recurso de que precisaremos inicialmente.</p>

<p><strong>A</strong> partir deste momento não mais utilizarei a palavra recurso. Uma vez que o Terraform chama os recursos de <em>resources</em>, devemos nos acostumar com sua nomenclatura.</p>

<p><strong>A</strong>ntes de mais nada, vamos criar um diretório para nosso projeto. Chamaremos nosso projeto de Marioweb, visto que se trata de uma versao open source do jogo Mario.</p>

<p><strong>A</strong>qui estarei criando o diretório via linha de comando, mas sinta-se livre para criar um diretório da forma que você preferir. Após criar o diretório, com algum terminal ou console aberto (ou prompt do CMD para usuários do Windows), navegue até este diretório recém criado:</p>

<p>```
$ mkdir marioweb</p>

<p>$ cd marioweb
```</p>

<p><strong>D</strong>entro do diretório <em>marioweb</em> crie um novo arquivo chamado <em>main.tf</em>.</p>

<p><strong>P</strong>ara manter um padrão, os arquivos de código do Terraform costumam utilizar o sufixo/extensão .tf e o principal arquivo em módulos ou projetos Terraform costuma se chamar <em>main.tf</em>, por se tratar do arquivo principal do módulo ou projeto.</p>

<p><strong>P</strong>ara criar este arquivo você poderá utilizar qualquer editor de textos de sua escolha: vim, emacs, vi, notepad, notepad++, sublime, atom, etc.</p>

<p><strong>E</strong>m nosso arquivo <em>main.tf</em> insira o seguinte conteúdo por enquanto:</p>

<p><strong>main.tf</strong></p>

<p>```</p>

<h1>Baixar a imagem do Projeto Docker-SuperMario</h1>

<p>resource &ldquo;docker_image&rdquo; &ldquo;image_id&rdquo; {
  name = &ldquo;pengbai/docker-supermario:latest&rdquo;
}
```</p>

<p><strong>O</strong> que temos no bloco de código acima:</p>

<ol>
<li>A primeira linha é apenas um comentário. Como boa prática, é importante termos comentários ao longo de nosso código para descrever o que pretendemos com aquele determinado trecho de código. E por hora, o que pretendemos é exatamente apenas isso: <em>Baixar a imagem do Projeto Docker-SuperMario</em> para nosso ambiente.</li>
<li>Na linha 2 estamos especificando que queremos utilizar um <em>resource</em>. Cada <em>resource</em> no Terraform leva dois parâmetros, sendo um deles o <em>tipo de resource</em> e o outro um <em>nome qualquer</em> para este resource. Como dito antes, este trecho de código pretende baixar a imagem do projeto SuperMario, portanto precisamos do tipo de <em>resource</em> chamado <em>docker_image</em>. Este é apenas um dos milhares de <em>resources</em> existentes para o Terraform. Em seguida estamos dando o nome <em>image_id</em> para nosso <em>resource</em> de tipo <em>docker_image</em>. O nome poderia ser qualquer um, até mesmo <em>minha_imagem_do_coracao</em>, mas para ficar mais descritiva e mantendo boas práticas, utilizarei <em>image_id</em>. Uma vez que identificamos o tipo de <em>resource</em> e o nome que queremos dar para ele, devemos encerrar a linha abrindo o bloco de código no qual listaremos os atributos deste <em>resource</em>. Para isto, utilizaremos um <em>{</em> para abrir este bloco.</li>
<li>Na linha 3 começamos a definir os atributos do nosso <em>resource</em>. A documentação do Terraform é excelente e lista todos os <em>resources</em> suportados, bem como todos os <em>atributos</em> suportados por cada <em>resource</em>. Neste caso, o único atributo que precisamos no momento é o <em>name</em>, ou nome da imagem que desejamos baixar. Em seguida, indicamos qual o nome da imagem desejada. Por padrão, o Docker adota a nomenclatura <em>&lt;REPOSITÓRIO/IMAGEM:TAG></em> para indicar a imagem desejada. Em nosso caso, o repositório onde a imagem se encontra se chama <em>pengbai</em> e a imagem em si é chamada de <em>docker-supermario</em>, portanto teremos: <em>name = &ldquo;pengbai/super-mario&rdquo;</em>. A <em>tag</em> não é obrigatória. Mas como desejo garantir que utilizaremos sempre a imagem mais recente, utilizarei a tag <em>latest</em> (última).</li>
<li>Uma vez que concluímos a definição de nosso <em>resource</em>, podemos fechar o nosso bloco de código para o mesmo utilizando um <em>}</em> na linha 4.</li>
</ol>


<p><strong>A</strong>gora que temos o início de nosso código, já podemos começar a testá-lo.</p>

<p><strong>D</strong>e volta ao nosso terminal/console, vamos iniciar o nosso ambiente Terraform para este projeto utilizando o comando <em>terraform init</em>. Este comando inicia nosso ambiente e baixa os plugins necessários para nosso projeto. No nosso caso, o Terraform baixará os plugins necessários para que nosso código possa lidar com o Docker.</p>

<p>```
$ terraform init</p>

<p>Initializing provider plugins&hellip;
&ndash; Checking for available provider plugins on <a href="https://releases.hashicorp.com...">https://releases.hashicorp.com...</a>
&ndash; Downloading plugin for provider &ldquo;docker&rdquo; (1.1.0)&hellip;</p>

<p>The following providers do not have any version constraints in configuration,
so the latest version was installed.</p>

<p>To prevent automatic upgrades to new major versions that may contain breaking
changes, it is recommended to add version = &ldquo;&hellip;&rdquo; constraints to the
corresponding provider blocks in configuration, with the constraint strings
suggested below.</p>

<ul>
<li>provider.docker: version = &ldquo;~> 1.1&rdquo;</li>
</ul>


<p>Terraform has been successfully initialized!</p>

<p>You may now begin working with Terraform. Try running &ldquo;terraform plan&rdquo; to see
any changes that are required for your infrastructure. All Terraform commands
should now work.</p>

<p>If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
```</p>

<p><strong>S</strong>e você recebeu um retorno parecido com o meu, significa que tudo está como deveria e que seu projeto foi iniciado com sucesso. Caso você liste os arquivos e diretórios ocultos de seu diretório, perceberá que ao rodar o comando <em>terraform init</em>, um diretório oculto chamado <em>terraform</em> foi criado. É nele que ficarão as informações que o Terraform precisa para executar corretamente o seu código, incluindo os plugins que ele necessita. No nosso caso, o plugin para o Docker estará lá.</p>

<p><strong>N</strong>osso próximo passo será executar o <em>planejamento</em> de nosso código. Ao rodar o <em>planejamento</em> o terraform listará exatamente tudo o que ele fará caso nosso código seja de fato executado. Novamente em nosso console/terminal, execute <em>terraform plan</em>:</p>

<p>```
$ terraform plan</p>

<p>Refreshing Terraform state in-memory prior to plan&hellip;
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.</p>

<h2>ATENÇÃO AQUI:</h2>

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li>docker_image.image_id
  id:     <computed>
  latest: <computed>
  name:   &ldquo;pengbai/docker-supermario:latest&rdquo;</li>
</ul>


<p>Plan: 1 to add, 0 to change, 0 to destroy.</p>

<hr />

<p>Note: You didn&rsquo;t specify an &ldquo;-out&rdquo; parameter to save this plan, so Terraform
can&rsquo;t guarantee that exactly these actions will be performed if
&ldquo;terraform apply&rdquo; is subsequently run.
```</p>

<p><strong>C</strong>aso você tenha recebido um retorno similar a este, significa que tudo parece correto em seu código e que apenas uma ação será executada, conforme descrito no resumo do plano ao final:</p>

<p><em>Plan: 1 to add, 0 to change, 0 to destroy.</em></p>

<p><strong>O</strong>u seja: Plano: 1 a adicionar, 0 a alterar, 0 a destruir.</p>

<p><strong>E</strong>xatamente o que queremos.</p>

<p><strong>C</strong>aso você tenha recebido uma mensagem de erro, significa que algo em seu código está errado. Por exemplo, se ao invés de utilizarmos <em>docker_image</em> como tipo de resource, utilizarmos <em>docker_images</em>, o resultado de meu <em>terraform plan</em> seria o seguinte:</p>

<p>```
$ terraform plan</p>

<p>Error: docker_images.image_id: Provider doesn&rsquo;t support resource: docker_images
```</p>

<p><strong>O</strong> erro geralmente é claro e nos indica onde está o erro. No erro acima, o Terraform nos diz que o resource <em>docker_images</em> não é suportado. Se checarmos na documentação, veremos que o nome correto do <em>resource</em> é <em>docker_image</em> (no singular).</p>

<p><strong>U</strong>ma vez que nosso plano foi executado sem erros, chegou a hora de aplicarmos nosso projeto.</p>

<p><strong>E</strong>xecute o seu código através do comando <em>terraform apply</em>:</p>

<p>```
$ terraform apply</p>

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li>docker_image.image_id
  id:     <computed>
  latest: <computed>
  name:   &ldquo;pengbai/docker-supermario:latest&rdquo;</li>
</ul>


<p>Plan: 1 to add, 0 to change, 0 to destroy.</p>

<p>Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only &lsquo;yes&rsquo; will be accepted to approve.</p>

<p>  Enter a value:
```</p>

<p><strong>R</strong>epare que mesmo ao utilizar <em>apply</em> ao invés de <em>plan</em>, uma espécie de planejamento também foi realizado antes da aplicação propriamente dita. O Terraform avaliou o código e nos indicou o que será realizado, perguntando-nos ao final se queremos ou não seguir com a execução. Caso tudo nos pareça correto, basta digitarmos <em>yes</em> e pressionar Enter novamente para que ele siga com a execução de fato.</p>

<p>```</p>

<p>  Enter a value: yes</p>

<p>docker_image.image_id: Creating&hellip;
  latest: &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  name:   &ldquo;&rdquo; => &ldquo;pengbai/docker-supermario:latest&rdquo;
docker_image.image_id: Still creating&hellip; (10s elapsed)
docker_image.image_id: Still creating&hellip; (20s elapsed)
docker_image.image_id: Still creating&hellip; (30s elapsed)
docker_image.image_id: Still creating&hellip; (40s elapsed)
docker_image.image_id: Creation complete after 47s (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)</p>

<p>Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```</p>

<p><strong>A</strong>ssim como no <em>plan</em>, o Terraform ao final nos deu um breve relatório do que foi feito:</p>

<p><em>Apply complete! Resources: 1 added, 0 changed, 0 destroyed.</em></p>

<p><strong>O</strong>u seja: Aplicação completa! Recursos: 1 adicionado, 0 alterados, 0 destruídos.</p>

<p><strong>S</strong>e quisermos ter certeza de que de fato o Terraform baixou a imagem Docker de que precisamos, basta digitarmos o comando do Docker que lista as imagens que possúimos em nosso ambiente. A nossa nova imagem do supermario deverá estar lá. Digite <em>docker images</em>:</p>

<p><code>
$ docker images
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
pengbai/docker-supermario   latest              49beaba1c5cc        4 months ago        686MB
</code></p>

<p><strong>Ó</strong>timo, nossa imagem está presente em nosso ambiente.</p>

<p><strong>O</strong> Terraform também nos permite saber o que estamos utilizando em termos de <em>resources</em> através do comando <em>terraform show</em>:</p>

<p>```
$ terraform show</p>

<p>docker_image.image_id:
  id = sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62pengbai/docker-supermario:latest
  latest = sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62
  name = pengbai/docker-supermario:latest
```</p>

<p><strong>V</strong>oltemos ao nosso código. Agora que já conseguimos fazer com que nosso código baixe a imagem que utilizaremos via Docker, chegou a hora de fazer algo com ela. Precisamos realizar o <em>deployment</em> da mesma em um container, certo?!</p>

<p><strong>V</strong>amos adicionar mais um <em>resource</em> em nosso código, desta vez um <em>resource</em> de tipo <em>docker_container</em>. Como o nome já diz, este <em>resource</em> lida com o container em si, e não mais apenas com a imagem.</p>

<p><strong>S</strong>eu código agora deverá estar da seguinte forma:</p>

<p>```</p>

<h1>Baixar a imagem do Projeto Docker-SuperMario</h1>

<p>resource &ldquo;docker_image&rdquo; &ldquo;image_id&rdquo; {
  name = &ldquo;pengbai/docker-supermario:latest&rdquo;
}</p>

<h1>Inicia o Container</h1>

<p>resource &ldquo;docker_container&rdquo; &ldquo;container_id&rdquo; {
  name  = &ldquo;supermario&rdquo;
  image = &ldquo;${docker_image.image_id.latest}&rdquo;
  ports {</p>

<pre><code>internal = "8080"
external = "80"
</code></pre>

<p>  }
}
```</p>

<p><strong>I</strong>gnorando as linhas já descritas anteriormente, vamos descrever as novas linhas de nosso código:</p>

<ol>
<li>Na linha 6 inserimos apenas mais um comentário, indicando que ali começaremos a descrever o código que criará nosso Container.</li>
<li>Na linha 7 indicamos que queremos mais um <em>resource</em>. Desta vez o tipo de <em>resource</em> que queremos é o <em>docker_container</em>, indicando também que queremos dar o nome <em>container_id</em> a este <em>resource</em>. Novamente, ao fim da linha, abriremos o bloco de código para este <em>resource</em> com uma <em>{</em>.</li>
<li>Dentro de nosso bloco, na linha 8, começaremos a listar os atributos deste <em>resource</em>. O primeiro atributo que listaremos é o <em>name</em>, e para ele daremos o nome <em>supermario</em>.</li>
<li>Na linha 9 indicaremos o atributo <em>image</em> e utilizaremos nossa primeira interpolação, onde utilizaremos valores de outra parte de nosso código como se fossem variáveis. No nosso <em>resource</em> anterior, <em>docker_image</em>, nós demos um nome <em>image_id</em>que será utilizado agora. Incluiremos também a tag <em>latest</em>, pois, conforme pudemos ver na saída de nosso comando <em>terraform show</em>, esta foi a tag utilizada pelo terraform para identificar o último status daquele <em>resource</em>. Portanto, aqui utilizaremos a interpolação inserindo o que queremos entre <em>{}</em> seguidas do símbolo <em>$</em>, conforme prega a sintaxe do Terraform para interpolação de valores, portanto teremos: <em>${docker_image.image_id.latest}</em>, onde <em>docker_image</em> é o tipo de resource de onde queremos o valor, <em>image_id</em> é o nome do resource de onde queremos o valor e <em>latest</em> é a tag para dizer que queremos o último valor daquele <em>resource</em>. O único motivo pelo qual temos um tipo de <em>resource</em> e um nome de <em>resource</em> é para facilitar a identificação quando possuímos diversos <em>resources</em> do mesmo tipo. Imagine um projeto em que utilizaremos 5 imagens diferentes do Docker. Teríamos 5 <em>resources</em> do tipo <em>docker_image</em>, porém cada um deles teria um nome diferente, certo?!</li>
<li>Na linha 10 de nosso código iniciamos o bloco de portas, afinal, toda aplicação roda em uma porta específica e com containers não seria diferente.</li>
<li>Nas linhas 11 e 12 indicamos os valores para portas <em>interna</em> e <em>externa</em>, onde a porta <em>intern</em> será a porta utilizada para rodar a aplicação internamente no container, e <em>extern</em> será a porta que o Docker irá mapear em nosso sistema local para que possamos acessar a nossa aplicação. Portanto, em nosso exemplo, a aplicação supermario irá rodar na porta <em>8080</em> internamente no container, e a porta 80 será mapeada para que possamos acessá-la de nosso navegador local.</li>
<li>Nas linhas 13 e 14 apenas fecharemos os dois blocos de código que criamos, sendo estes o bloco <em>ports</em> e o bloco <em>resource</em> do <em>docker_container</em>.</li>
</ol>


<p><strong>N</strong>ovamente, vamos planejar nosso projeto com <em>terraform plan</em>:</p>

<p>```
$ terraform plan
Refreshing Terraform state in-memory prior to plan&hellip;
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.</p>

<p>docker_image.image_id: Refreshing state&hellip; (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)</p>

<hr />

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li>docker_container.container_id
  id:               <computed>
  attach:           &ldquo;false&rdquo;
  bridge:           <computed>
  container_logs:   <computed>
  exit_code:        <computed>
  gateway:          <computed>
  image:            &ldquo;sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62&rdquo;
  ip_address:       <computed>
  ip_prefix_length: <computed>
  log_driver:       &ldquo;json-file&rdquo;
  logs:             &ldquo;false&rdquo;
  must_run:         &ldquo;true&rdquo;
  name:             &ldquo;supermario&rdquo;
  network_data.#:   <computed>
  ports.#:          &ldquo;1&rdquo;
  ports.0.external: &ldquo;80&rdquo;
  ports.0.internal: &ldquo;8080&rdquo;
  ports.0.ip:       &ldquo;0.0.0.0&rdquo;
  ports.0.protocol: &ldquo;tcp&rdquo;
  restart:          &ldquo;no&rdquo;
  rm:               &ldquo;false&rdquo;
  start:            &ldquo;true&rdquo;</li>
</ul>


<p>Plan: 1 to add, 0 to change, 0 to destroy.</p>

<hr />

<p>Note: You didn&rsquo;t specify an &ldquo;-out&rdquo; parameter to save this plan, so Terraform
can&rsquo;t guarantee that exactly these actions will be performed if
&ldquo;terraform apply&rdquo; is subsequently run.
```</p>

<p><strong>R</strong>epare que desta vez apenas 1 ação será executada: a criação do container. Não estamos mais recebendo as informações referentes à ação de baixar a imagem. O motivo para isto é a propriedade de idempotência que citei anteriormente. O Terraform sabe que a imagem já foi baixada, portanto a mesma não precisa ser baixada novamente, a menos que tivéssemos mudado a versão da mesma, nome, repositório, etc.</p>

<p><strong>U</strong>ma vez que o plano esteja de acordo com o que queremos, podemos aplicar nosso código com <em>terraform apply</em>:</p>

<p>```
$ terraform apply
docker_image.image_id: Refreshing state&hellip; (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)</p>

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li>docker_container.container_id
  id:               <computed>
  attach:           &ldquo;false&rdquo;
  bridge:           <computed>
  container_logs:   <computed>
  exit_code:        <computed>
  gateway:          <computed>
  image:            &ldquo;sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62&rdquo;
  ip_address:       <computed>
  ip_prefix_length: <computed>
  log_driver:       &ldquo;json-file&rdquo;
  logs:             &ldquo;false&rdquo;
  must_run:         &ldquo;true&rdquo;
  name:             &ldquo;supermario&rdquo;
  network_data.#:   <computed>
  ports.#:          &ldquo;1&rdquo;
  ports.0.external: &ldquo;80&rdquo;
  ports.0.internal: &ldquo;8080&rdquo;
  ports.0.ip:       &ldquo;0.0.0.0&rdquo;
  ports.0.protocol: &ldquo;tcp&rdquo;
  restart:          &ldquo;no&rdquo;
  rm:               &ldquo;false&rdquo;
  start:            &ldquo;true&rdquo;</li>
</ul>


<p>Plan: 1 to add, 0 to change, 0 to destroy.</p>

<p>Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only &lsquo;yes&rsquo; will be accepted to approve.</p>

<p>  Enter a value:
```</p>

<p><strong>M</strong>ais uma vez ele nos dá uma visão geral do que será feito e nos perguntará se queremos prosseguir. Digite <em>yes</em> e pressione Enter novamente.</p>

<p>```
Enter a value: yes</p>

<p>docker_container.container_id: Creating&hellip;
attach:           &ldquo;&rdquo; => &ldquo;false&rdquo;
bridge:           &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
container_logs:   &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
exit_code:        &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
gateway:          &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
image:            &ldquo;&rdquo; => &ldquo;sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62&rdquo;
ip_address:       &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
ip_prefix_length: &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
log_driver:       &ldquo;&rdquo; => &ldquo;json-file&rdquo;
logs:             &ldquo;&rdquo; => &ldquo;false&rdquo;
must_run:         &ldquo;&rdquo; => &ldquo;true&rdquo;
name:             &ldquo;&rdquo; => &ldquo;supermario&rdquo;
network_data.#:   &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
ports.#:          &ldquo;&rdquo; => &ldquo;1&rdquo;
ports.0.external: &ldquo;&rdquo; => &ldquo;80&rdquo;
ports.0.internal: &ldquo;&rdquo; => &ldquo;8080&rdquo;
ports.0.ip:       &ldquo;&rdquo; => &ldquo;0.0.0.0&rdquo;
ports.0.protocol: &ldquo;&rdquo; => &ldquo;tcp&rdquo;
restart:          &ldquo;&rdquo; => &ldquo;no&rdquo;
rm:               &ldquo;&rdquo; => &ldquo;false&rdquo;
start:            &ldquo;&rdquo; => &ldquo;true&rdquo;
docker_container.container_id: Creation complete after 1s (ID: 8c9d35eac2fcdc0c7e530567323167b82e72f33d4645abf20685b99d802e2359)</p>

<p>Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```</p>

<p><strong>C</strong>onforme o esperado: Aplicaçao completa! <em>Resources</em>: 1 adicionado, 0 alterados, 0 destruídos.</p>

<p><strong>M</strong>ais uma vez podemos verificar se de fato tudo funcionou como o esperado através do Docker. Desta vez, não queremos apenas baixar uma imagem Docker, mas sim criar um container com a mesma abrindo portas específicas que serão mapeadas entre nosso sistema local e nosso container. Execute agora <em>docker ps</em> para ver os containers que estão rodando neste momento:</p>

<p><code>
docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
8c9d35eac2fc        49beaba1c5cc        "catalina.sh run"   2 minutes ago       Up 2 minutes        0.0.0.0:80-&gt;8080/tcp   supermario
</code></p>

<p><strong>C</strong>omo podemos ver, temos um container rodando. Podemos até ver que existe um mapeamento de portas: *80->8080</p>

<p><strong>N</strong>ão está convencido ainda?</p>

<p><strong>A</strong>bra seu navegador e acesse o seguinte endereço: <em>localhost:80</em></p>

<p><strong>C</strong>aso o seu resultado seja algo parecido com a imagem, significa que seu código funcionou conforme o esperado.</p>

<p><img class="center" src="/imgs/mariodocker.png" title="&lsquo;Super Mario&rsquo;" ></p>

<p><strong>O</strong> terraform também nos permite destruir a nossa infraestrutura com o comando <em>terraform destroy</em>. Da mesma forma que o <em>apply</em>, o comando <em>destroy</em> também lhe dará uma prévia de o que será destruído e lhe pedirá par aconfirmar com um <em>yes</em> ou <em>no</em>:</p>

<p>```
$ terraform destroy
docker_image.image_id: Refreshing state&hellip; (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)
docker_container.container_id: Refreshing state&hellip; (ID: 8c9d35eac2fcdc0c7e530567323167b82e72f33d4645abf20685b99d802e2359)</p>

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  &ndash; destroy</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li><p>docker_container.container_id</p></li>
<li><p>docker_image.image_id</p></li>
</ul>


<p>Plan: 0 to add, 0 to change, 2 to destroy.</p>

<p>Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only &lsquo;yes&rsquo; will be accepted to confirm.</p>

<p>  Enter a value: yes</p>

<p>docker_container.container_id: Destroying&hellip; (ID: 8c9d35eac2fcdc0c7e530567323167b82e72f33d4645abf20685b99d802e2359)
docker_container.container_id: Destruction complete after 0s
docker_image.image_id: Destroying&hellip; (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)
docker_image.image_id: Destruction complete after 2s</p>

<p>Destroy complete! Resources: 2 destroyed.
```</p>

<p><strong>C</strong>omo podemos ver, o terraform destruiu dois <em>resources</em>. Destruiu tanto nosso container como nossa imagem. Você poderá confirmar isso tentando acessar novamente o jogo pelo seu navegador ou mesmo através dos comandos <em>docker images</em> e <em>docker ls</em> para ver que tanto o container como a imagem foram removidos de nosso sistema:</p>

<p>```
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</p>

<p>$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
```</p>

<p><strong>D</strong>e volta ao nosso código, vamos incrementá-lo apenas um pouco mais.</p>

<p><strong>O</strong> terraform nos permite especificar também <em>outputs</em>, ou saídas que nos serão apresentadas ao executarmos nosso código. Apenas informações que podem nos ser úteis.</p>

<p><strong>P</strong>or exemplo, supomos que ao executar nosso código, desejamos que o terraform nos informe o IP do container que foi criado e o nome do mesmo, nosso código agora ficaria assim:</p>

<p>```</p>

<h1>Baixar a imagem do Projeto Docker-SuperMario</h1>

<p>resource &ldquo;docker_image&rdquo; &ldquo;image_id&rdquo; {
  name = &ldquo;pengbai/docker-supermario:latest&rdquo;
}</p>

<h1>Inicia o Container</h1>

<p>resource &ldquo;docker_container&rdquo; &ldquo;container_id&rdquo; {
  name  = &ldquo;supermario&rdquo;
  image = &ldquo;${docker_image.image_id.latest}&rdquo;
  ports {</p>

<pre><code>internal = "8080"
external = "80"
</code></pre>

<p>  }
}</p>

<h1>Nos informa o ip e nome do container criado</h1>

<p>output &ldquo;Endereco IP&rdquo; {
  value = &ldquo;${docker_container.container_id.ip_address}&rdquo;
}</p>

<p>output &ldquo;Nome do Container&rdquo; {
  value = &ldquo;${docker_container.container_id.name}&rdquo;
}
```</p>

<p><strong>N</strong>ovamente, ignorando o código que já descrevemos anteriormente, teremos:</p>

<ol>
<li>Na linha 16 inserimos mais um comentário.</li>
<li>Na linha 17 especificamos que desta vez queremos um <em>output</em>, e não mais um <em>resource</em>. Da mesma forma que fizemos com <em>resources</em>, vamos dar um nome a este <em>output</em>, de forma que possamos facilmente identificá-lo posteriormente. No caso, vamos chamar nosso <em>output</em> de <em>Endereco IP</em>. Em seguida abriremos o bloco de código para este <em>output</em> novamente com <em>{</em>.</li>
<li>Na linha 18 daremos o <em>value</em> ou valor deste output. Novamente utilizaremos interpolação de valores para pegar este valor de nossos <em>resources</em>. Para conseguirmos o endereço ip do container, utilizaremos o atributo <em>ip_address</em>, que é um atributo descrito na documentação do Terraform como parte integrante do resource de tipo <em>docker_container</em>. Portanto, nosso <em>value</em> será: ${docker_container.container_id.ip_address}.</li>
<li>Na linha 19, apenas fechamos o bloco deste <em>output</em>.</li>
<li>Na linha 21 iniciamos nosso segundo <em>output</em>, com o nome <em>Nome do Container</em>. Em seguida, abriremos o bloco de código para este <em>output</em> com um <em>{</em>.</li>
<li>Na linha 22, faremos algo similar ao que fizemos com o <em>value</em> do output anterior. Utilizaremos interpolação para buscar o valor do atributo <em>name</em>, que faz parte do <em>resource</em> <em>docker_container</em>. Nosso <em>value</em> será: ${docker_container.container_id.name}</li>
<li>Na linha 23, apenas fechamos nosso <em>output</em>.</li>
</ol>


<p><strong>V</strong>amos então rodar nosso <em>plan</em> para ver o que aconteceria desta vez:</p>

<p>```
$ terraform plan
Refreshing Terraform state in-memory prior to plan&hellip;
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.</p>

<hr />

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li><p>docker_container.container_id
  id:               <computed>
  attach:           &ldquo;false&rdquo;
  bridge:           <computed>
  container_logs:   <computed>
  exit_code:        <computed>
  gateway:          <computed>
  image:            &ldquo;${docker_image.image_id.latest}&rdquo;
  ip_address:       <computed>
  ip_prefix_length: <computed>
  log_driver:       &ldquo;json-file&rdquo;
  logs:             &ldquo;false&rdquo;
  must_run:         &ldquo;true&rdquo;
  name:             &ldquo;supermario&rdquo;
  network_data.#:   <computed>
  ports.#:          &ldquo;1&rdquo;
  ports.0.external: &ldquo;80&rdquo;
  ports.0.internal: &ldquo;8080&rdquo;
  ports.0.ip:       &ldquo;0.0.0.0&rdquo;
  ports.0.protocol: &ldquo;tcp&rdquo;
  restart:          &ldquo;no&rdquo;
  rm:               &ldquo;false&rdquo;
  start:            &ldquo;true&rdquo;</p></li>
<li><p>docker_image.image_id
  id:               <computed>
  latest:           <computed>
  name:             &ldquo;pengbai/docker-supermario:latest&rdquo;</p></li>
</ul>


<p>Plan: 2 to add, 0 to change, 0 to destroy.</p>

<hr />

<p>Note: You didn&rsquo;t specify an &ldquo;-out&rdquo; parameter to save this plan, so Terraform
can&rsquo;t guarantee that exactly these actions will be performed if
&ldquo;terraform apply&rdquo; is subsequently run.
```</p>

<p><strong>D</strong>esta vez podemos ver que ambas as ações serão executadas: A imagem será baixada e o container será criado, afinal nós tínhamos removido tudo com <em>terraform destroy</em> anteriormente.</p>

<p><strong>V</strong>amos aplicar nosso código e confirmar com <em>yes</em>:</p>

<p>```
$ terraform apply</p>

<p>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create</p>

<p>Terraform will perform the following actions:</p>

<ul>
<li><p>docker_container.container_id
  id:               <computed>
  attach:           &ldquo;false&rdquo;
  bridge:           <computed>
  container_logs:   <computed>
  exit_code:        <computed>
  gateway:          <computed>
  image:            &ldquo;${docker_image.image_id.latest}&rdquo;
  ip_address:       <computed>
  ip_prefix_length: <computed>
  log_driver:       &ldquo;json-file&rdquo;
  logs:             &ldquo;false&rdquo;
  must_run:         &ldquo;true&rdquo;
  name:             &ldquo;supermario&rdquo;
  network_data.#:   <computed>
  ports.#:          &ldquo;1&rdquo;
  ports.0.external: &ldquo;80&rdquo;
  ports.0.internal: &ldquo;8080&rdquo;
  ports.0.ip:       &ldquo;0.0.0.0&rdquo;
  ports.0.protocol: &ldquo;tcp&rdquo;
  restart:          &ldquo;no&rdquo;
  rm:               &ldquo;false&rdquo;
  start:            &ldquo;true&rdquo;</p></li>
<li><p>docker_image.image_id
  id:               <computed>
  latest:           <computed>
  name:             &ldquo;pengbai/docker-supermario:latest&rdquo;</p></li>
</ul>


<p>Plan: 2 to add, 0 to change, 0 to destroy.</p>

<p>Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only &lsquo;yes&rsquo; will be accepted to approve.</p>

<p>  Enter a value: yes</p>

<p>docker_image.image_id: Creating&hellip;
  latest: &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  name:   &ldquo;&rdquo; => &ldquo;pengbai/docker-supermario:latest&rdquo;
docker_image.image_id: Still creating&hellip; (10s elapsed)
docker_image.image_id: Still creating&hellip; (20s elapsed)
docker_image.image_id: Still creating&hellip; (30s elapsed)
docker_image.image_id: Still creating&hellip; (40s elapsed)
docker_image.image_id: Still creating&hellip; (50s elapsed)
docker_image.image_id: Creation complete after 59s (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7&hellip;9c3d62pengbai/docker-supermario:latest)
docker_container.container_id: Creating&hellip;
  attach:           &ldquo;&rdquo; => &ldquo;false&rdquo;
  bridge:           &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  container_logs:   &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  exit_code:        &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  gateway:          &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  image:            &ldquo;&rdquo; => &ldquo;sha256:49beaba1c5cc49d2fa424ac03a15b0e761f637e835c1ed4d8108cc247a9c3d62&rdquo;
  ip_address:       &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  ip_prefix_length: &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  log_driver:       &ldquo;&rdquo; => &ldquo;json-file&rdquo;
  logs:             &ldquo;&rdquo; => &ldquo;false&rdquo;
  must_run:         &ldquo;&rdquo; => &ldquo;true&rdquo;
  name:             &ldquo;&rdquo; => &ldquo;supermario&rdquo;
  network_data.#:   &ldquo;&rdquo; => &ldquo;<computed>&rdquo;
  ports.#:          &ldquo;&rdquo; => &ldquo;1&rdquo;
  ports.0.external: &ldquo;&rdquo; => &ldquo;80&rdquo;
  ports.0.internal: &ldquo;&rdquo; => &ldquo;8080&rdquo;
  ports.0.ip:       &ldquo;&rdquo; => &ldquo;0.0.0.0&rdquo;
  ports.0.protocol: &ldquo;&rdquo; => &ldquo;tcp&rdquo;
  restart:          &ldquo;&rdquo; => &ldquo;no&rdquo;
  rm:               &ldquo;&rdquo; => &ldquo;false&rdquo;
  start:            &ldquo;&rdquo; => &ldquo;true&rdquo;
docker_container.container_id: Creation complete after 0s (ID: 655604d672af8ff76c10aca4cd169a6aa284dcca17f0e0215374fb18c86660fd)</p>

<p>Apply complete! Resources: 2 added, 0 changed, 0 destroyed.</p>

<p>Outputs:</p>

<p>Endereco IP = 172.17.0.2
Nome do Container = supermario
```</p>

<p><strong>R</strong>epare que tudo o que queríamos foi executado e que, ao final, recebemos duas saídas ou <em>outputs</em>:</p>

<p>```
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.</p>

<p>Outputs:</p>

<p>Endereco IP = 172.17.0.2
Nome do Container = supermario
```</p>

<p><strong>N</strong>ovamente, se você acessar em seu navegador o endereço <em>localhost:80</em>, ou utilizar os comandos <em>docker ps</em>, perceberá que sua aplicação está novamente rodando.</p>

<p><strong>N</strong>ão é complicado, certo?!</p>

<p><strong>O</strong>bviamente, isto é apenas um exemplo extremamente simplista de uso do Terraform para criar uma pequena infraestrutura como código, que em nosso caso é apenas um container.</p>

<p><strong>N</strong>o próximo post pretendo alterar um pouco este nosso código para utilizar algumas melhores práticas propostas pelo Terraform, como a utilização de variáveis e outputs em arquivos distintos, já que não utilizamos variáveis neste post.</p>

<p><strong>U</strong>m passo de cada vez, certo?!</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Conhecendo o Kubernetes - Clusters de Containers]]></title>
    <link href="https://kalib.github.io/blog/2017/06/24/conhecendo-o-kubernetes-clusters-de-containers/"/>
    <updated>2017-06-24T09:32:00-04:00</updated>
    <id>https://kalib.github.io/blog/2017/06/24/conhecendo-o-kubernetes-clusters-de-containers</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/kubernetes_logo.png" title="&lsquo;Kubernetes&rsquo;" ></p>

<h2>O que é Kubernetes</h2>

<p><strong>K</strong>ubernetes é uma solução Open Source desenvolvida pelo Google, originalmente chamada de K8s, como uma ferramenta para gerenciar clusters de containers (ou containeres, como prefira). Em 2005, quando a ferramenta foi desenvolvida, originalmente para uso interno, o Google doou o código à recém fundada <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>, em parceria com a <a href="https://www.linuxfoundation.org/">The Linux Foundation</a>.</p>

<p><strong>O</strong> motivo do leme em sua logomarca é devido à origem grega da palavra, que vem de Kuvernetes, que representa a pessoa que pilota o navio, timoneiro.</p>

<p><strong>C</strong>omo objetivo primário o Kubernetes provê uma plataforma de automação para deployments, escalonamento e operações de containers de aplicações em um cluster de hosts ou nodes.</p>

<p><strong>A</strong>ntes de seguir com a explicação, instalação e configuração do Kubernetes, estou supondo que você já possui algum conhecimento básico sobre o que sejam containers e tenha alguma familiaridade com o <a href="https://www.docker.com">Docker</a>. Caso não possua um entendimento básico sobre containers e Docker, sugiro que leia algo antes de seguir com este artigo. Possuo um post introdutório sobre containers com um exemplo básico e prático sobre como criar containers com Docker, bem como iniciar uma simples aplicação web &ndash;  <a href="/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">aqui</a>.</p>

<p><strong>O</strong> Kubernetes é formado por uma série de componentes ou blocos que, quando utilizados coletivamente, fornecem um método de deployment, manutenção e escalonamento de clusters de aplicações baseadas em containers. Estes componentes, ou primitives como o Kubernetes os chama, foram desenvolvidos com o intuito de serem independentes, de forma que quase não se faz necessário ter conhecimento entre si para que possam funcionar e trabalhar juntos, visto que todos se comunicam e interligam através de uma API, sejam componentes internos do Kubernetes ou mesmo extensões e containers.</p>

<p><strong>E</strong>mbora tenha sido inicialmente desenvolvido para o deployment e utilização de <strong>bilhões de containers</strong> internamente no Google, desde que seu código passou a ser distribuído abertamente com a licença <a href="https://commons.apache.org/proper/commons-daemon/license.html">Apache Commons</a> o Kubernetes tem sido adotado formalmente por praticamente todos os grandes provedores de serviços em nuvem.</p>

<h2>Arquitetura do Kubernetes</h2>

<p><img class="center" src="/imgs/kubernetes_architecture.png" title="&lsquo;Kubernetes Architecture&rsquo;" ></p>

<p><strong>D</strong>entre os principais componentes do Kubernetes, vamos destacar os seguintes:</p>

<ul>
<li><p><strong>Master ou Master Controller</strong> &ndash; Host que será o gerenciador principal do Kubernetes, responsável por gerenciar os Minions ou Nodes do Cluster;</p></li>
<li><p><strong>Nodes ou Minions</strong> &ndash; Embora normalmente a nomenclatura em diversos serviços de tecnolocia seja Node, o Kubernetes prefere chamar de Minions os hosts que fazem parte de um Cluster gerenciado pelo próprio Kubernetes. Este minion pode ser um servidor físico ou virtual, necessitando possuir um serviço de gerenciamento de containers, como o Docker, por exemplo;</p></li>
<li><p><strong>ETCD</strong> &ndash; Embora este seja um serviço independente, estou listando-o aqui pois este será fundamental em seu ciclo de desenvolvimento com o Kubernetes. Cada Minion deverá rodar o <a href="https://coreos.com/etcd/docs/latest/">ETCD</a> (serviço de comunicação e gerenciamento de configurações no formato par de Chave/Valor). O ETCD é utilizado para troca e armazenamento de informações sobre os containers, pods, minions, etc.</p></li>
<li><p><strong>Pods</strong> &ndash; São grupos de containers (um ou mais) rodando em um único minion do cluster. Cada Pod receberá um endereço IP único no Cluster como forma de possibilitar a utilização de portas sem a necessidade de se preocupar com conflitos;</p></li>
<li><p><strong>Labels</strong> &ndash; São informações de identificação na configuração e gerenciamento dos objetos (como Pods ou Minions) formados de pares &ldquo;chave:valor&rdquo;;</p></li>
<li><p><strong>Controllers</strong> &ndash; Além do Master Controller, dependendo do tamanho de sua infraestrutura e quantidade de Pods e Minions, você pode optar por ter mais de um Controller para dividir a carga e tarefas de gerenciamento. Os Controllers gerenciam um grupo de pods e, dependendo do estado de configuração desejada, podem acionar outros Controllers para lidar com as replicações e escalonamento. Os Controllers também são responsáveis pela substituiçao de Pods, caso um entre em estado de falha.</p></li>
</ul>


<h2>Instalação</h2>

<p><strong>V</strong>amos ao que interessa&hellip;</p>

<p><strong>N</strong>ovamente estou supondo que você já possui alguma familiaridade com Containers, Docker e, por consequência, com GNU/Linux.</p>

<p><strong>E</strong>estarei utilizando 4 servidores virtuais rodando CentOS 7 nos exemplos a seguir, mas fica a seu critério decidir quantos utilizar.</p>

<p><em>Certamente você optar por utilizar outra distribuição, seja Debian, Ubuntu, etc.. Uma vez que optei pelo CentOS 7, estarei utilizando comandos voltados para esta distro, mas sinta-se livre para adaptar seus comandos, como substituir o &ldquo;yum&rdquo; pelo &ldquo;apt-get&rdquo;, &ldquo;pacman&rdquo;, etc..</em></p>

<p><strong>E</strong>m minha configuração chamarei os servidores da seguinte forma:</p>

<ul>
<li>centos-master</li>
<li>centos-minion1</li>
<li>centos-minion2</li>
<li>centos-minion3</li>
</ul>


<p><strong>A</strong> primeira coisa que se deve fazer sempre que se pensa em trabalhar com clusters, independente de ser um cluster de containers ou não, é ter a certeza de que os servidores terão uma correta sincronização de relógios entre si. A forma mais simples e eficiente no nosso contexto é com a utilização do NTP, portanto comece instalando o NTP nos 4 servidores, bem como habilitando o serviço e iniciando-o:</p>

<p>```</p>

<h1>yum install -y ntp</h1>

<p>```</p>

<p>```</p>

<h1>systemctl enable ntpd &amp;&amp; systemctl start ntpd</h1>

<p>```</p>

<p><strong>C</strong>aso queira certificar-se de que o serviço está realmente rodando:</p>

<p>```</p>

<h1>systemctl status ntpd</h1>

<p>● ntpd.service &ndash; Network Time Service
   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled)
   Active: active (running) since Sat 2017-06-24 17:46:02 UTC; 3s ago
  Process: 1586 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)
 Main PID: 1587 (ntpd)
   Memory: 2.1M
   CGroup: /system.slice/ntpd.service</p>

<pre><code>       └─1587 /usr/sbin/ntpd -u ntp:ntp -g
</code></pre>

<p>```</p>

<p><strong>P</strong>inga?</p>

<p><strong>É</strong> importante nos certificarmos de que os servidores conseguem se comunicar e de que conseguem resolver nomes corretamente.</p>

<p><strong>N</strong>este exemplo, conforme informado mais acima, estamos utilizando 4 servidores com os seguintes nomes: <em>centos-master</em>, <em>centos-minion1</em>, <em>centos-minion2</em> e <em>centos-minion3</em>, portanto vamos editar o arquivo <strong>/etc/hosts</strong> de cada um deles para que possam se comunicar pelos nomes que desejamos:</p>

<p><strong>Insira as seguintes linhas no arquivo /etc/hosts dos 4 servidores:</strong></p>

<p><em>Lembre-se de substituir os IPs pelos IPs dos servidores em seu ambiente</em></p>

<p>```</p>

<h1>Ip local do servidor master</h1>

<p>172.31.22.126   centos-master</p>

<h1>Ip local do minion1</h1>

<p>172.31.120.16   centos-minion1</p>

<h1>Ip local do minion2</h1>

<p>172.31.25.6     centos-minion2</p>

<h1>Ip local do minion3</h1>

<p>172.31.123.22   centos-minion3
```</p>

<p>Feito isto, tente pingar do master para os 3 minions utilizando os nomes especificados no /etc/hosts:</p>

<p>```
[root@kalib1 ~]# ping centos-minion1
PING centos-minion1 (172.31.120.16) 56(84) bytes of data.
64 bytes from centos-minion1 (172.31.120.16): icmp_seq=1 ttl=64 time=1.06 ms</p>

<p>[root@kalib1 ~]# ping centos-minion2
PING centos-minion2 (172.31.25.6) 56(84) bytes of data.
64 bytes from centos-minion2 (172.31.25.6): icmp_seq=1 ttl=64 time=0.588 ms</p>

<p>[root@kalib1 ~]# ping centos-minion3
PING centos-minion3 (172.31.123.22) 56(84) bytes of data.
64 bytes from centos-minion3 (172.31.123.22): icmp_seq=1 ttl=64 time=1.24 ms
```</p>

<p><strong>V</strong>ocê pode realizar o mesmo teste a partir dos minions, pingando entre si e também para o centos-master.</p>

<p><strong>U</strong>ma vez que tenhamos certeza de que todos os hosts se comunicam, é hora de instalar mais alguns pacotes necessários.</p>

<p><strong>P</strong>rimeiramente, vamos configurar o repositório do Docker para o CentOS 7:</p>

<ul>
<li>Configurações de repositório retiradas dos repositórios CBS do Centos: <a href="https://cbs.centos.org/repos/virt7-docker-common-release/">https://cbs.centos.org/repos/virt7-docker-common-release/</a></li>
</ul>


<p><strong>V</strong>amos criar o seguinte arquivo de repositório:</p>

<p>```</p>

<h1>vim /etc/yum.repos.d/virt7-docker-common-release.repos</h1>

<p>```</p>

<p><strong>O</strong> conteúdo deste arquivo será o seguinte:</p>

<p><code>
[virt7-docker-common-release]
name=virt7-docker-common-release
baseurl=https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
gpgcheck=0
</code></p>

<p><em>Este arquivo deverá ser criado nos 4 servidores.</em></p>

<p><strong>E</strong>m seguida, vamos atualizar a nossa base de repositórios e pacotes, também <strong>nos 4 servidores</strong>, bem como habilitar o novo repositório para instalar os pacotes docker e kubernetes:</p>

<p>```</p>

<h1>yum update</h1>

<p>```</p>

<p>```</p>

<h1>yum install -y &mdash;enablerepo=virt7-docker-common-release docker kubernetes</h1>

<p>```</p>

<p><strong>C</strong>omo dito na introdução, também precisaremos do etcd para o armazenamento e troca de configurações, portanto vamos instalá-lo também nos 4 hosts:</p>

<p>```</p>

<h1>yum instal -y etcd</h1>

<p>```</p>

<h2>Configuração</h2>

<p><strong>V</strong>amos começar com a configuração básica dos serviços envolvidos. Primeiramente, vamos abrir o arquivo de configuração do kubernetes e fazer algumas alterações:</p>

<p><em>/etc/kubernetes/config</em></p>

<p><strong>N</strong>o arquivo config altere as seguintes linhas:</p>

<p><em>Edite o valor do parâmetro KUBE_MASTER, de forma que nosso master possa ser encontrado pelo nome que definimos no hosts file. O valor original é &ldquo;&mdash;master=<a href="https://127.0.0.1:8080">https://127.0.0.1:8080</a>&rdquo;, portanto mudaremos para o seguinte:</em></p>

<p><code>
KUBE_MASTER="--master=https://centos-master:8080"
</code></p>

<p><strong>A</strong>inda neste arquivo de configuração, vamos inserir a configuração do serviço ETCD, portanto inclua a seguinte linha ao final do arquivo:</p>

<p><code>
KUBE_ETCD_SERVERS="--etcd-servers=https://centos-master:2379"
</code></p>

<p><strong>S</strong>eu arquivo de configuração deverá estar similar a este:</p>

<p>```</p>

<h2>#</h2>

<h1>kubernetes system config</h1>

<p>#</p>

<h1>The following values are used to configure various aspects of all</h1>

<h1>kubernetes services, including</h1>

<p>#</p>

<h1>kube-apiserver.service</h1>

<h1>kube-controller-manager.service</h1>

<h1>kube-scheduler.service</h1>

<h1>kubelet.service</h1>

<h1>kube-proxy.service</h1>

<h1>logging to stderr means we get it in the systemd journal</h1>

<p>KUBE_LOGTOSTDERR=&ldquo;&mdash;logtostderr=true&rdquo;</p>

<h1>journal message level, 0 is debug</h1>

<p>KUBE_LOG_LEVEL=&ldquo;&mdash;v=0&rdquo;</p>

<h1>Should this cluster be allowed to run privileged docker containers</h1>

<p>KUBE_ALLOW_PRIV=&ldquo;&mdash;allow-privileged=false&rdquo;</p>

<h1>How the controller-manager, scheduler, and proxy find the apiserver</h1>

<p>KUBE_MASTER=&ldquo;&mdash;master=<a href="https://centos-master:8080">https://centos-master:8080</a>&rdquo;</p>

<p>KUBE_ETCD_SERVERS=&ldquo;&mdash;etcd-servers=<a href="https://centos-master:2379">https://centos-master:2379</a>&rdquo;
```</p>

<p><strong>R</strong>epita esta mesma configuração nos 4 hosts. Todos eles devem utilizar exatamente os mesmos valores utilizados aqui, apontando KUBE_MASTER e KUBE_ETCD_SERVERS para centos-master, visto que este será o responsável por gerenciar todos os nossos minions.</p>

<p><strong>U</strong>ma vez que o arquivo de configuração do kubernetes esteja pronto nos 4 hosts, vamos configurar o serviço de API do kubernetes:</p>

<p><em>/etc/kubernetes/apiserver</em></p>

<p><strong>Esta configuração abaixo será apenas para o Master.</strong></p>

<p><em>Edite o valor do parâmetro KUBE_API_ADDRESS, que originalmente é &ldquo;&mdash;insecure-bind-address=127.0.0.1&rdquo;, de forma que possamos novamente receber comunicação dos demais hosts.</em></p>

<p><code>
KUBE_API_ADDRESS="--address=0.0.0.0"
</code></p>

<p><em>Descomente as linhas KUBE_API_PORT e KUBELET_PORT, para que possamos estabelecer as portas de comunicação com a API:</em></p>

<p>```</p>

<h1>The port on the local server to listen on.</h1>

<p>KUBE_API_PORT=&ldquo;&mdash;port=8080&rdquo;</p>

<h1>Port minions listen on</h1>

<p>KUBELET_PORT=&ldquo;&mdash;kubelet-port=10250&rdquo;
```</p>

<p><em>Em nosso exemplo não utilizaremos o parâmetro KUBE_ADMISSION_CONTROL, o qual nos permite ter mais controles e restrições sobre quais nodes ou minios podem entrar em nosso ambiente, portanto vamos apenas comentar esta linha por enquanto:</em></p>

<p>```</p>

<h1>default admission control policies</h1>

<h1>KUBE_ADMISSION_CONTROL=&ldquo;&mdash;admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&rdquo;</h1>

<p>```</p>

<p><em>Nosso arquivo /etc/kubernetes/apiserver deverá estar assim:</em></p>

<p>```</p>

<h1>#</h1>

<h1>kubernetes system config</h1>

<p>#</p>

<h1>The following values are used to configure the kube-apiserver</h1>

<p>#</p>

<h1>The address on the local server to listen to.</h1>

<p>KUBE_API_ADDRESS=&ldquo;&mdash;address=0.0.0.0&rdquo;</p>

<h1>The port on the local server to listen on.</h1>

<p>KUBE_API_PORT=&ldquo;&mdash;port=8080&rdquo;</p>

<h1>Port minions listen on</h1>

<p>KUBELET_PORT=&ldquo;&mdash;kubelet-port=10250&rdquo;</p>

<h1>Comma separated list of nodes in the etcd cluster</h1>

<p>KUBE_ETCD_SERVERS=&ldquo;&mdash;etcd-servers=<a href="https://127.0.0.1:2379">https://127.0.0.1:2379</a>&rdquo;</p>

<h1>Address range to use for services</h1>

<p>KUBE_SERVICE_ADDRESSES=&ldquo;&mdash;service-cluster-ip-range=10.254.0.0/16&rdquo;</p>

<h1>default admission control policies</h1>

<h1>KUBE_ADMISSION_CONTROL=&ldquo;&mdash;admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&rdquo;</h1>

<h1>Add your own!</h1>

<p>KUBE_API_ARGS=&ldquo;&rdquo;
```</p>

<p><strong>S</strong>alve e feche o arquivo. Novamente, esta configuração deve ser feita apenas para o Master.</p>

<p><strong>A</strong>gora vamos configurar o serviço ETCD:</p>

<p><em>/etc/etcd/etcd.conf</em></p>

<p><strong>Esta configuração abaixo será apenas para o Master.</strong></p>

<p><em>Edite os valores dos parâmetros ETCD_LISTEN_CLIENT_URLS e ETCD_ADVERTISE_CLIENT_URLS, que originalmente apontam para localhost. Como desejamos que nosso etcd escute requisições dos demais hosts, altere para o seguinte:</em></p>

<p><code>
ETCD_LISTEN_CLIENT_URLS="https://0.0.0.0:2379"
...
...
ETCD_ADVERTISE_CLIENT_URLS="https://0.0.0.0:2379"
</code></p>

<p><strong>N</strong>ovamente, não é necessário alterar a configuração do etcd nos demais hosts, apenas no Master.</p>

<p><strong>U</strong>ma vez que as configurações iniciais foram feitas, vamos habilitar e iniciar os serviços necessários <strong>no Master</strong>, sendo eles:</p>

<ul>
<li>etcd</li>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-scheduler</li>
</ul>


<p>```</p>

<h1>systemctl enable etcd kube-apiserver kube-controller-manager kube-scheduler</h1>

<p>```</p>

<p>```</p>

<h1>systemctl start etcd kube-apiserver kube-controller-manager kube-scheduler</h1>

<p>```</p>

<p><strong>O</strong>s 4 serviços devem estar rodando. Para termos certeza, vamos checar o status dos mesmos:</p>

<p>```</p>

<h1>systemctl status etcd kube-apiserver kube-controller-manager kube-scheduler | grep &ldquo;(running)&rdquo;</h1>

<p>   Active: active (running) since Sat 2017-06-24 21:45:37 UTC; 1min ago
   Active: active (running) since Sat 2017-06-24 21:46:13 UTC; 1min ago
   Active: active (running) since Sat 2017-06-24 21:44:25 UTC; 1min ago
   Active: active (running) since Sat 2017-06-24 21:44:25 UTC; 1min ago
```</p>

<p><strong>N</strong>ovamente, estes serviços serão iniciados no Master, e não nos nodes/minions, visto que estes utilizarão outros serviços.</p>

<p><strong>A</strong>gora vamos configurar o seguinte arquivo nos nodes/minions:</p>

<p><em>/etc/kubernetes/kubelet</em></p>

<p><strong>Este arquivo apenas deverá ser editado nos nodes/minions, não no Master.</strong></p>

<p><em>Vamos alterar o valor do parâmetro KUBELET_ADDRESS para que aceite comunicação não apenas do localhost:</em></p>

<p><code>
KUBELET_ADDRESS="--address=0.0.0.0"
</code></p>

<p><em>Descomentaremos também a linha KUBELET_PORT, para que possamos ter uma porta definida para a comunicação do kubelet:</em></p>

<p>```</p>

<h1>The port for the info server to serve on</h1>

<p>KUBELET_PORT=&ldquo;&mdash;port=10250&rdquo;
```</p>

<p><em>Vamos alterar o valor do parâmetro KUBELET_HOSTNAME para o nome que definimos <strong>para cada um dos minions</strong>, portanto em cada um deles este será um valor diferente. Supondo que este seja o minion1, utilizaremos:</em></p>

<p><code>
KUBELET_HOSTNAME="--hostname-override=centos-minion1"
</code></p>

<p><em>Vamos também alterar o valor para KUBELET_API_SERVER, apontando para o nosso Master:</em></p>

<p><code>
KUBELET_API_SERVER="--api-servers=https://centos-master:8080"
</code></p>

<p><em>Vamos comentar a linha KUBELET_POD_INFRA_CONTAINER, visto que não utilizaremos uma infraestrutura de containers externa, pois estaremos utilizando nossos próprios PODs e containers:</em></p>

<p>```</p>

<h1>pod infrastructure container</h1>

<h1>KUBELET_POD_INFRA_CONTAINER=&ldquo;&mdash;pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&rdquo;</h1>

<p>```</p>

<p><em>Nosso arquivo deverá estar assim: (Lembrando que o parâmetro KUBELET_HOSTNAME deverá ser diferente para cada um dos 3 minions, respectivamente: centos-minion1, centos-minion2 e centos-minion3)</em></p>

<p>```</p>

<h2>#</h2>

<h1>kubernetes kubelet (minion) config</h1>

<h1>The address for the info server to serve on (set to 0.0.0.0 or &ldquo;&rdquo; for all interfaces)</h1>

<p>KUBELET_ADDRESS=&ldquo;&mdash;address=0.0.0.0&rdquo;</p>

<h1>The port for the info server to serve on</h1>

<p>KUBELET_PORT=&ldquo;&mdash;port=10250&rdquo;</p>

<h1>You may leave this blank to use the actual hostname</h1>

<p>KUBELET_HOSTNAME=&ldquo;&mdash;hostname-override=centos-minion1&rdquo;</p>

<h1>location of the api-server</h1>

<p>KUBELET_API_SERVER=&ldquo;&mdash;api-servers=<a href="https://centos-master:8080">https://centos-master:8080</a>&rdquo;</p>

<h1>pod infrastructure container</h1>

<h1>KUBELET_POD_INFRA_CONTAINER=&ldquo;&mdash;pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&rdquo;</h1>

<h1>Add your own!</h1>

<p>KUBELET_ARGS=&ldquo;&rdquo;
```</p>

<p><strong>U</strong>ma vez que estas configurações também estão feitas nos 3 minions, vamos habilitar e iniciar os serviços necessários nos minions:</p>

<ul>
<li>kube-proxy</li>
<li>kube-kubelet</li>
<li>docker</li>
</ul>


<p>```</p>

<h1>systemctl enable kube-proxy kubelet docker</h1>

<p>```</p>

<p>```</p>

<h1>systemctl start kube-proxy kubelet docker</h1>

<p>```</p>

<p><strong>N</strong>ovamente, vamos ter certeza de que os 3 serviços estão rodando:</p>

<p>```</p>

<h1>systemctl status kube-proxy kubelet docker | grep &ldquo;(running)&rdquo;</h1>

<p>   Active: active (running) since Sat 2017-06-24 21:44:23 UTC; 1h 16min ago
   Active: active (running) since Sat 2017-06-24 21:44:27 UTC; 1h 16min ago
   Active: active (running) since Sat 2017-06-24 21:44:27 UTC; 1h 16min ago
```</p>

<p><strong>N</strong>ovamente, estes 3 serviços devem ser habilitados e iniciados nos 3 minions.</p>

<p><strong>N</strong>este momento já temos nosso cluster rodando, com um master e 3 minions. :D</p>

<h2>Testando o Cluster com o Kubernetes</h2>

<p><strong>A</strong>gora que temos a configuração básica de nosso Master Controller e de 3 minions, vamos testar nosso cluster.</p>

<p><strong>U</strong>tilizaremos o utilitário kubectl (KubeControl) disponível com o kubernetes. Caso tenha interesse em ver os parâmetros e funções do mesmo&hellip; <em>$ man kubectl</em></p>

<p><strong>V</strong>amos verificar a lista dos nodes ou minions que temos neste momento registrados em nosso Cluster. Vamos digitar alguns comandos em nosso Master Controller (centos-master):</p>

<p><code>
[root@kalib1 ~]# kubectl get nodes
NAME             STATUS    AGE
centos-minion1   Ready     17m
centos-minion2   Ready     15m
centos-minion3   Ready     10m
</code></p>

<p><strong>O</strong>s três nodes criados e configurados anteriormente já são reconhecidos pelo nosso Kubernetes através do Master Controller. Além de registrados, estão com o status Ready, o que indica que estão prontos para funcionar e executar o que precisarmos.</p>

<p><em>Caso deseje conhecer mais parâmetros que a função <strong>get</strong> do kubectl possui, podemos invocar o manual desta função: $ man kubectl-get</em></p>

<p><strong>A</strong>lém do status, podemos conseguir diversas outras informações dos nodes através do <em>kubectl</em>: <em>(Ex: kubectl describe nodes)</em> Isto lhe daria informações sobre todos os nodes. Vamos experimentar com um node em específico.</p>

<p>```
[root@kalib1 ~]# kubectl describe node centos-minion1
Name:                   centos-minion1
Role:
Labels:                 beta.kubernetes.io/arch=amd64</p>

<pre><code>                    beta.kubernetes.io/os=linux
                    kubernetes.io/hostname=centos-minion1
</code></pre>

<p>Taints:                 <none>
CreationTimestamp:      Tue, 20 Jun 2017 19:27:31 +0000
Phase:
Conditions:
  Type                  Status  LastHeartbeatTime                       LastTransitionTime                      Reason     Message</p>

<hr />

<p>  OutOfDisk             False   Sun, 25 Jun 2017 01:39:38 +0000         Fri, 23 Jun 2017 17:31:44 +0000         KubeletHasSufficientDisk    kubelet has sufficient disk space available
  MemoryPressure        False   Sun, 25 Jun 2017 01:39:38 +0000         Tue, 20 Jun 2017 19:27:31 +0000         KubeletHasSufficientMemory  kubelet has sufficient memory available
  DiskPressure          False   Sun, 25 Jun 2017 01:39:38 +0000         Tue, 20 Jun 2017 19:27:31 +0000         KubeletHasNoDiskPressure    kubelet has no disk pressure
  Ready                 True    Sun, 25 Jun 2017 01:39:38 +0000         Fri, 23 Jun 2017 17:31:54 +0000         KubeletReady                        kubelet is posting ready status
Addresses:              172.31.120.16,172.31.120.16,centos-minion1
Capacity:
 alpha.kubernetes.io/nvidia-gpu:        0
 cpu:                                   1
 memory:                                1015348Ki
 pods:                                  110
Allocatable:
 alpha.kubernetes.io/nvidia-gpu:        0
 cpu:                                   1
 memory:                                1015348Ki
 pods:                                  110
System Info:
 Machine ID:                    f9afeb75a5a382dce8269887a67fbf58
 System UUID:                   EC2C8A0E-91D6-F54E-5A49-534A6A903FDA
 Boot ID:                       20961efd-c946-481a-97cb-7788209551ae
 Kernel Version:                3.10.0-327.28.2.el7.x86_64
 OS Image:                      CentOS Linux 7 (Core)
 Operating System:              linux
 Architecture:                  amd64
 Container Runtime Version:     docker://1.12.6
 Kubelet Version:               v1.5.2
 Kube-Proxy Version:            v1.5.2
ExternalID:                     centos-minion1
Non-terminated Pods:            (0 in total)
  Namespace                     Name            CPU Requests    CPU Limits      Memory Requests Memory Limits</p>

<hr />

<p>Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.
  CPU Requests  CPU Limits      Memory Requests Memory Limits</p>

<hr />

<p>  0 (0%)        0 (0%)          0 (0%)          0 (0%)
Events:
  FirstSeen     LastSeen        Count   From                            SubObjectPath   Type            Reason             Message</p>

<hr />

<p>  15m           15m             1       {kubelet centos-minion1}                        Normal          Starting           Starting kubelet.
  15m           15m             1       {kubelet centos-minion1}                        Warning         ImageGCFailed      unable to find data for container /
  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasSufficientDisk       Node centos-minion1 status is now: NodeHasSufficientDisk
  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasSufficientMemory     Node centos-minion1 status is now: NodeHasSufficientMemory
  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasNoDiskPressure       Node centos-minion1 status is now: NodeHasNoDiskPressure
  15m           15m             1       {kubelet centos-minion1}                        Warning         Rebooted           Node centos-minion1 has been rebooted, boot id: 20961efd-c946-481a-97cb-7788209551ae
```</p>

<p><strong>O</strong>bviamente recebemos um retorno com muitas informações em formato Json, o que nem sempre é como esperamos. Existem formas de filtrar os resultados e conseguir informações mais precisas, como o bom e velho grep:</p>

<p><code>
[root@kalib1 ~]# kubectl describe node centos-minion1 | grep Addresses
Addresses:              172.31.120.16,172.31.120.16,centos-minion1
</code></p>

<p><strong>V</strong>ocê também pode utilizar expressões regulares e a sintaxe do próprio Kubernetes para consultas mais complexas, como por exemplo, formatar a minha saída Json de forma a pegar apenas a listagem de status dos meus nodes que estão com Ready = True:</p>

<p>```
[root@kalib1 ~]# kubectl get nodes -o jsonpath=&lsquo;{range .items[<em>]}{@.metadata.name}:{range @.status.conditions[</em>]}{@.type}={@.status};{end}{end}&rsquo;| tr &lsquo;;&rsquo; &ldquo;\n&rdquo; | grep &ldquo;Ready=True&rdquo;</p>

<p>Ready=True
Ready=True
Ready=True
```</p>

<p><strong>A</strong> sua criatividade é o limite. ;]</p>

<p><strong>N</strong>ão temos nenhum pod configurado, mas também poderíamos utilizar <em>kubectl get</em> para conseguir a listagem de nossos pods:</p>

<p>```
[root@kalib1 ~]# kubectl get pods</p>

<p>No resources found.
```</p>

<h2>Criando pods</h2>

<p><strong>A</strong>ssim como com o Docker, Ansible e algumas outras ferramentas, utilizaremos a linguagem <a href="https://pt.wikipedia.org/wiki/YAML">YAML</a> para criar nossos arquivos de configuração.</p>

<p><strong>C</strong>riaremos um diretório chamado <em>Builds</em> em nosso Master Controller apenas para melhor organizar nossos arquivos de configuração e ficar mais fácil encontrá-los no futuro:</p>

<p>```</p>

<h1>mkdir Builds</h1>

<h1>cd Builds</h1>

<p>```</p>

<p><strong>P</strong>ara criarmos Pods, o que fazemos na verdade é criar arquivos de configuração que vão dizer ao Kubernetes qual o estado em que desejamos nossa infraestrutura. O papel do Kubernetes é ler esta configuração e assegurar que o estado de nossa infraestrutura reflita o estado desejado.</p>

<p><strong>P</strong>ara facilitar, vamos utilizar exemplos encontrados na própria documentação do Kubernetes. Comecemos com a criação de um Pod para um servidor web Nginx.</p>

<p><strong>V</strong>amos criar um arquivo chamado nginx.yaml dentro do diretório Builds que criamos anteriormente:</p>

<p>```</p>

<h1>vim nginx.yaml</h1>

<p>```</p>

<p><strong>N</strong>o arquivo indicaremos alguns atributos ou variáveis, bem como seus respectivos valores:</p>

<ul>
<li>apiVersion &ndash; Indica a versão da API do kubernetes utilizada</li>
<li>kind &ndash; o tipo de recurso que desejamos</li>
<li>metadata &ndash; dados referentes ao recurso desejado</li>
<li>spec &ndash; especificações sobre o que este recurso irá conter</li>
</ul>


<p><strong>V</strong>amos criar um Pod contendo um único container rodando a versão 1.7.9 do nginx bem como disponibilizando a porta 80 para receber conexões. Este deverá ser o conteúdo do arquivo <em>nginx.yaml</em>:</p>

<p>```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:</p>

<pre><code>- name: nginx
  image: nginx:1.7.9
  ports:
  - containerPort: 80
</code></pre>

<p>```</p>

<p><strong>A</strong>ntes de executarmos, vamos nos certificar novamente de duas coisas:</p>

<ul>
<li>Que realmente não temos nenhum Pod criado e ativo;</li>
<li>Que não temos nenhum container rodando em nossos nodes.</li>
</ul>


<p><em>No centos-master:</em></p>

<p>```
[root@kalib1 Builds]# kubectl get pods</p>

<p>No resources found.
```</p>

<p><em>No centos-minion1: (Execute o mesmo comando nos demais nodes (centos-minion2 e centos-minion3))</em></p>

<p>```
[root@kalib2 ~]# docker ps</p>

<p>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```</p>

<p><em>Novamente: Se você não faz ideia do que acabei de digitar, (docker ps) volte e leia um pouco sobre <a href="/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">Docker</a> antes de seguir com este artigo.</em></p>

<p><strong>C</strong>omo podemos ver, não temos nenhum Pod, bem como nenhum container rodando em nossos nodes.</p>

<p><strong>V</strong>amos utilizar <em>kubectl create</em> para criar o Pod utilizando o arquivo que criamos <em>nginx.yaml</em>: <em>Executaremos este comando no Master Controller &ndash; centos-master</em></p>

<p>```
[root@kalib1 Builds]# kubectl create -f nginx.yaml</p>

<p>pod &ldquo;nginx&rdquo; created
```</p>

<p><strong>O</strong> Kubernetes está dizendo que nosso Pod &ldquo;nginx&rdquo; foi criado. Vamos verificar:</p>

<p>```
[root@kalib1 Builds]# kubectl get pods</p>

<p>NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          1m
```</p>

<p><strong>O</strong> pod está criado e rodando. Agora, execute novamente <em>docker ps</em> nos 3 nodes para identificar em qual deles o container foi criado. Sim, como não especificamos nada, o Kubernetes vai verificar os recursos disponíveis no momento e vai lançar onde ele achar mais adequado.</p>

<p>```
[root@kalib4 ~]# docker ps</p>

<p>CONTAINER ID        IMAGE                                      COMMAND                  CREATED             STATUS              PORTS               NAMES
6de8e22e1536        nginx:1.7.9                                &ldquo;nginx -g &lsquo;daemon off&rdquo;   2 minutes ago       Up 2 minutes                            k8s_nginx.b0df00ef_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_583881e0
ae49b36ae11b        gcr.io/google_containers/pause-amd64:3.0   &ldquo;/pause&rdquo;                 2 minutes ago       Up 2 minutes                            k8s_POD.b2390301_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_fb5c834f
```</p>

<p><strong>S</strong>im, existem dois containers rodando. Um deles é o nosso &ldquo;nginx&rdquo;, enquanto que o outro é um container padrão do google chamado &ldquo;/pause&rdquo;, o qual será responsável pela manutenção de alguns recursos de nosso cluster.</p>

<p><strong>P</strong>odemos novamente pedir a descrição deste pod que acabamos de criar:</p>

<p>```
[root@kalib1 Builds]# kubectl describe pod nginx</p>

<p>Name:           nginx
Namespace:      default
Node:           centos-minion3/172.31.123.22
Start Time:     Sun, 25 Jun 2017 02:20:18 +0000
Labels:         <none>
Status:         Running
IP:             172.17.0.2
Controllers:    <none>
Containers:
  nginx:</p>

<pre><code>Container ID:               docker://6de8e22e153618271bb6e8095c68070126541331c8acfc3f5d1a654f4b978454
Image:                      nginx:1.7.9
Image ID:                   docker-pullable://docker.io/nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451
Port:                       80/TCP
State:                      Running
  Started:                  Sun, 25 Jun 2017 02:20:27 +0000
Ready:                      True
Restart Count:              0
Volume Mounts:              &lt;none&gt;
Environment Variables:      &lt;none&gt;
</code></pre>

<p>Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
No volumes.
QoS Class:      BestEffort
Tolerations:    <none>
Events:
  FirstSeen     LastSeen        Count   From                            SubObjectPath           Type            Reason     Message</p>

<hr />

<p>  6m            6m              1       {default-scheduler }                                    Normal          Scheduled  Successfully assigned nginx to centos-minion3
  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Pulling    pulling image &ldquo;nginx:1.7.9&rdquo;
  6m            6m              2       {kubelet centos-minion3}                                Warning         MissingClusterDNS   kubelet does not have ClusterDNS IP configured and cannot create Pod using &ldquo;ClusterFirst&rdquo; policy. Falling back to DNSDefault policy.
  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Pulled     Successfully pulled image &ldquo;nginx:1.7.9&rdquo;
  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Created    Created container with docker id 6de8e22e1536; Security:[seccomp=unconfined]
  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Started    Started container with docker id 6de8e22e1536
```</p>

<p><strong>O</strong>bviamente que isto é apenas a configuração mais básica que se possa imaginar, sem storage, mapeamentos de portas, redirecionamentos, rotas, etc. A ideia é apenas uma apresentação inicial..o que é o Kubernetes.</p>

<p><strong>H</strong>appy Hacking</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker - Uma alternativa elegante para containers no Linux]]></title>
    <link href="https://kalib.github.io/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/"/>
    <updated>2015-08-20T11:01:00-04:00</updated>
    <id>https://kalib.github.io/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/dockerlogo.png" title="&lsquo;Docker&rsquo;" ></p>

<p><strong>A</strong>ntes de falar sobre o Docker, é importante que se entenda o conceito de um container, portanto vamos começar do básico. A imagem acima, logomarca do Docker, deixa claro o que é um container. A baleia, representando um navio, carregando diversos caixotes ou containers ilustra o conceito físico de um container. Nada mais do que um enorme caixote que possui o intuito de isolar algo. Quando um grande navio transporta mercadorias de um porto para outro, ele costuma trazer diversos containers separando estas mercadorias, de forma que as coisas não fiquem misturadas e bagunçadas. A forma de separação vai depender dos critérios de organização utilizados pela embarcação, seja por proprietário, seja por categoria de produtos, etc. De qualquer forma, embora cada container possua seus elementos próprios, todos os containers compartilham alguns recursos básicos, como por exemplo a embarcação, que é o meio de transporte para todos os containers ali contidos.</p>

<p><strong>D</strong>a mesma forma se dá no mundo dos computadores, onde o conceito de containers surgiu para separar e isolar alguns recursos e aplicações, otimizando os recursos que servem como base e que podem ser utilizados de forma compartilhada, como por exemplo o kernel do Sistema Operacional. De certa forma isto nos faz lembrar um pouco da virtualização, onde cada máquina virtual compartilha os recursos da máquina física, no entanto existe uma diferença clara no contexto de containers, visto que em um cenário de virtualização você precisará possuir um SO instalado na máquina física, com seu kernel e todos os seus recursos, e um SO instalado em sua máquina virtual, também com seu kernel e todos os seus recursos. Quando falamos em containers, imagine que você só precisará do kernel, bem como vários outros recursos, na máquina que será a hospedeira do container (a embarcação).</p>

<p><strong>C</strong>ontainers Linux surgiram como uma tecnologia chave para empacotamento e entrega de aplicativos, combinando a leveza do isolamento de aplicativos com a flexibilidade de métodos de deploy baseados em imagens.</p>

<p><strong>U</strong>ma das formas mais simples de se imaginar a vantagem da utilização de containers é imaginar que você possui uma empresa que hospeda servidores de aplicações para seus clientes. Se um novo cliente surge querendo hospedar a aplicação dele, você subirá uma nova máquina virtual, o que inclui todo um novo sistema operacional, enquanto que em uma solução baseada em containers você poderá ter apenas a sua máquina com um único kernel Linux provendo as priorizações de recursos (CPU, memória, I/O, rede, etc.) sem a necessidade de dar boot em um novo sistema operacional (máquinia virtual) na qual rodará a aplicação deste cliente.</p>

<p><strong>D</strong>izem que uma imagem vale mais que mil palavras&hellip;</p>

<p><img class="center" src="/imgs/docker_vmdiagram.png" title="&lsquo;Virtual Machine Diagram&rsquo;" ></p>

<p><strong>N</strong>a imagem acima temos o cenário convencional com a utilização de <strong>Máquinas Virtuais</strong>. Em suma, temos um host físico, com seu respectivo SO e kernel. Acima deles temos a camada de virtualização ou HyperVisor, enquanto que acima desta teremos as máquinas virtuais, com seus respectivos SOs (cada um com seu kernel) instalados. No caso temos 3 VMs, com 3 SOs (cada um com seu kernel). Na camada acima encontramos o que realmente é necessário para o app do cliente funcionar, que são as bibliotecas e os binários. Por fim, o App do cliente em si.</p>

<p><strong>V</strong>ejamos como fica o cenário com a utilização de containers, docker neste caso&hellip;</p>

<p><img class="center" src="/imgs/docker_diagram.png" title="&lsquo;Docker Diagram&rsquo;" ></p>

<p><strong>N</strong>o cenário com o Docker percebemos que a camada de SO das VMs sumiu, visto que ela não é mais necessária. Ao invés de Máquinas Virtuais, agora nós temos 3 containers, onde cada container roda os binários e bibliotecas de um SO, porém se aproveitando do kernel já existente no Host.</p>

<p><strong>C</strong>om este grau de modularização nós ganhamos maior flexibilidade e agilidade no deploy de ambientes e aplicações.</p>

<p><strong>U</strong>ma das vantagens da utilização do Docker é a existência de um repositório de imagens prontas que ficam disponibilizadas livremente para quem desejar utilizar. Seja uma imagem pronta de um container com CentOS, Ubuntu, etc.. Já existem centenas e centenas de imagens prontas para uso, sendo esta uma base de compartilhamento comunitário, mas&hellip;</p>

<p><strong>V</strong>amos ao que interessa&hellip;</p>

<p><strong>N</strong>os exemplos a seguir, estou utilizando o Ubuntu Server 15.04, visto que estou atualmente realizando uma POC de VPS com um novo host, portanto aproveitarei para fazer disto uma parte de meus testes nesta VPS. Sinta-se livre para utilizar sua máquina física com Ubuntu, com Debian, ou mesmo uma máquina virtual, caso não goste de realizar testes em sua máquina física, o resultado será o mesmo. Para que tudo funcione como esperamos, só existem 2 pré-requisitos a serem atendidos:</p>

<p>1- O kernel do Linux que será utilizado deve ser igual ou superior ao 3.8;</p>

<p>2- Caso você esteja realizando os testes em uma VM, seria interessante que sua máquina física tivesse comunicação com a VM. Isso pode ser testado com um ping da máquina física para a VM. No caso de sua máquina virtual ser instalada com interface gráfica, esta comunicação não será necessária, pois o único momento em que utilizaremos isto será para abrir um navegador e fazer um teste de acesso ao endereço da máquina virtual.</p>

<p><strong>V</strong>amos lá. Para ter a certeza de que você atende o pré-requisito de kernel, utilize o comando &ldquo;uname -r&rdquo;:</p>

<p><code>
 kalib@cloudcaverna:~$ uname -r
 3.19.0-25-generic
</code></p>

<p><strong>E</strong>stou com o kernel 3.19, portanto superior ao kernel 3.8 que é o pré-requisito mínimo. Vamos em frente.</p>

<p><strong>P</strong>rimeiramente, vamos instalar o Docker. Seja lá qual for sua distribuição Linux, digite o comando: <strong>(O comando deve ser executado com o usuário root ou com o comando sudo!)</strong></p>

<p><code>
 # curl -sSL https://get.docker.com | sh
</code></p>

<p><strong>E</strong>le baixará e executará um script de instalação, no meu caso do Ubuntu ele irá instalar um repositório e em seguida instalará o docker. O próximo passo será iniciar o serviço do docker:</p>

<p><code>
 # /etc/init.d/docker start
 [ ok ] Starting docker (via systemctl): docker.service.
</code></p>

<p><strong>O</strong> docker possui uma série de scripts/comandos próprios para facilitar a sua administração, como por exemplo um script de <strong>ps</strong>, para que possamos ter a certeza de que ele está rodando e, além disso, saber se existem containers em execução, da mesma forma que faríamos com o ps do linux para ver os processos em andamento.</p>

<p>```
 # docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```</p>

<p><strong>P</strong>odemos ver que o docker está rodando, no entanto nenhum container está em execução. Na verdade, não temos nenhum container criado, portanto obviamente não poderia estar em execução.</p>

<p><strong>A</strong>lém do ps, podemos utilizar o script <strong>images</strong> para ver quais imagens de containers já possuímos para uso:</p>

<p>```
 # docker images</p>

<p> REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
```</p>

<p><strong>D</strong>a mesma forma, não temos ainda nenhuma imagem baixada para uso.</p>

<p><strong>U</strong>ma vez que estamos falando de containers, conforme dito anteriormente, a ideia é isolar ao máximo e otimizar o que precisamos para este container, portanto precisamos informar o processo que desejamos iniciar no container em questão.</p>

<p><strong>V</strong>amos criar um container do Ubuntu, por exemplo, na versão 15.04, lançada em Abril deste ano, e vamos iniciar juntamente com ele o processo /bin/bash. O comando utilizado será: docker run -i -t ubuntu:15.04 /bin/bash</p>

<p>```
 # docker run -i -t ubuntu:15.04 /bin/bash</p>

<p> Unable to find image &lsquo;ubuntu:15.04&rsquo; locally
 15.04: Pulling from library/ubuntu</p>

<p> 6e6a100fa147: Pull complete
 13c0c663a321: Pull complete
 2bd276ed39d5: Pull complete
 013f3d01d247: Already exists
 library/ubuntu:15.04: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.</p>

<p> Digest: sha256:b2d4940544e515d4bc62b2a9ad3e6137b3e1e0937a41fdc1f0f30d12935e5b09
 Status: Downloaded newer image for ubuntu:15.04</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>É</strong> importante reparar que na primeira linha de execução ele me trouxe um alerta informando que não foi possível encontrar a imagem &ldquo;ubuntu:15.04&rdquo; localmente. Como disse acima, não temos ainda nenhuma imagem baixada, portanto ele não encontrou localmente e foi baixar diretamente no repositório de imagens do docker.</p>

<p><strong>O</strong> procedimento foi extremamente rápido, certo? Acredite ou não, você já possui um container Ubuntu rodando em sua máquina. ;] Ainda não acredita? Repare novamente no seu prompt de comandos, veja que logo que ele finalizou o processo ele lhe deixou em um prompt &ldquo;estranho&rdquo;. No caso do meu exemplo acima, perceba que ao concluir o processo ele me deixou com o prompt assim:</p>

<p><code>
 root@d70562e7533c:/#
</code></p>

<p><strong>N</strong>ão, minha máquina não se chama d70562e7533c. Tenho certeza de que a sua também não se chama.. seja lá qual for a combinação de caracteres que lhe foi apresentada no prompt. Na verdade, sempre que iniciamos um container, o comportamento default é que você já é logado nele. Em suma, seu container com ubuntu 15.04 já foi criado e você já está logado nele, e esta combinação de caracteres estranha é o ID que foi dado ao seu container.</p>

<p><strong>A</strong>inda não acredita? Bom, você pode, por exemplo, dar um <strong>cat /etc/issue</strong>, para ver que você está de fato rodando um ubuntu 15.04. Claro, no meu caso não haverá diferença, pois minha máquina que está rodando o docker também é ubuntu 15.04.</p>

<p>```
 root@d70562e7533c:/# cat /etc/issue</p>

<p> Ubuntu 15.04 \n \l</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>O*utro teste, seria rodar </strong>ps -ef** no container. Você verá que não existe nenhum processo rodando. Aliás, haverá apenas 1 processo (além do próprio ps), que foi o processo indicado na criação: /bin/bash. Desta forma você terá a certeza de que não está no prompt de sua máquina mesmo, visto que na sua certamente existem dezenas ou centenas de processos rodando, do kernel, do usuário, etc.</p>

<p>```
 root@d70562e7533c:/# ps -ef</p>

<p> UID        PID  PPID  C STIME TTY          TIME CMD
 root         1     0  0 13:36 ?        00:00:00 /bin/bash
 root         9     1  0 13:44 ?        00:00:00 ps -ef</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>D</strong>a mesma forma você poderá experimentar outros comandos para testar (caso ainda não esteja acreditando que de forma tão &ldquo;oi, simples assim&rdquo; você já está com seu container pronto): ls, apt-get update, etc.. Tudo funcionando como se fosse uma máquina real, ou virtual, no entanto sem um kernel, visto que ela está utilizando o kernel da máquina host.</p>

<p><strong>A</strong>gora que temos a certeza de que estamos em nosso container, você pode sair do container e voltar para sua máquina host. Para isso você precisará pressionar as teclas <strong>Ctrl + P + Q</strong>. Desta forma, você verá que seu prompt voltará para seu host enquanto que seu container continuará rodando, você apenas saiu do prompt do mesmo.</p>

<p>```
 root@d70562e7533c:/# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>V</strong>amos verificar novamente o ps do docker, visto que da última vez ele estava vazio. Desta vez ele nos mostrará um processo em execução, que no caso é o container que criamos.</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
 d70562e7533c        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         15 minutes ago      Up 15 minutes                           modest_khorana
```</p>

<p><strong>N</strong>o retorno podemos ver o ID do nosso container, o nome da imagem que ele utiliza, o comando em execução, o tempo desde sua criação, o seu status, portas e nome.</p>

<p><strong>O</strong> container ID poderá ser utilizado para voltar para nosso container através do comando <strong>docker attach &lt;container-id></strong>: (Após digitar o comando, pressione novamente Enter para liberar o prompt)</p>

<p>```
 root@cloudcaverna:~# docker attach d70562e7533c</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>N</strong>o exemplo anterior nós utilizamos a combinação <strong>Ctrl + P + Q</strong> para sair do container mantendo-o rodando. Vamos experimentar utilizar desta vez <strong>Ctrl + D</strong>. Desta forma você não apenas está saindo mas também desligando o container. Execute novamente a lista de processos/containers do docker para ver:</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```</p>

<p><strong>N</strong>o entanto, é importante lembrar que a imagem do Ubuntu 15.04 que baixamos, continua disponível para o caso de precisarmos criar novos containers Ubuntu 15.04:</p>

<p>```
 root@cloudcaverna:~# docker images</p>

<p> REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
 ubuntu              15.04               013f3d01d247        17 hours ago        131.4 MB
```</p>

<p><strong>S</strong>imples&hellip; Mas vamos fazer algo mais próximo do mundo real, afinal um container apenas com o Ubuntu rodando, ou qualquer outra que seja a distribuição escolhida, não tem muita utilidade, portanto vamos criar um container rodando um servidor web, para o caso de querermos hospedar um site ou aplicalção web neste container. Por ser mais leve e simples, vou utilizar o nginx no exemplo. Vamos utilizar o comando <strong>docker run -i -t -p 8080:80 ubuntu:15.04 /bin/bash</strong></p>

<p><strong>N</strong>o comando acima estamos dizendo que queremos criar um novo container ubuntu 15.04 rodando o /bin/bash. Desta vez temos um parâmetro que não utilizamos anteriormente. O <strong>p</strong> serve para indicar a utilização de portas. Quando utilizamos <strong>p 8080:80</strong> estamos dizendo que vamos utilizar a porta 80 no container e que ela estará mapeada na porta 8080 do nosso host ou hospedeiro. Ou seja, quando instalarmos o Nginx no ubuntu do container, você poderá através de seu host abrir o navegador e acessar o seu endereço ip ou nome de host (caso você possua resolução de nomes funcionando) na porta 8080.</p>

<p>```
 root@cloudcaverna:~# docker run -i -t -p 8080:80 ubuntu:15.04 /bin/bash</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>O</strong> processo foi bem mais rápido desta vez, visto que já tínhamos a imagem do container ubuntu 15.04, portanto não tivemos a necessidade de baixar outra imagem. O seu container já está criado e você já está logado no prompt do mesmo, conforme pode ver através do ID do container que apareceu em seu prompt.</p>

<p><strong>V</strong>amos agora instalar o servidor web nginx para realizarmos o nosso teste. Para isso vamos atualizar os repositórios e em seguida instalar o pacote: <strong>apt-get update &amp;&amp; apt-get install -y nginx</strong></p>

<p>```
 root@08abb8611700:/# apt-get update &amp;&amp; apt-get install -y nginx</p>

<p> Ign <a href="https://archive.ubuntu.com">https://archive.ubuntu.com</a> vivid InRelease
 Ign <a href="https://archive.ubuntu.com">https://archive.ubuntu.com</a> vivid-updates InRelease
 Get:1 <a href="https://archive.ubuntu.com">https://archive.ubuntu.com</a> vivid/main Sources [1358 kB]
 Get:2 <a href="https://archive.ubuntu.com">https://archive.ubuntu.com</a> vivid/restricted Sources [7100 B]
 &hellip;
 Building dependency tree     <br/>
 Reading state information&hellip; Done
 The following extra packages will be installed:
  fontconfig-config fonts-dejavu-core geoip-database init-system-helpers libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu52
  libjbig0 libjpeg-turbo8 libjpeg8 libpng12-0 libssl1.0.0 libtiff5 libvpx1 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4
  libxslt1.1 nginx-common nginx-core sgml-base ucf xml-core
 Suggested packages:
  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert sgml-base-doc debhelper
 The following NEW packages will be installed:
  fontconfig-config fonts-dejavu-core geoip-database init-system-helpers libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu52
  libjbig0 libjpeg-turbo8 libjpeg8 libpng12-0 libssl1.0.0 libtiff5 libvpx1 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4
  libxslt1.1 nginx nginx-common nginx-core sgml-base ucf xml-core
 0 upgraded, 31 newly installed, 0 to remove and 0 not upgraded.
 Need to get 14.0 MB of archives.
 After this operation, 53.3 MB of additional disk space will be used.
 &hellip;
 Get:1 <a href="https://archive.ubuntu.com/ubuntu/">https://archive.ubuntu.com/ubuntu/</a> vivid/main libexpat1 amd64 2.1.0-6ubuntu1 [70.6 kB]
 Processing triggers for systemd (219-7ubuntu6) &hellip;</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>C</strong>ortei bastante a saída visto ser desnecessária, mas uma vez que o nginx esteja instalado, vamos iniciá-lo: <strong>/etc/init.d/nginx start</strong>. Em seguida, vamos utilizar o ps para ver os processos que estão rodando no nosso container:</p>

<p>```
 root@08abb8611700:/# /etc/init.d/nginx start</p>

<p> root@08abb8611700:/# ps -ef</p>

<p> UID        PID  PPID  C STIME TTY          TIME CMD
 root         1     0  0 14:10 ?        00:00:00 /bin/bash
 root       609     1  0 14:19 ?        00:00:00 nginx: master process /usr/sbin/nginx
 www-data   610   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   611   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   612   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   613   609  0 14:19 ?        00:00:00 nginx: worker process
 root       614     1  0 14:19 ?        00:00:00 ps -ef</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>F</strong>eito isto, o serviço está rodando e já pode ser testado. Em seu host você poderá abrir o navegador e acessar o endereço local de seu host, com a porta 8080, visto que foi esta que definimos inicialmente para mapear a porta 80 do container: <strong>localhost:8080</strong></p>

<p><strong>C</strong>aso esteja utilizando uma máquina virtual para fazer seus testes, você terá duas possibilidades:
1- Caso sua máquina virtual possua alguma interface gráfica instalada, você poderá abrir o navegador da própria VM e acessar o mesmo endereço de localhost com a porta 8080;
2- Caso sua VM não esteja com nenhum ambiente gráfico instalado, você poderá utilizar aplicações de CLI para testar (ex: lynx, curl, etc.) ou usar o navegador da máquina que serve de host para sua VM, levando em conta que você fez o teste descrito no início para ter certeza de que sua máquina física consegue se comunicar com sua VM. Neste caso, em sua máqunina física você acessará o endereço de sua vm no navegador, com a porta 8080.</p>

<p><strong>R</strong>esultado? O Nginx em nosso container rodando perfeitamente.</p>

<p><img class="center" src="/imgs/docker_nginx8080.png" title="&lsquo;Nginx on Docker&rsquo;" ></p>

<p><strong>D</strong>a mesma forma feita anteriormente, podemos sair de nosso container com a combinação de teclas <strong>Ctrl + P + Q</strong> e verificar os processos/containers do docker em execução:</p>

<p>```
 root@08abb8611700:/# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         19 minutes ago      Up 19 minutes       0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>É</strong> importante salientar que quando saímos do container com a combinação <strong>Ctrl + P + Q</strong> nós não estamos fechando o container, pois ele continua rodando, conforme pode ser visto com <strong>docker ps</strong>. No entanto, quando saímos do nosso antigo container com a combinação <strong>Ctrl + D</strong>, nós percebemos que ele finalizou de vez o container. Além de finalizar, ele excluiu o nosso container, visto que o mesmo não foi salvo, ou &ldquo;comittado&rdquo;. Se sairmos deste container no qual instalamos o nginx utilizando <strong>Ctrl + D</strong>, nós estaremos descartando tudo o que foi feito nele. Para poder finalizar o seu container sem perdê-lo, ou seja, mantendo o container salvo e tudo o que foi instalado/configurado nele, nós precisamos sair do container com a combinação <strong>Ctrl + P + Q</strong>, conforme fizemos acima, e em seguida realizar um commit deste container. Estaremos então criando uma imagem com o atual estado do container. Desta forma, se posteriormente precisarmos subir um novo container que rode o SO ubuntu 15.04 e que também possua o nginx, poderemos criar um novo container a partir desta imagem em poucos segundos. O commit se dá da seguinte forma: <strong>docker commit &lt;container-id> &lt;nome-que-vc-desejar></strong></p>

<p><strong>L</strong>embrando que o id do container pode ser conseguido através do comando <strong>docker ps</strong> e que o <strong>nome-que-vc-desejar</strong> será o nome utilizado para identificar esta sua máquina/imagem.</p>

<p>```
 root@cloudcaverna:~# docker commit 08abb8611700 cloudcaverna/ubuntu-nginx:1.0</p>

<p> b0922bc8f41295cadadbd131c075e29288b52e8bb2d9546cb7c0327eb95fe7dc</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>U</strong>tilizei 1.0 ao final para ter uma ideia de versionamento, visto que o docker nos permite trabalhar desta forma. É uma questão de organização.</p>

<p><strong>E</strong>m seguida você pode verificar sua imagem criada através do script <strong>images</strong> do docker, bem como o seu container ainda rodando através do script <strong>ps</strong>:</p>

<p>```
 root@cloudcaverna:~# docker images</p>

<p> REPOSITORY                  TAG                 IMAGE ID            CREATED              VIRTUAL SIZE
 cloudcaverna/ubuntu-nginx   1.0                 b0922bc8f412        About a minute ago   204.6 MB
 ubuntu                      15.04               013f3d01d247        18 hours ago         131.4 MB</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         49 minutes ago      Up 49 minutes       0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>V</strong>amos agora criar um novo container. Aqui você pode escolher como prosseguir. Eu criarei um container com a distribuição Arch Linux rodando, mas você pode seguir e criar outra com o Ubuntu caso deseje, então vejamos as opções:</p>

<p><strong>Opção 1 &ndash; Caso escolha criar este segundo container como Arch Linux</strong></p>

<p>```
 root@cloudcaverna:~# docker run -i -t -p 6660:80 base/archlinux /bin/bash</p>

<p> Unable to find image &lsquo;base/archlinux:latest&rsquo; locally
 latest: Pulling from base/archlinux</p>

<p> b31c6c1462e6: Pull complete
 b97e110c94d9: Already exists
 Digest: sha256:7905fad7578b9852999935fb0ba9c32fe16cece9e4d1d742a34f55ce9cebdfd1
 Status: Downloaded newer image for base/archlinux:latest</p>

<p> [root@be266bf7e5a3 /]#</p>

<p>```</p>

<p><strong>Opção 2 &ndash; Caso deseje criar um novo container Ubuntu aproveitando a imagem que já está pronta e com nginx já instalado</strong></p>

<p><code>
 docker run -i -t -p 6660:80 &lt;nome-que-vc-deu-para-sua-imagem&gt;
</code></p>

<p>Como eu dei o nome de <em>cloudcaverna/ubuntu-nginx</em>, eu utilizaria <em>docker run -i -t -p 6660:80 cloudcaverna/ubuntu-nginx</em>.</p>

<p>Desta forma você não precisará sequer instalar o nginx novamente neste container, visto que você utilizou como base uma imagem que já possuía o nginx instalado, restando apenas a você testar no navegador novamente o endereço porém trocando a porta para 6660.</p>

<p><strong>C</strong>omo eu resolvi seguir em frente com um container totalmente novo, baseado no Arch Linux, vou dar um <strong>cat /etc/issue</strong> para ver que realmente estou em um ambiente com a distribuição Arch Linux e vou instalar o nginx nele com o pacman, visto que este é o gerenciador de pacotes do Arch:</p>

<p>```
 [root@be266bf7e5a3 /]# cat /etc/issue</p>

<p> Arch Linux \r (\l)</p>

<p> [root@be266bf7e5a3 /]# pacman -Sy nginx</p>

<p> :: Synchronizing package databases&hellip;
 core                                                        121.2 KiB   203K/s 00:01 [#################################################] 100%
 extra                                                      1773.8 KiB   644K/s 00:03 [#################################################] 100%
 community                                                     2.7 MiB   936K/s 00:03 [#################################################] 100%
 resolving dependencies&hellip;
 looking for inter-conflicts&hellip;</p>

<p> Packages (1): nginx-1.8.0-1</p>

<p> Total Download Size:    0.34 MiB
 Total Installed Size:   0.98 MiB</p>

<p> :: Proceed with installation? [Y/n]
 :: Retrieving packages &hellip;
 nginx-1.8.0-1-x86_64                                        349.5 KiB   266K/s 00:01  [#################################################] 100%
 (1/1) installing nginx                                                                [ #################################################] 100%</p>

<p> [root@be266bf7e5a3 /]#
```</p>

<p><strong>A</strong>gora que estou com o nginx rodando também neste container do Arch Linux, vou sair do container pressionando a combinação <strong>Ctrl + P + Q</strong> e em seguida rodar o script de <strong>ps</strong> do docker:</p>

<p>```
 [root@be266bf7e5a3 /]# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 be266bf7e5a3        base/archlinux      &ldquo;/bin/bash&rdquo;         10 minutes ago      Up 10 minutes       0.0.0.0:6660->80/tcp   cocky_hoover
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         About an hour ago   Up About an hour    0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
 ```</p>

<p> <strong>D</strong>esta vez eu possuo dois containers criados, sendo um com o ubuntu 15:04 e outro com o Arch Linux. Agora vou realizar o commit do meu container Arch Linux com nginx, para não perder esta imagem. Em seguida, executarei o script <strong>images</strong> para ver as imagens que já possuo:</p>

<p> ```
  root@cloudcaverna:~# docker commit be266bf7e5a3 cloudcaverna/archlinux-nginx:1.0</p>

<p> f4ea14bf23c47466fb256fff9e3ab32ca85fb0256a05007ef4972ad7ff5f2aa9</p>

<p> root@cloudcaverna:~# docker images</p>

<p> REPOSITORY                     TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
 cloudcaverna/archlinux-nginx   1.0                 f4ea14bf23c4        5 seconds ago       285.9 MB
 cloudcaverna/ubuntu-nginx      1.0                 b0922bc8f412        20 minutes ago      204.6 MB
 ubuntu                         15.04               013f3d01d247        18 hours ago        131.4 MB
 base/archlinux                 latest              b97e110c94d9        8 weeks ago         278.8 MB</p>

<p> root@cloudcaverna:~#
```
<strong>A</strong>gora vou testar no navegador o nginx deste meu segundo container, o qual defini que utilizaria a porta 6660 do meu host:</p>

<p><img class="center" src="/imgs/docker_nginx6660_8080.png" title="&lsquo;Nginx on Docker&rsquo;" ></p>

<p><strong>R</strong>epare que acessei ambos os endereços, tanto o da porta 8080, o qual está apresentando o nginx do meu primeiro container, quanto o da porta 6660, que apresenta o nginx do meu segundo container. Ambos funcionando em paralelo, com ambientes distintos, sendo um Ubuntu e o outro Arch Linux, porém ambos compartilham o mesmo kernel, que é o do meu host.</p>

<p><strong>O</strong> próprio script <strong>ps</strong> do docker lhe informa as portas que estão sendo utilizadas para cada container, caso você esteja em dúvida:</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 be266bf7e5a3        base/archlinux      &ldquo;/bin/bash&rdquo;         26 minutes ago      Up 26 minutes       0.0.0.0:6660->80/tcp   cocky_hoover
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         About an hour ago   Up About an hour    0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>D</strong>a mesma forma, você poderá fazer toda e qualquer operação que você faria em uma máquina qualquer, como por exemplo monitorar os logs de acesso do nginx. Basta se conectar em algum dos dois containers com <strong>docker attach &lt;container-id></strong> e em seguida abrir o arquivo de log do nginx com o tail: <strong>tail -f /var/log/nginx/access.log</strong>. Com o log rodando, pode acessar novamente no navegador o endereço com a porta que está mapeada para este container e você verá os logs do seu acesso.</p>

<p><strong>A</strong>nteriormente nós vimos que com a combinação <strong>Ctrl + P + Q</strong> eu consigo sair do container porém ele permanecerá rodando. Com <strong>Ctrl + D</strong> eu finalizava o container de vez. Mas, supondo que eu queira parar temporariamente o container, posso utilizar o script <strong>stop</strong> do container inserindo o id do container que desejo parar:</p>

<p>```
 root@cloudcaverna:~# docker stop be266bf7e5a3
 be266bf7e5a3</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>E</strong>xiste ainda uma forma de ver o que foi alterado no container desde sua criação. É literalmente uma espécie de &ldquo;diff&rdquo;:</p>

<p><code>
 root@cloudcaverna:~# docker diff 08abb8611700
 C /.wh..wh.plnk
 A /.wh..wh.plnk/93.1190648
 C /bin
 A /bin/running-in-container
 A /core
 C /etc
 C /etc/default
 A /etc/default/nginx
 A /etc/fonts
 A /etc/fonts/conf.avail
 A /etc/fonts/conf.avail/10-antialias.conf
 A /etc/fonts/conf.avail/10-autohint.conf
 A /etc/fonts/conf.avail/10-hinting-full.conf
 A /etc/fonts/conf.avail/10-hinting-medium.conf
 A /etc/fonts/conf.avail/10-hinting-slight.conf
 A /etc/fonts/conf.avail/10-hinting.conf
 A /etc/fonts/conf.avail/10-no-sub-pixel.conf
 A /etc/fonts/conf.avail/10-scale-bitmap-fonts.conf
 A /etc/fonts/conf.avail/10-sub-pixel-bgr.conf
 A /etc/fonts/conf.avail/10-sub-pixel-rgb.conf
 A /etc/fonts/conf.avail/10-sub-pixel-vbgr.conf
 A /etc/fonts/conf.avail/10-sub-pixel-vrgb.conf
 A /etc/fonts/conf.avail/10-unhinted.conf
 A /etc/fonts/conf.avail/11-lcdfilter-default.conf
 A /etc/fonts/conf.avail/11-lcdfilter-legacy.conf
 A /etc/fonts/conf.avail/11-lcdfilter-light.conf
 ...
 ...
</code></p>

<p><strong>A</strong> saída é extensa, portanto cortei aqui mesmo, mas você terá basicamente todo o diff do que foi alterado desde a criação do container.</p>

<p><strong>R</strong>esumidamente, esta é a função do docker. Com criatividade e disposição se faz muita coisa com ele. Não é a toa que os big players de mercado já estão utilizando bastante esta ferramenta para soluções de container, como por exemplo: Amazon, Apcera, Cisco, CoreOS, Datera, VMWare, Verizon Labs, Red Hat, Google, RackSpace, Oracle, IBM, Intel, Microsoft, HP, etc.</p>

<p><strong>L</strong>embrando que o endereço de repositórios com as imagens já existentes e disponibilizadas gratuitamente é <a href="https://hub.docker.com">https://hub.docker.com</a></p>

<p><strong>A</strong>té a próxima&hellip;</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
</feed>
