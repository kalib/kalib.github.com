<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Seguranca | Marcelo Cavalcante Rocha ~]]></title>
  <link href="http://kalib.github.io/blog/categories/seguranca/atom.xml" rel="self"/>
  <link href="http://kalib.github.io/"/>
  <updated>2018-04-01T16:56:26-04:00</updated>
  <id>http://kalib.github.io/</id>
  <author>
    <name><![CDATA[Marcelo Cavalcante Rocha - Kalib]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Recebendo Alarmes do AWS Diretamente no Slack]]></title>
    <link href="http://kalib.github.io/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack/"/>
    <updated>2017-03-11T12:03:00-05:00</updated>
    <id>http://kalib.github.io/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/aws_slack.png" title="&lsquo;AWS_Slack&rsquo;" ></p>

<p><strong>A</strong>ntes de entrar na configuração dos serviços, talvez seja necessário apresentar o <a href="http://www.slack.com">Slack</a>, visto que muitos ainda não conhecem ou utilizam esta poderosa e versátil ferramenta de comunicação instantânea para times.</p>

<p><strong>S</strong>lack é uma plataforma para comunicação entre times que desejam um ambiente mais dinâmico e ágil. Diferentemente de muitas plataformas de chat disponíveis, como o Google Hangouts, o Slack nos permite criar canais distintos com membros distintos de um mesmo time fazendo parte daquele canal específico. Não, não estou falando de chat em grupo, mas sim canais específicos que permitem integrações com serviços distintos, como receber notificações sobre commits feitos em um repositório ou branch específico no github, notificações de tickets abertos em ferramentas como o Jira, por exemplo, etc. O Slack é completamente programável e escalável, o que nos permite ter inúmeras funcionalidas.</p>

<p><strong>P</strong>rovavelmente não seja necessário apresentar o AWS, ou Amazon Web Services, visto que já está no mercado desde 2006, no entanto cabe um resumo para os que não estão familiarizados com o mesmo (embora o público alvo deste post seja quem já possui alguma familiaridade com AWS).</p>

<p><strong>A</strong>ws ou Amazon Web Services é uma plataforma de serviços em nuvem segura, oferecendo poder computacional, armazentamento de banco de dados, distribuição de conteúdo e outras funcionalidades.</p>

<p><strong>P</strong>or que eu deveria ter alarmes e notificações do AWS em um serviço de chat como o Slack quando já recebo estas notificações por email?</p>

<p><strong>É</strong> verdade que o uso mais comum para envio de alarmes e notificações do AWS costuma ser via email, no entanto fica fácil identificar alguns problemas com este método. O principal e mais recorrente que vejo é o caso de as notificações caírem em um email específico visto por poucas pessoas (na maioria das vezes) ou nem visto sequer, pois geralmente as pessoas ficam cansadas de olhar notificações e ter sua caixa de entrada entupida com eles portanto criam filtros que jogam os emails de notificação para um diretório que dificilmente será checado.</p>

<p><strong>O</strong>utro problema comum com esta prática é a demora até que alguém leia a notificação no meio de tantos outros na pasta ou filtro criado e, muitas vezes, quando se vê a notificação, o problema já está aguardando uma solução há horas.</p>

<p><strong>D</strong>eixando claro, não estou defendendo a ideia de abolir as notificações por email. Eu mesmo utilizo ambos, afinal o email continua bastante eficiente para fins de armazenamento e checagem histórica, por exemplo.</p>

<p><strong>U</strong>ma vez que nos dias atuais os times de TI estão cada vez mais unificados e dinâmicos, buscando incorporar uma mentalidade DevOps e Agile, a comunicação rápida e eficiente se torna um fator primordial para o sucesso de qualquer projeto. Ter um local centralizado para conversar com os demais membros do time, trocar arquivos, detalhes de projetos, receber notificações de commits, prazos, tickets, documentação e, por que não, notificações de monitoramento e alarmes, torna-se essencial.</p>

<p><strong>V</strong>amos então entender como funcionaria uma solução para enviar as notificações e alarmes do AWS para o Slack.</p>

<p><strong>O</strong> que utilizaremos:</p>

<ol>
<li>No Slack:

<ul>
<li>Um plugin ou Slack App chamado <strong>Incoming WebHooks</strong></li>
<li>O nome de um canal para envio das notificações</li>
</ul>
</li>
<li>No AWS:

<ul>
<li>Serviço <strong>SNS Topic</strong></li>
<li>Serviço <strong>CloudWatch</strong></li>
<li>Serviço <strong>Lambda Function</strong></li>
</ul>
</li>
</ol>


<p><strong>V</strong>amos lá&hellip;</p>

<p><strong>Slack</strong></p>

<p><strong>V</strong>amos começar escolhendo o canal no Slack no qual desejo receber a minha notificação ou alarme: #devops</p>

<p><em>Estou supondo que você já utiliza o Slack e já possui um time criado no mesmo. Caso ainda não, crie um time no Slack seguindo os passos descritos no <a href="https://slack.com/">site oficial</a> antes de seguir em frente&hellip; ;]</em></p>

<p><strong>O</strong> próximo passo é configurar a integração instalando o Plugin ou Slack App <strong>Incoming WebHooks</strong>. Para isto, acesse a página de apps de seu time no Slack: <a href="https://SEUTIME.slack.com/apps">https://SEUTIME.slack.com/apps</a></p>

<p><strong>P</strong>esquise por Incoming WebHooks e você terá apenas um resultado, portanto clique sem medo.</p>

<p><img class="center" src="/imgs/slack1.png" title="&lsquo;Incoming WebHook&rsquo;" ></p>

<p><strong>C</strong>lique no pequeno lápis que se encontrará no canto direito para editar as configurações do Incoming WebHook. Os únicos campos que precisaremos editar neste momento são os seguintes:
  * Post to Channel &ndash; Aqui indicarei o meu canal: #devops
  * Customize Name &ndash; Aqui indicarei um nome qualquer: AWS-Alerts</p>

<p><strong>Importante:</strong> Repare que nesta página de configurações ele lhe passará uma entrada ou URL com o código para o seu WebHook. Esta informação estará listada em <strong>Webhook URL</strong> e será algo como: *<a href="https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.">https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.</a> Copie esta informação em algum local de fácil acesso pois precisaremos desta URL para a configuração que faremos a seguir no AWS.</p>

<p><strong>S</strong>alve suas configurações e vamos configurar os serviços do AWS para que nosso WebHook possa receber as informações devidamente.</p>

<p><strong>Amazon Web Services</strong></p>

<p><strong>S</strong>e você já possui alguma familiaridade com o AWS, sabe que existem duas formas principais para administração e gerenciamento de nossos serviços: Pela interface web de gerenciamento (GUI) OU pela linha de comandos através da AWS CLI Tool que se comunica com a API do AWS. Este procedimento, assim como praticamente todos os outros, pode ser realizado por ambos os meios.</p>

<p><strong>S</strong>e você também gosta de automação, provavelmente prefere utilizar a CLI, no entanto irei listar aqui o procedimento em ambos os meios.</p>

<p><strong>Passo 1: Criando um SNS Topic para receber os alarmes</strong></p>

<p><strong>1.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço SNS;</li>
<li>Crie um novo SNS Topic:

<ul>
<li>No menu da lateral esquerda, clique em <strong>Topics</strong>;</li>
<li>Clique em <strong>Create new topic</strong>;</li>
<li>Preencha os campos <strong>Name</strong> (obrigatório) e <strong>Display Name</strong> (opcional) para o seu tópico. Para este exemplo utilizarei <em>aws-slack-alerts</em> como <strong>Name</strong> e <em>aws-slack</em> como <strong>Display Name</strong>; <em>(O Display Name só é necessário em caso de você também desejar enviar notificações por SMS)</em></li>
<li>Clique em <strong>Create Topic</strong></li>
</ul>
</li>
<li>Agora você já deve ser capaz de ver seu SNS Topic na lista.</li>
</ul>


<p><strong>1.2 &ndash; Pela AWS CLI Tool</strong></p>

<p><em>Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando a região na qual você deseja criar seu tópico e o nome desejado:</li>
</ul>


<p>```python
aws sns create-topic</p>

<pre><code>--region us-west-1
--name aws-slack-alerts
</code></pre>

<p>```
  * <strong>IMPORTANTE:</strong> Você receberá um identificador (TopicArn) para este alarme. Você precisará dele no passo seguinte.
  * Caso queira ter certeza, você pode listar seus tópicos utilizando:</p>

<p><code>python
aws sns list-topics
</code></p>

<p><strong>Passo 2: Criando um Alarme no serviço CloudWatch</strong></p>

<p><strong>2.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>CloudWatch</strong>;</li>
<li>Crie um novo Alarme:

<ul>
<li>Clique em <strong>Alarms</strong>;</li>
<li>Clique no botão <strong>Create Alarm</strong>;</li>
<li>Escolha a categoria do alarme desejado. Para este exemplo utilizarei <strong>ELB Metric > Per-LB Metrics</strong> <em>(Dentre as várias categorias disponíveis, esta se refere à Load Balancers)</em>;</li>
<li>Selecione a métrica exata desejada. No caso deste exemplo, preciso selecionar a métrica e o Load Balancer desejado. Ao escolher a métrica e o alvo (em meu caso um Load Balancer) clique em <strong>Next</strong>. Neste exemplo eu escolhi a métrica <strong>HTTPCode_Backend_5XX</strong> <em>(para monitorar 500 errors)</em> e um Load Balancer chamado <strong>LB-GuySpyV3</strong>;</li>
<li>O próximo passo é definir um nome e uma descrição para este <strong>Alarme</strong>, bem como definir as triggers e períodos de monitoramento. Neste exemplo utilizei o nome <strong>LB-GuySpyV3-ELB_500</strong> para meu alarme; <em>(Não entrarei em detalhes quanto ao uso das triggers, visto que para cada tipo ou categoria de métrica, as triggers serão diferentes, bem como o cenário de seu ambiente e nível de criticidade. Em resumo, se você deseja monitorar o uso de CPU de um determinado servidor, a trigger seria o gatilho que ativaria o alarme, por exemplo: Só quero ser alarmado se o uso de CPU neste servidor ou instância for >= 90% e assim permanecer por pelo menos 60 segundos, ou por dois períodos seguidos de 60seg.)</em></li>
<li>Na seção <strong>Actions</strong> da configuração do Alarme defina o <strong>State</strong> e indique que a notificação deverá ser enviada <strong>(Send notification to)</strong> para o <strong>SNS Topic</strong> que criamos anteriormente. Para este exemplo optei por <strong>State is ALARM</strong> e decidi enviar as notificações para <strong>aws-slack-alerts</strong>, sendo este o SNS Topic que criei no início;</li>
<li>Finalize clicando em <strong>Create Alarm</strong>.</li>
</ul>
</li>
</ul>


<p>  <strong>2.2 &ndash; Pela AWS CLI Tool</strong></p>

<p>  <em>Novamente&hellip; Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando os atributos abaixo:

<ul>
<li><strong>region</strong> <em>(Região)</em>;</li>
<li><strong>alarm-name</strong> <em>(Nome do alarme)</em>;</li>
<li><strong>alarm-description</strong> <em>(Descrição do alarme)</em>;</li>
<li><strong>alarm-actions</strong> <em>(Definir a ação do alarme &ndash; Apontar para o TopicArn do SNS Topic que criamos anteriormente)</em>;</li>
<li><strong>metric-name</strong> <em>(Nome da Métrica desejada)</em>;</li>
<li><strong>namespace AWS/ELB &mdash;statistic</strong> <em>(Estatística desejada para aquela métrica, neste caso utilizarei Sum (Soma) ao invés de Average (Média))</em>;</li>
<li><strong>dimensions</strong> <em>(O alvo desta métrica de monitoramento, no nosso caso um Load Balancer)</em>;</li>
<li><strong>period</strong> e <strong>evaluation-periods</strong> <em>(Períodos desejados para a trigger)</em>;</li>
<li><strong>threshold</strong> <em>(O valor desejado: Neste exemplo estou colocando o valor como 1, portanto receberei o alarme caso seja >= 1. Sim, eu sei que receberei o alarme a cada minuto, mas estou fazendo isto de propósito para recebermos a notificação a fim de teste. Nunca utilize um threshold desses em produção. :p)</em>;</li>
<li><strong>comparison-operator</strong> <em>(Operador de comparação desejado, neste caso >=)</em>;</li>
</ul>
</li>
</ul>


<p>```python
aws cloudwatch put-metric-alarm &mdash;region us-west-1</p>

<pre><code>--alarm-name "LB-GuySpyV3-ELB_500"
--alarm-description "Sends 500-errors to Slack"
--actions-enabled
--alarm-actions "TheTopicArn from last step"
--metric-name "HTTPCode_Backend_5XX"
--namespace AWS/ELB --statistic "Sum"
--dimensions "Name=LoadBalancerName,Value=LB-GuySpyV3"
--period 60
--evaluation-periods 60
--threshold 1
--comparison-operator "GreaterThanOrEqualToThreshold"
</code></pre>

<p>```</p>

<p><strong>Passo 3: Criando uma Função Lambda como Assinante (Subscriber) do nosso SNS Topic</strong></p>

<p><strong>3.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>Lambda</strong>;</li>
<li>Crie uma <strong>Nova Função Lambda</strong>:

<ul>
<li>Clique em <strong>Create a Lambda Function</strong>;</li>
<li>Na tela <strong>Select Blueprint</strong> clique na opção <strong>cloudwatch-alarm-to-slack</strong>; <em>(Você poderá precisar buscar por esta opção)</em></li>
<li>O próximo passo será a tela <strong>Configure Triggers</strong>. Selecione o <strong>SNS Topic</strong> que foi criado anteriormente (aws-slack-alerts neste exemplo) e marque a opção <strong>Enable Trigger</strong> e clique em Next;</li>
<li>Em <strong>Configure Function</strong> dê um Nome e uma Descrição para a função e escolha <strong>Node.js.4.3</strong> como <strong>Runtime</strong>;</li>
<li>No campo <strong>Lambda Function Code</strong> cole o seguinte código: <a href="https://gist.github.com/tomfa/b33f768908b0a83987d26f269e377e95">Disponível no github</a>

<ul>
<li>(Você deverá setar os valores das variáveis <strong>CHANNEL</strong> e <strong>PATH</strong>, onde CHANNEL é o canal do Slack para o qual você deseja mandar as notificações e PATH é a URL de seu WebHook, recebida quando configuramos o Incoming WebHook no Slack)</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>```python
var https = require(&lsquo;https&rsquo;);
var util = require(&lsquo;util&rsquo;);</p>

<p>var CHANNEL = &ldquo;#devops&rdquo;;
var PATH = &ldquo;/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv&rdquo;;</p>

<p>exports.handler = function(event, context) {</p>

<pre><code>console.log(JSON.stringify(event, null, 2));
console.log('From SNS:', event.Records[0].Sns.Message);

var postData = {
    "channel": CHANNEL,
    "username": "AWS SNS",
    "text": "*" + event.Records[0].Sns.Subject + "*",
    "icon_emoji": ":aws:"
};

var message = event.Records[0].Sns.Message;
var severity = "good";

var dangerMessages = [
    " but with errors",
    " to RED",
    "During an aborted deployment",
    "Failed to deploy application",
    "Failed to deploy configuration",
    "has a dependent object",
    "is not authorized to perform",
    "Pending to Degraded",
    "Stack deletion failed",
    "Unsuccessful command execution",
    "You do not have permission",
    "Your quota allows for 0 more running instance"];

var warningMessages = [
    " aborted operation.",
    " to YELLOW",
    "Adding instance ",
    "Degraded to Info",
    "Deleting SNS topic",
    "is currently running under desired capacity",
    "Ok to Info",
    "Ok to Warning",
    "Pending Initialization",
    "Removed instance ",
    "Rollback of environment"       
    ];

for(var dangerMessagesItem in dangerMessages) {
    if (message.indexOf(dangerMessages[dangerMessagesItem]) != -1) {
        severity = "danger";
        break;
    }
}

// Only check for warning messages if necessary
if (severity == "good") {
    for(var warningMessagesItem in warningMessages) {
        if (message.indexOf(warningMessages[warningMessagesItem]) != -1) {
            severity = "warning";
            break;
        }
    }       
}

postData.attachments = [
    {
        "color": severity,
        "text": message
    }
];

var options = {
    method: 'POST',
    hostname: 'hooks.slack.com',
    port: 443,
    path: PATH
};

var req = https.request(options, function(res) {
  res.setEncoding('utf8');
  res.on('data', function (chunk) {
    context.done(null, postData);
  });
});

req.on('error', function(e) {
  console.log('problem with request: ' + e.message);
});   

req.write(util.format("%j", postData));
req.end();
</code></pre>

<p>};
```</p>

<ul>
<li>O <strong>Handler</strong> deverá ser o default <code>index.handler</code>;

<ul>
<li>Para <strong>role</strong> selecione <strong>Create a custom role</strong>; <em>(Isto será necessário apenas para a sua primeira função)</em></li>
<li>Na tela seguinte selecione <strong>lambda_basic_execution</strong> como <strong>IAM role</strong> e deixe o <strong>Policy Name</strong> com seu valor default. O AWS irá criar uma política de segurança padrão que nos dará os privilégios necessários. Clique em <strong>Allow</strong>;</li>
<li>Certifique-se de que o valor para <strong>VPC</strong> na seção <strong>Advanced Settings</strong> seja <strong>No VPC</strong>;
Clique em <strong>Next</strong>, reveja suas configurações e clique em <strong>Create Function</strong>;</li>
</ul>
</li>
<li>Aguarde seu alarme acontecer e receba a notificação no Slack. :D</li>
</ul>


<p>O resultado em seu Slack será algo assim&hellip;</p>

<p><img class="center" src="/imgs/slack2.png" title="&lsquo;Notification_Slack&rsquo;" ></p>

<p><strong>P</strong>arabéns, você já está recebendo suas notificações via Slack. Basta criar outros alarmes no AWS utilizando a mesma Lambda Function e o mesmo SNS Topic.</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker - Uma alternativa elegante para containers no Linux]]></title>
    <link href="http://kalib.github.io/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/"/>
    <updated>2015-08-20T11:01:00-04:00</updated>
    <id>http://kalib.github.io/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/dockerlogo.png" title="&lsquo;Docker&rsquo;" ></p>

<p><strong>A</strong>ntes de falar sobre o Docker, é importante que se entenda o conceito de um container, portanto vamos começar do básico. A imagem acima, logomarca do Docker, deixa claro o que é um container. A baleia, representando um navio, carregando diversos caixotes ou containers ilustra o conceito físico de um container. Nada mais do que um enorme caixote que possui o intuito de isolar algo. Quando um grande navio transporta mercadorias de um porto para outro, ele costuma trazer diversos containers separando estas mercadorias, de forma que as coisas não fiquem misturadas e bagunçadas. A forma de separação vai depender dos critérios de organização utilizados pela embarcação, seja por proprietário, seja por categoria de produtos, etc. De qualquer forma, embora cada container possua seus elementos próprios, todos os containers compartilham alguns recursos básicos, como por exemplo a embarcação, que é o meio de transporte para todos os containers ali contidos.</p>

<p><strong>D</strong>a mesma forma se dá no mundo dos computadores, onde o conceito de containers surgiu para separar e isolar alguns recursos e aplicações, otimizando os recursos que servem como base e que podem ser utilizados de forma compartilhada, como por exemplo o kernel do Sistema Operacional. De certa forma isto nos faz lembrar um pouco da virtualização, onde cada máquina virtual compartilha os recursos da máquina física, no entanto existe uma diferença clara no contexto de containers, visto que em um cenário de virtualização você precisará possuir um SO instalado na máquina física, com seu kernel e todos os seus recursos, e um SO instalado em sua máquina virtual, também com seu kernel e todos os seus recursos. Quando falamos em containers, imagine que você só precisará do kernel, bem como vários outros recursos, na máquina que será a hospedeira do container (a embarcação).</p>

<p><strong>C</strong>ontainers Linux surgiram como uma tecnologia chave para empacotamento e entrega de aplicativos, combinando a leveza do isolamento de aplicativos com a flexibilidade de métodos de deploy baseados em imagens.</p>

<p><strong>U</strong>ma das formas mais simples de se imaginar a vantagem da utilização de containers é imaginar que você possui uma empresa que hospeda servidores de aplicações para seus clientes. Se um novo cliente surge querendo hospedar a aplicação dele, você subirá uma nova máquina virtual, o que inclui todo um novo sistema operacional, enquanto que em uma solução baseada em containers você poderá ter apenas a sua máquina com um único kernel Linux provendo as priorizações de recursos (CPU, memória, I/O, rede, etc.) sem a necessidade de dar boot em um novo sistema operacional (máquinia virtual) na qual rodará a aplicação deste cliente.</p>

<p><strong>D</strong>izem que uma imagem vale mais que mil palavras&hellip;</p>

<p><img class="center" src="/imgs/docker_vmdiagram.png" title="&lsquo;Virtual Machine Diagram&rsquo;" ></p>

<p><strong>N</strong>a imagem acima temos o cenário convencional com a utilização de <strong>Máquinas Virtuais</strong>. Em suma, temos um host físico, com seu respectivo SO e kernel. Acima deles temos a camada de virtualização ou HyperVisor, enquanto que acima desta teremos as máquinas virtuais, com seus respectivos SOs (cada um com seu kernel) instalados. No caso temos 3 VMs, com 3 SOs (cada um com seu kernel). Na camada acima encontramos o que realmente é necessário para o app do cliente funcionar, que são as bibliotecas e os binários. Por fim, o App do cliente em si.</p>

<p><strong>V</strong>ejamos como fica o cenário com a utilização de containers, docker neste caso&hellip;</p>

<p><img class="center" src="/imgs/docker_diagram.png" title="&lsquo;Docker Diagram&rsquo;" ></p>

<p><strong>N</strong>o cenário com o Docker percebemos que a camada de SO das VMs sumiu, visto que ela não é mais necessária. Ao invés de Máquinas Virtuais, agora nós temos 3 containers, onde cada container roda os binários e bibliotecas de um SO, porém se aproveitando do kernel já existente no Host.</p>

<p><strong>C</strong>om este grau de modularização nós ganhamos maior flexibilidade e agilidade no deploy de ambientes e aplicações.</p>

<p><strong>U</strong>ma das vantagens da utilização do Docker é a existência de um repositório de imagens prontas que ficam disponibilizadas livremente para quem desejar utilizar. Seja uma imagem pronta de um container com CentOS, Ubuntu, etc.. Já existem centenas e centenas de imagens prontas para uso, sendo esta uma base de compartilhamento comunitário, mas&hellip;</p>

<p><strong>V</strong>amos ao que interessa&hellip;</p>

<p><strong>N</strong>os exemplos a seguir, estou utilizando o Ubuntu Server 15.04, visto que estou atualmente realizando uma POC de VPS com um novo host, portanto aproveitarei para fazer disto uma parte de meus testes nesta VPS. Sinta-se livre para utilizar sua máquina física com Ubuntu, com Debian, ou mesmo uma máquina virtual, caso não goste de realizar testes em sua máquina física, o resultado será o mesmo. Para que tudo funcione como esperamos, só existem 2 pré-requisitos a serem atendidos:</p>

<p>1- O kernel do Linux que será utilizado deve ser igual ou superior ao 3.8;</p>

<p>2- Caso você esteja realizando os testes em uma VM, seria interessante que sua máquina física tivesse comunicação com a VM. Isso pode ser testado com um ping da máquina física para a VM. No caso de sua máquina virtual ser instalada com interface gráfica, esta comunicação não será necessária, pois o único momento em que utilizaremos isto será para abrir um navegador e fazer um teste de acesso ao endereço da máquina virtual.</p>

<p><strong>V</strong>amos lá. Para ter a certeza de que você atende o pré-requisito de kernel, utilize o comando &ldquo;uname -r&rdquo;:</p>

<p><code>
 kalib@cloudcaverna:~$ uname -r
 3.19.0-25-generic
</code></p>

<p><strong>E</strong>stou com o kernel 3.19, portanto superior ao kernel 3.8 que é o pré-requisito mínimo. Vamos em frente.</p>

<p><strong>P</strong>rimeiramente, vamos instalar o Docker. Seja lá qual for sua distribuição Linux, digite o comando: <strong>(O comando deve ser executado com o usuário root ou com o comando sudo!)</strong></p>

<p><code>
 # curl -sSL https://get.docker.com | sh
</code></p>

<p><strong>E</strong>le baixará e executará um script de instalação, no meu caso do Ubuntu ele irá instalar um repositório e em seguida instalará o docker. O próximo passo será iniciar o serviço do docker:</p>

<p><code>
 # /etc/init.d/docker start
 [ ok ] Starting docker (via systemctl): docker.service.
</code></p>

<p><strong>O</strong> docker possui uma série de scripts/comandos próprios para facilitar a sua administração, como por exemplo um script de <strong>ps</strong>, para que possamos ter a certeza de que ele está rodando e, além disso, saber se existem containers em execução, da mesma forma que faríamos com o ps do linux para ver os processos em andamento.</p>

<p>```
 # docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```</p>

<p><strong>P</strong>odemos ver que o docker está rodando, no entanto nenhum container está em execução. Na verdade, não temos nenhum container criado, portanto obviamente não poderia estar em execução.</p>

<p><strong>A</strong>lém do ps, podemos utilizar o script <strong>images</strong> para ver quais imagens de containers já possuímos para uso:</p>

<p>```
 # docker images</p>

<p> REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
```</p>

<p><strong>D</strong>a mesma forma, não temos ainda nenhuma imagem baixada para uso.</p>

<p><strong>U</strong>ma vez que estamos falando de containers, conforme dito anteriormente, a ideia é isolar ao máximo e otimizar o que precisamos para este container, portanto precisamos informar o processo que desejamos iniciar no container em questão.</p>

<p><strong>V</strong>amos criar um container do Ubuntu, por exemplo, na versão 15.04, lançada em Abril deste ano, e vamos iniciar juntamente com ele o processo /bin/bash. O comando utilizado será: docker run -i -t ubuntu:15.04 /bin/bash</p>

<p>```
 # docker run -i -t ubuntu:15.04 /bin/bash</p>

<p> Unable to find image &lsquo;ubuntu:15.04&rsquo; locally
 15.04: Pulling from library/ubuntu</p>

<p> 6e6a100fa147: Pull complete
 13c0c663a321: Pull complete
 2bd276ed39d5: Pull complete
 013f3d01d247: Already exists
 library/ubuntu:15.04: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.</p>

<p> Digest: sha256:b2d4940544e515d4bc62b2a9ad3e6137b3e1e0937a41fdc1f0f30d12935e5b09
 Status: Downloaded newer image for ubuntu:15.04</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>É</strong> importante reparar que na primeira linha de execução ele me trouxe um alerta informando que não foi possível encontrar a imagem &ldquo;ubuntu:15.04&rdquo; localmente. Como disse acima, não temos ainda nenhuma imagem baixada, portanto ele não encontrou localmente e foi baixar diretamente no repositório de imagens do docker.</p>

<p><strong>O</strong> procedimento foi extremamente rápido, certo? Acredite ou não, você já possui um container Ubuntu rodando em sua máquina. ;] Ainda não acredita? Repare novamente no seu prompt de comandos, veja que logo que ele finalizou o processo ele lhe deixou em um prompt &ldquo;estranho&rdquo;. No caso do meu exemplo acima, perceba que ao concluir o processo ele me deixou com o prompt assim:</p>

<p><code>
 root@d70562e7533c:/#
</code></p>

<p><strong>N</strong>ão, minha máquina não se chama d70562e7533c. Tenho certeza de que a sua também não se chama.. seja lá qual for a combinação de caracteres que lhe foi apresentada no prompt. Na verdade, sempre que iniciamos um container, o comportamento default é que você já é logado nele. Em suma, seu container com ubuntu 15.04 já foi criado e você já está logado nele, e esta combinação de caracteres estranha é o ID que foi dado ao seu container.</p>

<p><strong>A</strong>inda não acredita? Bom, você pode, por exemplo, dar um <strong>cat /etc/issue</strong>, para ver que você está de fato rodando um ubuntu 15.04. Claro, no meu caso não haverá diferença, pois minha máquina que está rodando o docker também é ubuntu 15.04.</p>

<p>```
 root@d70562e7533c:/# cat /etc/issue</p>

<p> Ubuntu 15.04 \n \l</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>O*utro teste, seria rodar </strong>ps -ef** no container. Você verá que não existe nenhum processo rodando. Aliás, haverá apenas 1 processo (além do próprio ps), que foi o processo indicado na criação: /bin/bash. Desta forma você terá a certeza de que não está no prompt de sua máquina mesmo, visto que na sua certamente existem dezenas ou centenas de processos rodando, do kernel, do usuário, etc.</p>

<p>```
 root@d70562e7533c:/# ps -ef</p>

<p> UID        PID  PPID  C STIME TTY          TIME CMD
 root         1     0  0 13:36 ?        00:00:00 /bin/bash
 root         9     1  0 13:44 ?        00:00:00 ps -ef</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>D</strong>a mesma forma você poderá experimentar outros comandos para testar (caso ainda não esteja acreditando que de forma tão &ldquo;oi, simples assim&rdquo; você já está com seu container pronto): ls, apt-get update, etc.. Tudo funcionando como se fosse uma máquina real, ou virtual, no entanto sem um kernel, visto que ela está utilizando o kernel da máquina host.</p>

<p><strong>A</strong>gora que temos a certeza de que estamos em nosso container, você pode sair do container e voltar para sua máquina host. Para isso você precisará pressionar as teclas <strong>Ctrl + P + Q</strong>. Desta forma, você verá que seu prompt voltará para seu host enquanto que seu container continuará rodando, você apenas saiu do prompt do mesmo.</p>

<p>```
 root@d70562e7533c:/# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>V</strong>amos verificar novamente o ps do docker, visto que da última vez ele estava vazio. Desta vez ele nos mostrará um processo em execução, que no caso é o container que criamos.</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
 d70562e7533c        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         15 minutes ago      Up 15 minutes                           modest_khorana
```</p>

<p><strong>N</strong>o retorno podemos ver o ID do nosso container, o nome da imagem que ele utiliza, o comando em execução, o tempo desde sua criação, o seu status, portas e nome.</p>

<p><strong>O</strong> container ID poderá ser utilizado para voltar para nosso container através do comando <strong>docker attach &lt;container-id></strong>: (Após digitar o comando, pressione novamente Enter para liberar o prompt)</p>

<p>```
 root@cloudcaverna:~# docker attach d70562e7533c</p>

<p> root@d70562e7533c:/#
```</p>

<p><strong>N</strong>o exemplo anterior nós utilizamos a combinação <strong>Ctrl + P + Q</strong> para sair do container mantendo-o rodando. Vamos experimentar utilizar desta vez <strong>Ctrl + D</strong>. Desta forma você não apenas está saindo mas também desligando o container. Execute novamente a lista de processos/containers do docker para ver:</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```</p>

<p><strong>N</strong>o entanto, é importante lembrar que a imagem do Ubuntu 15.04 que baixamos, continua disponível para o caso de precisarmos criar novos containers Ubuntu 15.04:</p>

<p>```
 root@cloudcaverna:~# docker images</p>

<p> REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
 ubuntu              15.04               013f3d01d247        17 hours ago        131.4 MB
```</p>

<p><strong>S</strong>imples&hellip; Mas vamos fazer algo mais próximo do mundo real, afinal um container apenas com o Ubuntu rodando, ou qualquer outra que seja a distribuição escolhida, não tem muita utilidade, portanto vamos criar um container rodando um servidor web, para o caso de querermos hospedar um site ou aplicalção web neste container. Por ser mais leve e simples, vou utilizar o nginx no exemplo. Vamos utilizar o comando <strong>docker run -i -t -p 8080:80 ubuntu:15.04 /bin/bash</strong></p>

<p><strong>N</strong>o comando acima estamos dizendo que queremos criar um novo container ubuntu 15.04 rodando o /bin/bash. Desta vez temos um parâmetro que não utilizamos anteriormente. O <strong>p</strong> serve para indicar a utilização de portas. Quando utilizamos <strong>p 8080:80</strong> estamos dizendo que vamos utilizar a porta 80 no container e que ela estará mapeada na porta 8080 do nosso host ou hospedeiro. Ou seja, quando instalarmos o Nginx no ubuntu do container, você poderá através de seu host abrir o navegador e acessar o seu endereço ip ou nome de host (caso você possua resolução de nomes funcionando) na porta 8080.</p>

<p>```
 root@cloudcaverna:~# docker run -i -t -p 8080:80 ubuntu:15.04 /bin/bash</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>O</strong> processo foi bem mais rápido desta vez, visto que já tínhamos a imagem do container ubuntu 15.04, portanto não tivemos a necessidade de baixar outra imagem. O seu container já está criado e você já está logado no prompt do mesmo, conforme pode ver através do ID do container que apareceu em seu prompt.</p>

<p><strong>V</strong>amos agora instalar o servidor web nginx para realizarmos o nosso teste. Para isso vamos atualizar os repositórios e em seguida instalar o pacote: <strong>apt-get update &amp;&amp; apt-get install -y nginx</strong></p>

<p>```
 root@08abb8611700:/# apt-get update &amp;&amp; apt-get install -y nginx</p>

<p> Ign <a href="http://archive.ubuntu.com">http://archive.ubuntu.com</a> vivid InRelease
 Ign <a href="http://archive.ubuntu.com">http://archive.ubuntu.com</a> vivid-updates InRelease
 Get:1 <a href="http://archive.ubuntu.com">http://archive.ubuntu.com</a> vivid/main Sources [1358 kB]
 Get:2 <a href="http://archive.ubuntu.com">http://archive.ubuntu.com</a> vivid/restricted Sources [7100 B]
 &hellip;
 Building dependency tree     <br/>
 Reading state information&hellip; Done
 The following extra packages will be installed:
  fontconfig-config fonts-dejavu-core geoip-database init-system-helpers libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu52
  libjbig0 libjpeg-turbo8 libjpeg8 libpng12-0 libssl1.0.0 libtiff5 libvpx1 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4
  libxslt1.1 nginx-common nginx-core sgml-base ucf xml-core
 Suggested packages:
  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert sgml-base-doc debhelper
 The following NEW packages will be installed:
  fontconfig-config fonts-dejavu-core geoip-database init-system-helpers libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu52
  libjbig0 libjpeg-turbo8 libjpeg8 libpng12-0 libssl1.0.0 libtiff5 libvpx1 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4
  libxslt1.1 nginx nginx-common nginx-core sgml-base ucf xml-core
 0 upgraded, 31 newly installed, 0 to remove and 0 not upgraded.
 Need to get 14.0 MB of archives.
 After this operation, 53.3 MB of additional disk space will be used.
 &hellip;
 Get:1 <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> vivid/main libexpat1 amd64 2.1.0-6ubuntu1 [70.6 kB]
 Processing triggers for systemd (219-7ubuntu6) &hellip;</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>C</strong>ortei bastante a saída visto ser desnecessária, mas uma vez que o nginx esteja instalado, vamos iniciá-lo: <strong>/etc/init.d/nginx start</strong>. Em seguida, vamos utilizar o ps para ver os processos que estão rodando no nosso container:</p>

<p>```
 root@08abb8611700:/# /etc/init.d/nginx start</p>

<p> root@08abb8611700:/# ps -ef</p>

<p> UID        PID  PPID  C STIME TTY          TIME CMD
 root         1     0  0 14:10 ?        00:00:00 /bin/bash
 root       609     1  0 14:19 ?        00:00:00 nginx: master process /usr/sbin/nginx
 www-data   610   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   611   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   612   609  0 14:19 ?        00:00:00 nginx: worker process
 www-data   613   609  0 14:19 ?        00:00:00 nginx: worker process
 root       614     1  0 14:19 ?        00:00:00 ps -ef</p>

<p> root@08abb8611700:/#
```</p>

<p><strong>F</strong>eito isto, o serviço está rodando e já pode ser testado. Em seu host você poderá abrir o navegador e acessar o endereço local de seu host, com a porta 8080, visto que foi esta que definimos inicialmente para mapear a porta 80 do container: <strong>localhost:8080</strong></p>

<p><strong>C</strong>aso esteja utilizando uma máquina virtual para fazer seus testes, você terá duas possibilidades:
1- Caso sua máquina virtual possua alguma interface gráfica instalada, você poderá abrir o navegador da própria VM e acessar o mesmo endereço de localhost com a porta 8080;
2- Caso sua VM não esteja com nenhum ambiente gráfico instalado, você poderá utilizar aplicações de CLI para testar (ex: lynx, curl, etc.) ou usar o navegador da máquina que serve de host para sua VM, levando em conta que você fez o teste descrito no início para ter certeza de que sua máquina física consegue se comunicar com sua VM. Neste caso, em sua máqunina física você acessará o endereço de sua vm no navegador, com a porta 8080.</p>

<p><strong>R</strong>esultado? O Nginx em nosso container rodando perfeitamente.</p>

<p><img class="center" src="/imgs/docker_nginx8080.png" title="&lsquo;Nginx on Docker&rsquo;" ></p>

<p><strong>D</strong>a mesma forma feita anteriormente, podemos sair de nosso container com a combinação de teclas <strong>Ctrl + P + Q</strong> e verificar os processos/containers do docker em execução:</p>

<p>```
 root@08abb8611700:/# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         19 minutes ago      Up 19 minutes       0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>É</strong> importante salientar que quando saímos do container com a combinação <strong>Ctrl + P + Q</strong> nós não estamos fechando o container, pois ele continua rodando, conforme pode ser visto com <strong>docker ps</strong>. No entanto, quando saímos do nosso antigo container com a combinação <strong>Ctrl + D</strong>, nós percebemos que ele finalizou de vez o container. Além de finalizar, ele excluiu o nosso container, visto que o mesmo não foi salvo, ou &ldquo;comittado&rdquo;. Se sairmos deste container no qual instalamos o nginx utilizando <strong>Ctrl + D</strong>, nós estaremos descartando tudo o que foi feito nele. Para poder finalizar o seu container sem perdê-lo, ou seja, mantendo o container salvo e tudo o que foi instalado/configurado nele, nós precisamos sair do container com a combinação <strong>Ctrl + P + Q</strong>, conforme fizemos acima, e em seguida realizar um commit deste container. Estaremos então criando uma imagem com o atual estado do container. Desta forma, se posteriormente precisarmos subir um novo container que rode o SO ubuntu 15.04 e que também possua o nginx, poderemos criar um novo container a partir desta imagem em poucos segundos. O commit se dá da seguinte forma: <strong>docker commit &lt;container-id> &lt;nome-que-vc-desejar></strong></p>

<p><strong>L</strong>embrando que o id do container pode ser conseguido através do comando <strong>docker ps</strong> e que o <strong>nome-que-vc-desejar</strong> será o nome utilizado para identificar esta sua máquina/imagem.</p>

<p>```
 root@cloudcaverna:~# docker commit 08abb8611700 cloudcaverna/ubuntu-nginx:1.0</p>

<p> b0922bc8f41295cadadbd131c075e29288b52e8bb2d9546cb7c0327eb95fe7dc</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>U</strong>tilizei 1.0 ao final para ter uma ideia de versionamento, visto que o docker nos permite trabalhar desta forma. É uma questão de organização.</p>

<p><strong>E</strong>m seguida você pode verificar sua imagem criada através do script <strong>images</strong> do docker, bem como o seu container ainda rodando através do script <strong>ps</strong>:</p>

<p>```
 root@cloudcaverna:~# docker images</p>

<p> REPOSITORY                  TAG                 IMAGE ID            CREATED              VIRTUAL SIZE
 cloudcaverna/ubuntu-nginx   1.0                 b0922bc8f412        About a minute ago   204.6 MB
 ubuntu                      15.04               013f3d01d247        18 hours ago         131.4 MB</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         49 minutes ago      Up 49 minutes       0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>V</strong>amos agora criar um novo container. Aqui você pode escolher como prosseguir. Eu criarei um container com a distribuição Arch Linux rodando, mas você pode seguir e criar outra com o Ubuntu caso deseje, então vejamos as opções:</p>

<p><strong>Opção 1 &ndash; Caso escolha criar este segundo container como Arch Linux</strong></p>

<p>```
 root@cloudcaverna:~# docker run -i -t -p 6660:80 base/archlinux /bin/bash</p>

<p> Unable to find image &lsquo;base/archlinux:latest&rsquo; locally
 latest: Pulling from base/archlinux</p>

<p> b31c6c1462e6: Pull complete
 b97e110c94d9: Already exists
 Digest: sha256:7905fad7578b9852999935fb0ba9c32fe16cece9e4d1d742a34f55ce9cebdfd1
 Status: Downloaded newer image for base/archlinux:latest</p>

<p> [root@be266bf7e5a3 /]#</p>

<p>```</p>

<p><strong>Opção 2 &ndash; Caso deseje criar um novo container Ubuntu aproveitando a imagem que já está pronta e com nginx já instalado</strong></p>

<p><code>
 docker run -i -t -p 6660:80 &lt;nome-que-vc-deu-para-sua-imagem&gt;
</code></p>

<p>Como eu dei o nome de <em>cloudcaverna/ubuntu-nginx</em>, eu utilizaria <em>docker run -i -t -p 6660:80 cloudcaverna/ubuntu-nginx</em>.</p>

<p>Desta forma você não precisará sequer instalar o nginx novamente neste container, visto que você utilizou como base uma imagem que já possuía o nginx instalado, restando apenas a você testar no navegador novamente o endereço porém trocando a porta para 6660.</p>

<p><strong>C</strong>omo eu resolvi seguir em frente com um container totalmente novo, baseado no Arch Linux, vou dar um <strong>cat /etc/issue</strong> para ver que realmente estou em um ambiente com a distribuição Arch Linux e vou instalar o nginx nele com o pacman, visto que este é o gerenciador de pacotes do Arch:</p>

<p>```
 [root@be266bf7e5a3 /]# cat /etc/issue</p>

<p> Arch Linux \r (\l)</p>

<p> [root@be266bf7e5a3 /]# pacman -Sy nginx</p>

<p> :: Synchronizing package databases&hellip;
 core                                                        121.2 KiB   203K/s 00:01 [#################################################] 100%
 extra                                                      1773.8 KiB   644K/s 00:03 [#################################################] 100%
 community                                                     2.7 MiB   936K/s 00:03 [#################################################] 100%
 resolving dependencies&hellip;
 looking for inter-conflicts&hellip;</p>

<p> Packages (1): nginx-1.8.0-1</p>

<p> Total Download Size:    0.34 MiB
 Total Installed Size:   0.98 MiB</p>

<p> :: Proceed with installation? [Y/n]
 :: Retrieving packages &hellip;
 nginx-1.8.0-1-x86_64                                        349.5 KiB   266K/s 00:01  [#################################################] 100%
 (1/1) installing nginx                                                                [ #################################################] 100%</p>

<p> [root@be266bf7e5a3 /]#
```</p>

<p><strong>A</strong>gora que estou com o nginx rodando também neste container do Arch Linux, vou sair do container pressionando a combinação <strong>Ctrl + P + Q</strong> e em seguida rodar o script de <strong>ps</strong> do docker:</p>

<p>```
 [root@be266bf7e5a3 /]# root@cloudcaverna:~#</p>

<p> root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 be266bf7e5a3        base/archlinux      &ldquo;/bin/bash&rdquo;         10 minutes ago      Up 10 minutes       0.0.0.0:6660->80/tcp   cocky_hoover
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         About an hour ago   Up About an hour    0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
 ```</p>

<p> <strong>D</strong>esta vez eu possuo dois containers criados, sendo um com o ubuntu 15:04 e outro com o Arch Linux. Agora vou realizar o commit do meu container Arch Linux com nginx, para não perder esta imagem. Em seguida, executarei o script <strong>images</strong> para ver as imagens que já possuo:</p>

<p> ```
  root@cloudcaverna:~# docker commit be266bf7e5a3 cloudcaverna/archlinux-nginx:1.0</p>

<p> f4ea14bf23c47466fb256fff9e3ab32ca85fb0256a05007ef4972ad7ff5f2aa9</p>

<p> root@cloudcaverna:~# docker images</p>

<p> REPOSITORY                     TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
 cloudcaverna/archlinux-nginx   1.0                 f4ea14bf23c4        5 seconds ago       285.9 MB
 cloudcaverna/ubuntu-nginx      1.0                 b0922bc8f412        20 minutes ago      204.6 MB
 ubuntu                         15.04               013f3d01d247        18 hours ago        131.4 MB
 base/archlinux                 latest              b97e110c94d9        8 weeks ago         278.8 MB</p>

<p> root@cloudcaverna:~#
```
<strong>A</strong>gora vou testar no navegador o nginx deste meu segundo container, o qual defini que utilizaria a porta 6660 do meu host:</p>

<p><img class="center" src="/imgs/docker_nginx6660_8080.png" title="&lsquo;Nginx on Docker&rsquo;" ></p>

<p><strong>R</strong>epare que acessei ambos os endereços, tanto o da porta 8080, o qual está apresentando o nginx do meu primeiro container, quanto o da porta 6660, que apresenta o nginx do meu segundo container. Ambos funcionando em paralelo, com ambientes distintos, sendo um Ubuntu e o outro Arch Linux, porém ambos compartilham o mesmo kernel, que é o do meu host.</p>

<p><strong>O</strong> próprio script <strong>ps</strong> do docker lhe informa as portas que estão sendo utilizadas para cada container, caso você esteja em dúvida:</p>

<p>```
 root@cloudcaverna:~# docker ps</p>

<p> CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                  NAMES
 be266bf7e5a3        base/archlinux      &ldquo;/bin/bash&rdquo;         26 minutes ago      Up 26 minutes       0.0.0.0:6660->80/tcp   cocky_hoover
 08abb8611700        ubuntu:15.04        &ldquo;/bin/bash&rdquo;         About an hour ago   Up About an hour    0.0.0.0:8080->80/tcp   jolly_hawking</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>D</strong>a mesma forma, você poderá fazer toda e qualquer operação que você faria em uma máquina qualquer, como por exemplo monitorar os logs de acesso do nginx. Basta se conectar em algum dos dois containers com <strong>docker attach &lt;container-id></strong> e em seguida abrir o arquivo de log do nginx com o tail: <strong>tail -f /var/log/nginx/access.log</strong>. Com o log rodando, pode acessar novamente no navegador o endereço com a porta que está mapeada para este container e você verá os logs do seu acesso.</p>

<p><strong>A</strong>nteriormente nós vimos que com a combinação <strong>Ctrl + P + Q</strong> eu consigo sair do container porém ele permanecerá rodando. Com <strong>Ctrl + D</strong> eu finalizava o container de vez. Mas, supondo que eu queira parar temporariamente o container, posso utilizar o script <strong>stop</strong> do container inserindo o id do container que desejo parar:</p>

<p>```
 root@cloudcaverna:~# docker stop be266bf7e5a3
 be266bf7e5a3</p>

<p> root@cloudcaverna:~#
```</p>

<p><strong>E</strong>xiste ainda uma forma de ver o que foi alterado no container desde sua criação. É literalmente uma espécie de &ldquo;diff&rdquo;:</p>

<p><code>
 root@cloudcaverna:~# docker diff 08abb8611700
 C /.wh..wh.plnk
 A /.wh..wh.plnk/93.1190648
 C /bin
 A /bin/running-in-container
 A /core
 C /etc
 C /etc/default
 A /etc/default/nginx
 A /etc/fonts
 A /etc/fonts/conf.avail
 A /etc/fonts/conf.avail/10-antialias.conf
 A /etc/fonts/conf.avail/10-autohint.conf
 A /etc/fonts/conf.avail/10-hinting-full.conf
 A /etc/fonts/conf.avail/10-hinting-medium.conf
 A /etc/fonts/conf.avail/10-hinting-slight.conf
 A /etc/fonts/conf.avail/10-hinting.conf
 A /etc/fonts/conf.avail/10-no-sub-pixel.conf
 A /etc/fonts/conf.avail/10-scale-bitmap-fonts.conf
 A /etc/fonts/conf.avail/10-sub-pixel-bgr.conf
 A /etc/fonts/conf.avail/10-sub-pixel-rgb.conf
 A /etc/fonts/conf.avail/10-sub-pixel-vbgr.conf
 A /etc/fonts/conf.avail/10-sub-pixel-vrgb.conf
 A /etc/fonts/conf.avail/10-unhinted.conf
 A /etc/fonts/conf.avail/11-lcdfilter-default.conf
 A /etc/fonts/conf.avail/11-lcdfilter-legacy.conf
 A /etc/fonts/conf.avail/11-lcdfilter-light.conf
 ...
 ...
</code></p>

<p><strong>A</strong> saída é extensa, portanto cortei aqui mesmo, mas você terá basicamente todo o diff do que foi alterado desde a criação do container.</p>

<p><strong>R</strong>esumidamente, esta é a função do docker. Com criatividade e disposição se faz muita coisa com ele. Não é a toa que os big players de mercado já estão utilizando bastante esta ferramenta para soluções de container, como por exemplo: Amazon, Apcera, Cisco, CoreOS, Datera, VMWare, Verizon Labs, Red Hat, Google, RackSpace, Oracle, IBM, Intel, Microsoft, HP, etc.</p>

<p><strong>L</strong>embrando que o endereço de repositórios com as imagens já existentes e disponibilizadas gratuitamente é <a href="https://hub.docker.com">https://hub.docker.com</a></p>

<p><strong>A</strong>té a próxima&hellip;</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Assista ao documentário sobre Aaron Swartz: O menino da internet]]></title>
    <link href="http://kalib.github.io/blog/2014/08/03/assista-ao-documentario-sobre-aaron-swartz-o-menino-da-internet/"/>
    <updated>2014-08-03T07:19:00-04:00</updated>
    <id>http://kalib.github.io/blog/2014/08/03/assista-ao-documentario-sobre-aaron-swartz-o-menino-da-internet</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/aaron-swartz-movie.jpg" title="&lsquo;Aaron Swartz Movie&rsquo;" >
<code>
 Informação é poder. Mas, como todo poder, há aqueles que querem mantê-la para si mesmos. O patrimônio cultural e científico do mundo, publicado ao longo dos séculos em livros e revistas, está cada vez mais szendo digitalizado e trancado por um punhado de corporações privadas. Enquanto isso, aqueles que foram bloqueados não estão em pé de braços cruzados. Eles estão bisbilhotando em buracos e escalando cercas libertando as informações trancadas pelos editores e compartilhando com seus amigos. Mas toda essa ação acontece no escuro, escondida no subterrâneo. É chamado de roubo ou pirataria, como se compartilhar uma riqueza de conhecimentos fosse o equivalente  de saquear um navio e matar sua tripulação. Mas compartilhar não é imoral - é um imperativo moral. Só os cegos pela ganância se recusam a deixar um amigo fazer uma cópia. Não há justiça em seguir leis injustas. É hora de virmos para a luz e, na grande tradição de desobediência civil, declararmos a nossa oposição a este roubo privado da cultura pública.
</code></p>

<p><strong>E</strong>ste é apenas um trecho do manifesto assinado por Aaron, entitulado &ldquo;Manifesto do guerrilheiro ao acesso livre&rdquo;.</p>

<p><strong>R</strong>ecentemente foi lançado um documentário de Brian Knappenberger sobre <em>Aaron Swartz</em>, o qual foi considerado um dos principais nomes da internet e luta pela liberdade de acesso ao conhecimento dos últimos anos.</p>

<p><strong>P</strong>ara quem ainda não sabe do que se trata, Aaron Swartz foi um dos criadores do RSS bem como do famoso site de notícias e debates Reddit.Após alguns anos lutando e enfrentando a justiça americana Aaron cometeu suicídio.</p>

<p><img class="left" src="/imgs/aaron_swartz.jpg" title="&lsquo;Aaron Swartz&rsquo;" ><strong>A</strong>aron estava sendo condenado a cerca de 50 anos de prisão, bem como a pagar um montante superior a U$ 4 milhões em multas por querer tornar públicos os artigos acadêmicos e científicos que eram mantidos na base do JSTOR, o qual vendia o acesso a estes artigos que, na visão de Aaron, deveriam ser de domínio e acesso público.</p>

<p><strong>A</strong>aron sempre defendeu e lutou para que o conhecimento fosse de livre acesso a todos. Lutou tanto que acabou sendo covardemente perseguido e pressionado pelo governo americano, o que acabou por lhe deixar exausto, psicologicamente e financeiramente, ao ponto de ele desistir da luta ao invés de simplesmente &ldquo;assumir&rdquo; que estava errado e aceitar os &ldquo;acordos&rdquo; que lhe foram oferecidos pela justiça americana.</p>

<p><strong>S</strong>eu crime? A curiosidade. A fome por conhecimento. Também a vontade de expor este conhecimento a todos que o desejassem.</p>

<p><strong>P</strong>ara quem por algum motivo ainda não conhece o recurso de legendas ou caption do YoutTube, caso a legenda do filme não apareça automaticamente, basta clicar no botão de legendas/caption, habilitando-o, conforme apresentado na imagem abaixo:</p>

<p><img class="center" src="/imgs/youtube_captions.png" title="&lsquo;Youtube Captions&rsquo;" ></p>

<iframe width="560" height="315" src="http://kalib.github.io//www.youtube.com/embed/2uj1EeiuK5U" frameborder="0" allowfullscreen></iframe>


<p>Link para o vídeo: <a href="https://www.youtube.com/watch?v=2uj1EeiuK5U">https://www.youtube.com/watch?v=2uj1EeiuK5U</a></p>

<p><strong>A</strong>braços,</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Alterando os parâmetros do kernel em tempo real com o Systcl]]></title>
    <link href="http://kalib.github.io/blog/2014/02/13/alterando-os-parametros-do-kernel-em-tempo-real-com-o-systcl/"/>
    <updated>2014-02-13T22:02:00-05:00</updated>
    <id>http://kalib.github.io/blog/2014/02/13/alterando-os-parametros-do-kernel-em-tempo-real-com-o-systcl</id>
    <content type="html"><![CDATA[<p><img class="left" src="/imgs/linux-kernel.jpg" title="&lsquo;Linux Kernel&rsquo;" >
<strong>O</strong> <em>kernel</em>, em se tratando de sistemas operacionais, é o núcleo e componente mais importante da maioria dos computadores. Basicamente, serve de ponte entre os aplicativos e o processamento real de dados feito a nível de hardware. É ele o responsável por gerenciar os recursos do sistema, podendo oferecer uma camada de abstração de nível mais baixo para os recursos, como processadores e dispositivos de entrada/saída, que os softwares aplicativos devem controlar para realizar sua função. Com o GNU/Linux não é diferente. O núcleo Linux (Linux Kernel) forma a estrutura do sistema operacional GNU/Linux.</p>

<p><strong>C</strong>omo é de se esperar, o kernel possui diversos parâmetros configurados que definirão as características do seu sistema, controle de dispositivos, módulos, drivers, etc. Por vezes faz-se necessário alterar algum parâmetro do kernel para alguma tarefa ou rotina específica, portanto que tal ganhar tempo e alterar um ou mais parâmetros do kernel <em>on the fly</em>?!</p>

<p><strong>O</strong> comando <em>sysctl</em> pode ajudar nesta tarefa. Ele ajuda a configurar os parâmetros do kernel em tempo de execução.</p>

<p><strong>P</strong>ara listar os atuais parâmetros de seu kernel digite:</p>

<p>```
 [kalib@tuxcaverna ~]$ sysctl -a</p>

<p> abi.vsyscall32 = 1
 debug.exception-trace = 1
 dev.cdrom.autoclose = 1
 dev.cdrom.autoeject = 0
 dev.cdrom.check_media = 0
 dev.cdrom.lock = 1
 dev.hpet.max-user-freq = 64
 dev.mac_hid.mouse_button2_keycode = 97
 dev.mac_hid.mouse_button3_keycode = 100
 dev.mac_hid.mouse_button_emulation = 0
 dev.scsi.logging_level = 0
 fs.aio-max-nr = 65536
 fs.aio-nr = 41192
 fs.binfmt_misc.status = enabled
 fs.dentry-state = 177183        161128  45      0       0       0
 fs.dir-notify-enable = 1
 fs.epoll.max_user_watches = 1209446
 fs.file-max = 586836
 fs.file-nr = 8992       0       586836
 fs.inode-nr = 96800     290
 fs.inotify.max_user_watches = 8192
 fs.lease-break-time = 45
 kernel.sched_cfs_bandwidth_slice_us = 5000
 kernel.sched_child_runs_first = 0
 kernel.version = #1 SMP PREEMPT Fri Jan 31 10:22:54 CET 2014
 kernel.watchdog = 1
 kernel.watchdog_thresh = 10
 kernel.yama.ptrace_scope = 1
 net.core.bpf_jit_enable = 0
 net.core.busy_poll = 0
 net.ipv4.cipso_cache_bucket_size = 10
 net.ipv4.conf.all.accept_local = 0
```</p>

<p><strong>O</strong> retorno deste comando é bastante extenso, portanto colei aqui apenas algumas linhas aleatórias de meu resultado.</p>

<p><strong>P</strong>ara alterar temporariamente um parâmetro, utilize o parâmetro -w do sysctl, indicando a variável que deseja alterar e o novo valor que será utilizado para a mesma.</p>

<p><code>
 [kalib@tuxcaverna ~]$ sysctl -w {nome-da-variável=valor}
</code></p>

<p><strong>N</strong>o caso acima a(s) alteração(ões) será(ão) perdida(s) após a reinicialização do sistema.</p>

<p><strong>C</strong>aso deseje realizar alterações permanentes, edite o arquivo <em>/etc/sysctl.conf</em> e em seguida aplique suas modificações com o parâmetro -p do sysctl.</p>

<p><code>
 [kalib@tuxcaverna ~]$ sysctl -p
</code></p>

<p><strong>D</strong>esta forma, após a reinicialização suas modificações permanecerão ativas.</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BlackArch Linux - Uma nova distribuição para Pentesters]]></title>
    <link href="http://kalib.github.io/blog/2014/01/30/blackarch-linux-uma-nova-distribuicao-para-pentesters/"/>
    <updated>2014-01-30T08:47:00-05:00</updated>
    <id>http://kalib.github.io/blog/2014/01/30/blackarch-linux-uma-nova-distribuicao-para-pentesters</id>
    <content type="html"><![CDATA[<p><img class="left" src="/imgs/blackarch.jpg" title="&lsquo;BlackArch&rsquo;" ></p>

<p><strong>U</strong>ma boa novidade para os profissionais de segurança: <a href="http://www.blackarch.org" target="_blank">BlackArch</a>! Para quem, assim como eu, gosta de como as coisas funcionam no Arch Linux essa é uma notícia particularmente boa, visto que o BlackArch não se trata realmente de uma nova distribuição, mas sim de uma <em>extensão</em> para o Arch Linux. Como assim? Bom, você possui duas opções para utilizar o BlackArch, sendo uma delas como uma distribuição completa, através de um Live CD, por exemplo, e a outra como uma extensão (um repositório de pacotes) para o Arch Linux, onde você poderá apenas inserir um repositório em sua já existente distribuição Arch Linux e ter acesso ao conjunto de ferramentas do BlackArch.</p>

<p><strong>O</strong> BlackArch, atualmente, possui suporte para as arquiteturas i686 e x86_64, com previsão de suporte para ARM em breve (Sim, meu RaspBerry poderá se tornar uma ferramenta para pentests). No mais, o BlackArch hoje possui mais de 600 ferramentas, estando este número crescendo constantemente, e utiliza grupos modulares de pacotes, facilitando a instalação dos mesmos.</p>

<p><strong>A</strong> ISO Live trás diversos gerenciadores de janelas ou ambientes gráficos, como o dwm, Fluxbox, Openbox, Awesome, Wmii, i3 e Spectrwm. É claro, ele também trás um instalador capaz de instalar a partir do fonte.</p>

<p><strong>D</strong>entre as ferramentas existentes estão: 3proxy, 42zip, acccheck, aesfix, against, airflood, airoscript, bluepot, blueprint, braces, bss, bully, cisco-ocs, cmospwd, dbd, dc3dd, deblaze, dhcpig, enumiax, fakedns, &hellip; Vocẽ não espera que eu liste todos os mais de 600, certo?</p>

<p><a href="http://blackarch.org/images/screenshots/openbox.png" target="_blank"><img class="center" src="/imgs/openbox.png" title="&lsquo;BlackArch Openbox&rsquo;" ></a></p>

<p><strong>Configurando como um Repositório Não-Oficial</strong></p>

<p><strong>S</strong>e você já possui o Arch Linux instalado e deseja apenas inserir o BlackArch como um repositório em sua distro, execute os seguintes comandos como root, os quais servirão para assinar os pacotes: <em>(Se você não possui o Arch Linux instalado e/ou simplesmente deseja rodar o Live CD ou instalar o mesmo por completo, seja em uma máquina física ou virtual, siga para a seção <a href="#instalando">Instalando o BlackArch Linux utilizando a Live-ISO</a>)</em></p>

<p>```
 # wget -q <a href="http://blackarch.org/keyring/blackarch-keyring.pkg.tar.xz">http://blackarch.org/keyring/blackarch-keyring.pkg.tar.xz</a>{,.sig}</p>

<p> # gpg &mdash;keyserver hkp://pgp.mit.edu &mdash;recv 4345771566D76038C7FEB43863EC0ADBEA87E4E3</p>

<p> # gpg &mdash;keyserver-o no-auto-key-retrieve &mdash;with-f blackarch-keyring.pkg.tar.xz.sig</p>

<p> # pacman-key &mdash;init</p>

<p> # rm blackarch-keyring.pkg.tar.xz.sig</p>

<p> # pacman &mdash;noc -U blackarch-keyring.pkg.tar.xz
```</p>

<p><strong>E</strong>m seguida, adicione as seguintes linhas ao seu arquivo <em>/etc/pacman.conf</em>:</p>

<p><code>
  [blackarch]
  Server = &lt;mirror_site&gt;/$repo/os/$arch
</code></p>

<p><strong>Substitua</strong> <em>&lt;mirror_site></em> por um mirror de sua escolha, preferencialmente um dos <strong>mirrors oficiais</strong> contidos <a href="http://blackarch.org/download.html#mirrors" target="_blank"><em>neste link</em></a>.</p>

<p><strong>U</strong>ma vez que você tenha seguido os passos acima, execute:</p>

<p><code>
 $ sudo pacman -Syyu
</code></p>

<p><strong>Instalando os pacotes</strong></p>

<p><strong>A</strong>gora que você já preparou o terreno assinando e configurando o repositório do Black Arch, basta instalar os pacotes em seu Arch Linux.</p>

<p><strong>P</strong>ara listar todas as ferramentas disponíveis, execute:</p>

<p><code>
 $ sudo pacman -Sgg | grep blackarch | cut -d' ' -f2 | sort -u
</code></p>

<p><strong>P</strong>ara instalar todas as ferramentas, execute:</p>

<p><code>
 $ sudo pacman -S blackarch
</code></p>

<p><strong>P</strong>ara instalar uma categoria de ferramentas, execute:</p>

<p><code>
 $ sudo pacman -S blackarch-&lt;categoria&gt;
</code></p>

<p><strong>P</strong>ara ver as categorias existentes no BlackArch, execute:</p>

<p><code>
 $ sudo pacman -Sg | grep blackarch
</code></p>

<p><strong><a name="instalando">Instalando o BlackArch Linux utilizando a Live-ISO</a></strong></p>

<p><strong>A</strong>ntes de mais nada, <a href="http://blackarch.org/download.html" target="_blank">baixe a ISO a partir do site oficial</a>.</p>

<p><strong>E</strong>m seguida, dê boot na ISO e instale o script de instalação do BlackArch:</p>

<p><code>
 $ sudo pacman -S blackarch-install-scripts
</code></p>

<p><strong>A</strong>gora, basta instalar:</p>

<p><code>
 # blackarch-install
</code></p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
</feed>
