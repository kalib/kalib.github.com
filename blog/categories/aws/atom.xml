<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AWS | Marcelo Cavalcante Rocha ~]]></title>
  <link href="https://kalib.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="https://kalib.github.io/"/>
  <updated>2018-10-27T18:54:30-04:00</updated>
  <id>https://kalib.github.io/</id>
  <author>
    <name><![CDATA[Marcelo Cavalcante Rocha - Kalib]]></name>
    
  </author>
  <generator uri="https://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Infraestrutura como Código com Terraform]]></title>
    <link href="https://kalib.github.io/blog/2018/10/22/infraestrutura-como-codigo-com-terraform/"/>
    <updated>2018-10-22T21:26:00-04:00</updated>
    <id>https://kalib.github.io/blog/2018/10/22/infraestrutura-como-codigo-com-terraform</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/terraform.png" title="&lsquo;Terraform&rsquo;" ></p>

<h2>Infraestrutura como Código (IAC &ndash; Infrastructure as Code)</h2>

<p><strong>I</strong>nfraestrutura como código &ndash; IaC (ou infrastructure as code em inglês) &ndash; é o processo de gerenciamento e provisionamento de recursos de infraestrutura através de códigos ou arquivos de configuração que descrevem o estado desejado para tal infraestrutura ou recursos de infraestrutura. A principal característica de IaC é o uso de scripts ou definições declarativas ao invés de processos manuais, mas o termo é utilizado com mais frequência para promover abordagens declarativas. Como se tratam de arquivos de código, as definições podem ser armazenadas em um sistema de controle de versões, tal como o Git.</p>

<p><strong>A</strong>bordagens IaC são comumente promovidas para computação em nuvem e às vezes são comercializadas como infraestrutura como serviço (infrastructure as a service, IaaS). IaC suporta IaaS, mas os dois conceitos não devem ser confundidos.</p>

<h2>IaC e DevOps</h2>

<p><strong>I</strong>aC, ou Infraestrutura como Código é um conceito bastante ligado à filosofia DevOps, visto que com práticas de implementação de uma infraestrutura baseada em códigos declarativos podemos aproximar as equipes de Operações e Desenvolvimento, fazendo com que os desenvolvedores tornem-se mais envolvidos nas configurações de máquinas ou recursos de infraestrutura como um todo, enquanto que os profissionais de Operações se envolvem mais cedo no processo de desenvolvimento. Além disso, agora ambas as equipes podem armazenar seu código em um mesmo ambiente, como por exemplo repositórios Git.</p>

<p><strong>I</strong>nfraestrutura como código mostrou-se uma excelente solução para livrar equipes de tarefas enfadonhas do cotidiano realizadas manualmente. Além de tomarem muito tempo e serem tarefas extremamente repetitivas, os corriqueiros processos manuais estão sujeitos a erros e podem colocar as operações em risco.</p>

<h4>Algumas vantagens da utilização de IaC</h4>

<ul>
<li><p><strong>Elimina tarefas repetitivas</strong> &ndash; Se você precisa criar 3 clusters Kubernetes em seu provedor de cloud (GCP ou AWS, por exemplo), você não precisa repetir os mesmos passos 3 vezes. Escreve um bloco de código que define a criação de um cluster e poderá aplicar este mesmo código quantas vezes forem necessárias;</p></li>
<li><p><strong>Documentação simplificada</strong> &ndash; Não há necessidade de logar-se em um servidor ou provedor de cloud para tentar vasculhar tudo o que foi configurado (está tudo no código);</p></li>
<li><p><strong>Reaproveitamento</strong> &ndash; Uma vez que tudo está codificado e separado em módulos, fica fácil reaproveitar módulos e código para futuras implementações;</p></li>
<li><p><strong>Simples manutenção</strong> &ndash; Mudanças na configuração, versões, regras e demais definições podem ser implementadas e aplicadas rapidamente com pequenas alterações no código;</p></li>
<li><p><strong>Versionamento</strong> &ndash; Ao abordar nossa infraestrutura como código passamos a ter diversos benefícios já rotineiros para desenvolvedores, como por exemplo a possibilidade de gerenciar nosso código em sistemas de versionamento como o Git, de forma a facilitar o trabalho em equipes, controle de versões, mudanças, etc;</p></li>
<li><p><strong>Agilidade</strong> &ndash; Se preciso trocar a faixa de endereços IP de uma VPC ou subnet, alterar uma linha de código é muito mais rápido do que logar em uma dashboard, procurar tal recurso e alterar manualmente os valores desejados;</p></li>
<li><p><strong>Possibilidade de soluções agnósticas</strong> &ndash; Em um mundo tecnológico que muda constantemente não são raras as ocasiões em que temos de mudar completamente nossa infraestrutura, seja deixando de usar servidores físicos para passar a utilizar VMs, ou migrando de VMs locais para a nuvem, ou de VMs na nuvem para containers, etc. Independente de qual seja o cenário de mudança, uma vez que sua infraestrutura está definida em código, dependendo das ferramentas escolhidas para codificar sua infra, o mesmo código poderia ser utilizado para um ambiente VMWare, AWS, Azure, GCP, etc, com poucas modificações. (Já citei agilidade e Simples manutenção, certo?!);</p></li>
<li><p><strong>Fácil replicar</strong> &ndash; Em um ambiente não codificado ou automatizado, geralmente repetimos as mesmas configurações para criarmos ambientes distintos como Produção, Teste, Desenvolvimento, etc. Uma vez que sua infra está codificada, você aplica o mesmo código para criar quantos ambientes desejar;</p></li>
<li><p><strong>Recuperação de Desastres ou Disaster Recovery</strong> &ndash; Desastres acontecem. Imagine um problema grande em sua infraestrutura. Em um cenário de virtualização, imagine que seu host VMWare simplesmente parou de funcionar pois seu disco queimou. Ou que o storage onde se encontravam as suas VMs simplesmente foi destruído. Ou, em um ambiente de cloud, imagine que sua senha de administrador da nuvem vazou e seu ambiente foi completamente excluído. Ou mesmo que o próprio data center ou região na qual se encontra a sua infra estrutura teve algum problema sério e toda a sua infra caiu. Claro, as boas práticas já pregam há muito tempo que sempre devemos ter backups de todos os servidores e sistemas, mas backups nada mais são do que arquivos. E a infraestrutura de fato? Você precisa ter uma infraestrutura ativa antes de conseguir restaurar backups, certo? Rede, firewall, VPCs, Clusters, Servidores, etc.. Se você possui toda a sua infraestrutura em código, recuperar tudo isso é tão simples quanto executar um único comando.</p></li>
<li><p><strong>Planejamento (plan) e Testes</strong> &ndash; Práticas como planejamento e testes fazem parte (ou ao menos deveríam fazer) da rotina de praticamente qualquer desenvolvedor. Profissionais de infraestrutura sempre tiveram uma desvantagem em relação a isso, pois era complicado fazer testes de infraestrutura. Teste basicamente significava instalar exatamente a mesma infraestrutura em um ambiente isolado para testes. Ainda possível, porém pouco confiável e com altas chances de falhas, pois, por ser um processo manual e lento, não há qualquer garantia de que todos os mesmos passos serão executados no ambiente de produção tal como foram executados no ambiente de teste. Com infraestrutura como código, fica fácil utilizar-se das mesmas técnicas de planejamento e testes automatizados há muito utilizadas por desenvolvedores. Agora você consegue executar testes no código de sua infraestrutura que, literalmente, irão avaliar cada bloco de seu código e simular a execução de cada expressão ou descrição, dando-lhe assim uma visão geral sobre o que acontecerá, o que funcionará e o que falhará, garantindo uma integradade fiel entre teste e implantação em produção ou demais ambientes.</p></li>
</ul>


<p><strong>L</strong>indo, não? Lembro de meus tempos de faculdade, quando costumava dizer a meus colegas que todos os profissionais de TI deveríam saber programar, independente de desejarem ou não trabalhar com programação. Na ocasião, em meados de 2006, a maioria deles dizia que isso era loucura. &ldquo;Porque aprender a programar se vou trabalhar com infraestrutura?&rdquo; Bom, tudo o que posso dizer hoje é: Bem vindos à era DevOps.</p>

<p><strong>Q</strong>uando falamos em infraestrutura como código, existem diversas ferramentas que trabalham em cima deste conceito, e muitas delas atuam juntas para englobar soluções mais completas, mas uma de minhas favoritas é o <a href="https://www.terraform.io">Terraform</a>, da <a href="https://www.hashicorp.com/">Hashicorp</a>.</p>

<h2>Escolha da ferramenta ideal para IAC</h2>

<p><strong>C</strong>om uma simples busca no Google pelo termo &ldquo;ïnfraestrutura como código&rdquo; ou &ldquo;IAC&rdquo;, será extremamente fácil encontrar diversas ferramentas, dentre as mais populares estão Chef, Puppet, Ansible, SaltStack, Terraform, CloudFormation, etc.</p>

<p><strong>U</strong>m problema comum para quem inicia no mundo DevOps ou simplesmente deseja começar a utilizar infraestrutura como código é justamente a escolha. Qual a melhor ferramenta? Qual devo utilizar?</p>

<p><strong>E</strong>esta é uma dificuldade comum e inerante ao fato de se ter muitas opções. Se em uma sorveteria você só possui os sabores chocolate e baunilha, é extremamente simples optar por um, outro ou nenhum dos dois. No entanto, em uma sorveteria com 50 sabores, você provavelmente perderá alguns minutos apenas lendo todas as opções, do contrário irá apostar na sorte e escolher o primeiro que lhe parecer apetitoso, correndo o risco de descartar algum que não chegou a ver, mas que poderia ser muito melhor e refrescante para um dia quente como os do nordeste cearense.</p>

<p><strong>O</strong> mais importante é sempre realizar uma pesquisa sobre pontos fortes e fracos de cada uma delas antes de tomar uma decisão, tendo em mente alguns aspectos:</p>

<ul>
<li><p>A escolha não deve (ou não deveria) ser puramente pessoal. A melhor ferramenta dificilmente será a que você gostou mais de utilizar. A melhor ferramenta será a que melhor atende as necessidades do seu projeto ou negócio;</p></li>
<li><p>A análise deve ser feita em diversos aspectos, e não apenas em um ou dois. Supondo que você pesquise por exemplo quais possuem mais módulos gratuitos e quais delas possuem uma comunidade mais ativa na internet para dúvidas, mas esqueceu de ponderar o preço para ter acesso a suporte corporativo, você pode ter feito uma boa ou uma má escolha. Em caso de ser uma pequena empresa, com prazos relativamente longos para entregas de projetos e maior flexibilidade em termos de tempo fora do ar (downtime), o suporte corporativo pode não ser um fator decisivo. No entanto, em uma empresa de ambiente mais crítico, como um banco, demais sistemas financeiros, governamentais, etc., o suporte corporativo se torna um fator mais importante, portanto escolher uma ferramenta sem ponderar o valor de seu suporte corporativo acaba sendo um tiro no pé, o que reforça a ideia de que sempre devemos avaliar o máximo de aspectos possíveis e relevantes ao nosso projeto ou ambiente;</p></li>
<li><p>Outro fator fundamental e, em meu ver o mais importante, é entender que não necessariamente a escolha será exclusiva. Imagine que você precisa montar uma mesa que veio toda desmontada: tábuas, parafusos, gavetas, etc. Você tem algumas ferramentas a disposição, como chave de fendas, martelo, régua, serra, furadeira, etc. Você pode ser uma espécie de rambo e gostar de resolver as coisas com uma ferramenta só e, sinceramente, você pode até ser capaz de conseguir montar a mesa inteira apenas utilizando o martelo, parabéns por isso. Mas será que essa é a forma mais eficiente de resolver o problema? Será que não seria mais rápido e organizado utilizando um martelo e uma chave de fendas? Afinal, temos parafusos também, certo?!</p></li>
</ul>


<p><strong>C</strong>onforme descrito acima, o ideal é sempre avaliar o projeto ou ambiente no qual se irá trabalhar, sem a necessidade de escolher apenas uma ferramenta.</p>

<p><strong>S</strong>im, Chef, Puppet e Ansible são ferramentas de Infraestrutura como Código, no entanto elas possuem tarefas mais específicas, nas quais possuem mais desempenho, como por exemplo o gerenciamento de configurações, para não listar todas as suas funções.</p>

<p><strong>E</strong>, claro, o CloudFormation é uma excelente ferramenta da Amazon para criação de infraestrutura como código, no entanto ela fica restrita ao ambiente de cloud da Amazon, o AWS. E se meu projeto estiver utilizando VMs em um ambiente VMWare? Ou se eu utilizar Google Cloud? Ou mesmo um ambiente mais heterogênio, com VMWare, Google Cloud e Amazon AWS? O CloudCloudFormation não seria a melhor opção, por ser restrito ao ambiente AWS.</p>

<p><strong>S</strong>empre fui a favor de utilizar as ferramentas corretas para cada tarefa em específico, portanto porque utilizar apenas uma se tenho outras disponíveis?</p>

<p><strong>O</strong> <a href="https://www.terraform.io">Terraform</a>, por outro lado, é específico para a criação da infraestrutura base, se saindo muito melhor do que Chef, Ansible ou Puppet nesta tarefa, mas nada impede (e eu encorajo e o faço) que você utilize Chef, Puppet ou Ansible, para gerenciar configurações, bootstraping ou deployments na infraestrutura criada pelo Terraform.</p>

<p><strong>A</strong>lém do mais, diferente do CloudFormation, o Terraform é uma solução agnóstica, permitindo-lhe criar infraestrutura em praticamente qualquer ambiente, seja ele em Cloud (Amazon AWS, Microsoft Azure, Google GCP, IBM Cloud, Digital Ocean, etc.), ambiente virtualizado, local ou em Data Centers (VMWare, Xen, Virtual Box, etc.), Docker, Kubernetes, além de recursos diversos de infraestrutura e softwares, tais como Redes (CloudFlare, DNS, DNSimple, F5 BIG-IP, Palo Alto Networks,etc.), Bancos de Dados (InfluxDB, MySQl ou PostgreSQL), dentre muitas outras coisas.</p>

<h2>Terraform</h2>

<p><strong>O</strong> Terraform, da Hashicorp, lhe permite criar, alterar e melhorar sua infraestrutura de forma segura e previsível. É uma ferramenta Open Source que codifica APIs em arquivos de configuração declarativos que podem ser compartilhados entre membros de um time, tratados como código, editados, revisados e versionados.</p>

<p><img class="center" src="/imgs/terraform-flow.png" title="&lsquo;Terraform Flow&rsquo;" ></p>

<p><strong>A</strong> imagem acima descreve bem o fluxo básico da utilização de Terraform para codificar sua infraestrutura, na qual o fluxo mais simplista é:</p>

<ul>
<li>Escrever o código de sua infraestrutura;</li>
<li>Planejar a execução do seu código, de forma que você receba informações antecipadamente de tudo o que acontecerá quando você aplicar o seu código;</li>
<li>Crie uma infraestrutura reproduzível ao aplicar seu código.</li>
</ul>


<p><strong>A</strong>pesar de este ser o fluxo mais simplista, com a utilização de infraestrutura como código você pode melhorar seu fluxo inserindo colaboração e compartilhamento, armazenando e gereciando seu código em um repositório git, por exemplo, além de ter assim um registro completo das mudanças e evoluções de sua infraestrutura, facilitando a automação em fluxos mais complexos, como por exemplo em pipelines de Integração Contínua.</p>

<p><strong>O</strong> Terraform funciona basicamente através de recursos, ou resources, que definem o tipo de infraestrutura você estará criando bem como seus atributos. Além disso, conforme dito anteriormente, o Terraform também pode ser utilizado em paralelo com diversas outras ferramentas de automação em forma de provedores, ou providers, como Puppet, Chef, Ansible, etc.</p>

<p><strong>P</strong>or estarmos tentando aplicar para a infraestrutura um conceito que seja mais próximo do que já era utilizado por desenvolvedores há muito tempo, o Terraform possui também uma abordagem que lhe permite reaproveitamento de código, através de módulos. Existem diversos módulos criados e disponibilizados gratuitamente, mas você pode também criar seus próprios módulos de forma a melhor organizar e reaproveitar seu próprio código em diversos projetos.</p>

<p><strong>A</strong>rquivos de configuração descrevem ao Terraform os componentes necessários para rodar uma única aplicação que representa todo o seu datacenter. O Terraform gera um plano de execução descrevendo o que fará para alcançar o estado desejado, e em seguida, caso aprovado, o executará para criar a infraestrutura desejada. Conforme a configuração muda, o Terraform será capaz de determinar o que mudou e criará planos de execução incrementais que podem ser aplicados.</p>

<p><strong>V</strong>ejamos o seguinte diagrama que descreve uma simples infraesturura. Imaginemos que esta é a infraestrutura que queremos rodar em nossa conta no Google Cloud para termos um site de e-commerce:</p>

<p><img class="center" src="/imgs/diagrama-ecommerce.png" title="&lsquo;Kalib Ecommerce&rsquo;" ></p>

<p>O diagrama acima possui diversos elementos:</p>

<ol>
<li>Uma organização no Google Cloud chamada Kalib Avante;</li>
<li>Um diretório ou Folder (como chamado no Google Cloud) chamado Projetos;</li>
<li>Um projeto chamado E-Commerce;</li>
<li>Um projeto chamado Zebra Feliz;</li>
<li>Dentro do projeto E-Commerce temos dois ambientes: Produção e Teste</li>
<li>Repare que o projeto Zebra Feliz está incompleto e sem ambientes distintos, como Produção, teste, etc. Bom, trata-se de um projeto piloto ainda em desenvolvimento e planejamento, portanto os recursos não foram ainda criados por completo. Mas o Terraform nos permite incrementar recursos quando necessário, certo? Portanto, sem problemas com isto por enquanto.</li>
</ol>


<p><strong>E</strong>sta é a estrutura básica, já em termos de recursos temos Firewalls, clusters kubernetes com Nodes, buckets de storage para conservar o status ou state do Terraform e por consequência de sua infraestrutura, Discos persistentes, Container Registry (repositório de imagens Docker), VPCs, Load Balancer, VMs, etc.</p>

<p><strong>C</strong>aso esteja se perguntando, sim o Terraform lhe permite criar esta infraestrutura inteira, bem como outras bem mais complexas, com mais projetos, mais ambientes, mais recursos, etc.</p>

<p><strong>D</strong>esta forma podemos ter um código terraform dividido em alguns módulos, armazenado em um repositório Git, por exemplo, e criar toda essa infraestrutura, desde a Organização vazia, ao diretório de projetos, aos 2 projetos em si, buckets, clusters kubernetes, DNS, IAM, load balancer, VMs por trás do Load Balancer, etc. Tudo isto com um único comando:</p>

<p><code>
terraform apply
</code></p>

<p><strong>L</strong>embrando um pouco do que falamos lá em cima, sobre ser simples reproduzir, ou se recuperar de desastres&hellip; imagine que uma região inteira caiu no Google, onde temos nossa infraestrutura. Sim, eu sei que isso é extremamente raro, mas vamos imaginar os cenários mais absurdos e raros também. Imagine que perdi toda a minha infraestrutura. Imagine ter que recriar tudo isso (projetos, diretórios, storages, DNS, IAM, clusters, Load Balancer, VMs, etc, etc..) manualmente..? Demoraria bastante, certo?! Mas, como fomos espertos e criamos tudo via terraform, um simples <strong>terraform apply</strong> irá criar tudo novamente para nós, exatamente como era antes.</p>

<p><strong>O</strong> mesmo se dá caso precisemos recriar toda essa mesma infraestrutura em uma nova região do Google, ou caso queiramos destruir nossa infra e recriá-la em outra zona, por algum motivo.</p>

<p><strong>A</strong>qui estamos lidando apenas com a Infraestrutura pois, conforme dito antes, o Terraform é excelente para criar a infraestrutura, mas o ideal ainda é utilizar outros softwares para provisionamento e deployment. Por exemplo, uma vez que temos nossa infraestrutura inteira criada, podemos começar a provisionar os sistemas e softwares através de outras ferrmentas, como Helm (para deployment dentro dos clusters Kubernetes), Chef, Puppet, Ansible, etc.</p>

<p><strong>A</strong> ideia deste post é apenas dar uma introdução teórica, uma ideia de como infraestrutura como código funciona, e de como o Terraform é capaz de fazer tudo isso de forma segura e robusta. (Embora eu já veja uma enorme barra de rolagem aqui ao lado e sei que lhe fiz ler bastante, supondo que leu até aqui. :p)</p>

<p><strong>E</strong>m meu próximo post pretendo fazer uma abordagem mais prática e com mão na massa, utilizando de fato o Terraform para criar uma simples infraestrutura via código.</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Criando uma Imagem AWS EC2 com Packer e Puppet]]></title>
    <link href="https://kalib.github.io/blog/2018/08/11/criando-uma-imagem-aws-ec2-com-packer-e-puppet/"/>
    <updated>2018-08-11T09:12:00-04:00</updated>
    <id>https://kalib.github.io/blog/2018/08/11/criando-uma-imagem-aws-ec2-com-packer-e-puppet</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/packer_puppet_aws_bash.png" title="&lsquo;Packer_Puppet_Bash_AWS&rsquo;" ></p>

<h2>Packer, Puppet, Bash e AWS</h2>

<p><strong>A</strong> plataforma AWS da Amazon é atualmente uma das maiores e mais populares quando o assunto é Cloud e automação em nuvem, permitindo o uso de soluções de infra estrutura completamente na nuvem, sem a necessidade de termos Hardware físico, otimizando custos e nos dando mais flexibilidade.</p>

<p><strong>A</strong> própria plataforma nos disponibiliza diversos recursos para facilitar a implementação de nossas soluções e tornar nossas tarefas rotineiras mais simples. Por exemplo, para a criação de VMs, ou instâncias, no AWS de forma mais rápida, podemos utilizar uma imagem previamente criada, de forma que possamos evitar alguns passos e configurações repetitivas.</p>

<p><strong>U</strong>ma vez que eu identifico uma necessidade para minha aplicação e sei que preciso de uma máquina virtual com configurações e aplicações específicas para poder rodar minha aplicação, eu posso criar uma imagem com todos estes pré-requisitos de forma que ao resolver criar uma nova VM, eu não precise realizar todos estes passos manualmente. Além de evitar trabalho repetitivo, nos garante uma maior flexibilidade ao ter nossa infraestrutura como código, de forma que podemos literalmente ter as instruções que compõem nossa infraestrutura em um repositório Git, por exemplo, além de nos permitir realizar alterações nesta imagem também de forma simples e rápida para a geração de novas imagens de instâncias com as nossas alterações em poucos segundos ou minutos, dependendo da quantidade de alterações envolvdidas.</p>

<p><strong>S</strong>e você ainda não faz ideia de o que seja o Packer ou o que ele é capaz de fazer, sugiro que volte uma casa e leia meu <a href="https://blog.marcelocavalcante.net/blog/2018/07/30/automatizando-a-criacao-de-imagens-com-packer/">post anterior</a>, onde explico o que é o Packer e apresento um simples exemplo de seu uso para a criação de imagens para o Docker.</p>

<p><strong>O</strong> intuito deste post é mostrar como podemos estruturar um simples código para que possamos criar uma imagem no AWS que poderá ser utilizada posteriormente para a criação de instâncias. Esta imagem será criada através do Packer e, para incrementar ainda mais nossa imagem, utilizaremos o recurso de provisioners (ou provisionadores/provedores) disponível no Packer. Utilizaremos dois provisioners como recursos externos para o provisionamento e configuração de nossa imagem, sendo eles bash script e <a href="https://puppet.com/">Puppet</a>.</p>

<h2>AWS</h2>

<p><strong>U</strong>ma vez que estou assumindo que você já possui o Packer instalado, bem como que você já possui uma ideia de como ele funciona, vamos iniciar pelo AWS. (Ainda não possui o Packer e não sabe o que ele faz? Novamente, <a href="https://blog.marcelocavalcante.net/blog/2018/07/30/automatizando-a-criacao-de-imagens-com-packer/">volte uma casa</a>.)</p>

<p><strong>O</strong> primeiro pré-requisito para este post/tutorial é uma conta no AWS. Caso você não possua uma e queira repetir os passos aqui descritos, siga e crie uma. Lembrando que o AWS lhe dá uma série de recursos que podem ser utilizados gratuitamente no que eles chamam de &ldquo;Free Tier&rdquo;. Uma vez que utilizaremos apenas recursos simples aqui, você não deverá ser cobrado por nada ao seguir os exemplos deste post. O ideal é que você exclua os recursos ou encerre sua conta após o término deste exercício para evitar ser cobrado por algo. Caso não o faça e resolva continuar testando algumas coisas no AWS, você pode ser cobrado em alguns centavos ou reais, dependendo de o que resolva testar e por quanto. (Sua responsabilidade, claro.)</p>

<p><strong>A</strong> conta no AWS pode ser criada aqui: <a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a></p>

<p><strong>U</strong>ma vez que a conta no AWS esteja criada e pronta para uso, o primeiro passo será de fato conseguir uma chave para que possamos nos comunicar com o AWS via CLI através de uma API. Durante a criação de nosso código com o Packer precisaremos utilizar esta chave de acesso, portanto vá em frente e crie uma através deste link: <a href="https://console.aws.amazon.com/iam/home?#security_credential">https://console.aws.amazon.com/iam/home?#security_credential</a></p>

<p><strong>C</strong>lique na opção Access Keys, ou Chaves de Acesso, e crie uma nova. <strong>É extremamente importante</strong> que você esteja atento neste momento, pois ele apenas lhe mostrará o ID e senha para a chave uma única vez, portanto esteja pronto para copiar e salvar ambos os valores. Será algo similar a isto:</p>

<p><img class="center" src="/imgs/aws_key.png" title="&lsquo;AWS Key&rsquo;" ></p>

<p><strong>É</strong> claro que eu já excluí essa chave&hellip; :p Não perca seu tempo&hellip; >]</p>

<p><strong>U</strong>ma vez que você tenha salvo ambos os valores, vamos tratar da identificação/autenticação com o AWS.</p>

<p><strong>O</strong> mecanismo padrão do Packer de autenticação neste caso seria através de duas variáveis em nosso arquivo json:</p>

<p>```
{
  &ldquo;builders&rdquo;: [{</p>

<pre><code>"type": "amazon-ebs",
"access_key": "SUA ACCESS KEY AQUI",
"secret_key": "SUA SECRET ACCESS KEY AQUI",
</code></pre>

<p>&hellip; &hellip; &hellip;
```</p>

<p><strong>E</strong>mbora seja a forma mais simples, não a utilizaremos. Fica claro que não é uma forma muito segura, certo?! Quando se pensa em infraestrutura como código, um dos principais objetivos é podermos versionar e hospedar nosso código em um repositório Git, por exemplo. Ter nossa chave como parte do código não é nada seguro, especialmente se vamos compartilhar este código em um repositório Git.</p>

<p><strong>A</strong> forma mais simples de lidarmos com isso é salvando nossa chave e senha como variáveis de ambiente e, em nosso arquivo json, importarmos estas variáveis de ambiente diretamente.</p>

<p><strong>E</strong>m Linux ou OS X, digite o seguinte em um terminal ou console:</p>

<p><code>
$ export AWS_ACCESS_KEY_ID=SUA ACCESS KEY AQUI
$ export AWS_SECRET_ACCESS_KEY=SUA SECRET ACCESS KEY AQUI
</code></p>

<p><strong>C</strong>ertifique-se de que os valores foram definidos corretamente:</p>

<p><code>
$ echo $AWS_ACCESS_KEY_ID
$ echo $AWS_SECRET_ACCESS_KEY
</code></p>

<p>Por hora isso é tudo de que precisaremos para o AWS.</p>

<h2>Packer</h2>

<p><strong>H</strong>ora de começarmos a escrever nosso código que será utilizado pelo Packer para a criação de nossa imagem.</p>

<p><strong>D</strong>esta vez estaremos criando uma imagem EC2 para o AWS, portanto alguns provisioners e parâmetros serão diferentes dos utilizados no <a href="https://blog.marcelocavalcante.net/blog/2018/07/30/automatizando-a-criacao-de-imagens-com-packer/">post anterior</a>, onde criamos uma imagem para o Docker.</p>

<p><strong>C</strong>omecemos criando um arquivo json vazio. Chamarei meu arquivo de <em>ubuntuaws.json</em>.</p>

<p><strong>A</strong> primeira coisa que faremos é incluir as credenciais de nossa conta no AWS. Como criamos duas variáveis de ambiente em nosso host, chamadas <em>AWS_ACCESS_KEY_ID</em> e <em>AWS_SECRET_ACCESS_KEY</em>, invocaremos estas duas variáveis da seguinte forma no início de nosso arquivo: <em>env `AWS_ACCESS_KEY_ID`</em>, etc&hellip; Vamos ao código.</p>

<p>```
{
  &ldquo;variables&rdquo;: {</p>

<pre><code>"aws_access_key": "{{env `AWS_ACCESS_KEY_ID`}}",
"aws_secret_key": "{{env `AWS_SECRET_ACCESS_KEY`}}",
"region": "us-east-1"
</code></pre>

<p>  },
}
```</p>

<p><strong>N</strong>ormalmente uma varíavel poderia ser declarada apenas com <em>&ldquo;aws_access_key&rdquo;: &ldquo;sua_chave&rdquo;</em>, conforme fizemos com a variável <em>region</em> acima, no entanto, por questões de segurança, não queremos ter nossa chave exposta no código, certo?! Portanto, estamos trazendo os valores diretamente das variáveis de ambiente que criamos. A utilização do parâmetro <em>env</em> é o que indica ao Packer que ele deverá buscar estas variáveis em nosso <em>env</em> (environment).</p>

<p><strong>É</strong> importante lembrar que o aws possui datacenters e recursos em diversas regiões do mundo. Você não precisa obrigatoriamente utilizar a região <em>us-east-1</em>. Optei por utilizar esta região em meu código pelo fato de eu morar em Toronto, o que faz desta região uma boa escolha para meus recursos de nuvem por conta da proximidade (menor delay).</p>

<p><strong>S</strong>e você está no Brasil, provavelmente a melhor opção seja <em>sa-east-1</em>, a qual se encontra em São Paulo. De qualquer forma, você pode verificar a lista de regiões disponíveis no AWS através <a href="https://docs.aws.amazon.com/pt_br/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">deste link</a>.</p>

<p><strong>A</strong>té então nosso código está simples e não faz basicamente nada além de definir as duas variáves para nossa autenticação, mas ainda assim é importante termos certeza de que não cometemos nenhum erro de sintaxe:</p>

<p>```
$ packer validate ubuntuaws.json
Error initializing core: 1 error(s) occurred:</p>

<ul>
<li>at least one builder must be defined
```</li>
</ul>


<p><strong>P</strong>or enquanto ignore este erro, nossa sintaxe esta correta. O Packer apenas está nos dizendo que não conseguiu iniciar o projeto pois ao menos um builder deve ser definido e, até então, nós não definimos nenhum. Este será o nosso próximo passo. Desta vez, ao invés de utilizarmos um builder do tipo Docker, utilizaremos um do tipo <em>amazon-ebs</em>. Começaremos inserindo uma vírgula ao fim do bloco de variáveis e nosso código agora ficará da seguinte forma:</p>

<p>```
{
  &ldquo;variables&rdquo;: {</p>

<pre><code>"aws_access_key": "{{env `AWS_ACCESS_KEY_ID`}}",
"aws_secret_key": "{{env `AWS_SECRET_ACCESS_KEY`}}",
"region": "us-east-1"
</code></pre>

<p>  },
&ldquo;builders&rdquo;: [{</p>

<pre><code>"type": "amazon-ebs",
"access_key": "{{user `aws_access_key`}}",
"secret_key": "{{user `aws_secret_key`}}",
"region": "{{user `region`}},
"source_ami_filter": {
  "filters": {
  "virtualization-type": "hvm",
  "name": "ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*",
  "root-device-type": "ebs"
  },
  "owners": ["099720109477"],
  "most_recent": true
},
"instance_type": "t2.micro",
"ssh_username": "ubuntu",
"ami_name": "packer-example {{timestamp}}"
</code></pre>

<p>  }]
}
```</p>

<p><strong>O</strong> que temos agora:</p>

<p><em>builders:</em> Inciamos nosso bloco de builders com as intruções ou parâmetros que definirão as especificações mais básicas para a criação de nossa imagem no AWS.</p>

<p><em>type:</em> Aqui indicamos o tipo de builders que utilizaremos. No caso do EC2 do AWS, o tipo se chama <em>amazon-ebs</em>. Basicamente este builder irá utilizar uma imagem previamente existente, como as fornecidas por padrão pela Amazon, para criar uma nova imagem que poderá ser futuramente utilizada para provisionar suas instâncias EC2 com EBS (Elastic Block Storage).</p>

<p><em>access_key:</em> e <em>secret_key:</em> Aqui apenas indicamos que queremos utilizar o valor das variáveis que criamos mais acima. É importante lembrar que quando as definimos, utilizamos <em>env</em>, para indicar que a origem delas estava em nossas variáveis de ambiente. Agora estamos utilizando <em>user</em> para indicar que são variáveis criadas em nosso código mesmo (usuário).</p>

<p><em>region:</em> Novamente, assim como com as chaves, anteriormente nós declaramos esta variável e agora estamos inserindo-a em nosso código como uma variável de usuário <em>user</em>.</p>

<p><em>source_ami_filter:</em> Neste bloco iremos passar as informações básicas sobre a imagem que será utilizada como origem ou <em>source</em> base para nossa imagem. Lembrando novamente de que utilizaremos uma AMI (Amazon Machine Image) já existente por padrão no AWS.</p>

<p><em>filters:</em> Utilizaremos alguns filtros para definir a nossa imagem <em>source</em>.</p>

<p><em>virtualization_type:</em> Nosso primeiro parâmetro de filtro será o tipo de virtualização que desejamos utilizar. Se você já utilizou AWS antes, provavelmente reparou que você possui algumas formas de virtualização disponíveis, como HVM e PV. Utilizaremos HVM em nosso código.</p>

<p><em>name:</em> Aqui indicamos o nome da imagem <em>source</em> que queremos utilizar como base de nossa imagem. Como a Canonical vive atualizando suas imagens no marketplace do AWS, não utilizaremos um nome exato aqui, pois correríamos o risco de esta imagem ter sido descontinuada ou mesmo de estar desatualizada quando você estiver lendo e executando este tutorial, portanto utilizaremos um coringa (asterísco) e indicaremos um parâmetro extra para dizer que queremos utilizar a mais recente. Para nome, utilizaremos apenas: <em>ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*</em> onde o asterísco do final indica que não nos importa o final do nome, e qualquer coisa será válida.</p>

<p><em>root-device-type:</em> Indicamos <em>ebs</em> como tipo de storage para nossa imagem e tipo de instância.</p>

<p><em>owners:</em> Indicamos o dono da imagem. Na página do AWS, cada imagem é vinculada a um dono, conforme imagem abaixo:</p>

<p><img class="center" src="/imgs/aws_ubuntu_ami.png" title="&lsquo;AWS Ubuntu AMI&rsquo;" ></p>

<p><em>most_recent:</em> Este é o parâmetro que, quando definido como <em>true</em>, fará com que seja utilizada a imagem mais recente que atenda aos demais filtros utilizados para a imagem.</p>

<p><em>instance_type:</em> Indica o tipo de instância que será utilizada no AWS. O AWS possui dezenas de categorias de instâncias, onde cada categoria ou tipo possui uma quantidade diferente de memória, CPU, etc.</p>

<p><em>ami_name:</em> Finalmente, aqui indicamos o nome que queremos atribuir à nossa imagem ao final da criação da mesma.</p>

<p><strong>A</strong>gora que possuímos um código mais completo e que realmente conseguirá fazer algo, vamos validar o código e executá-lo em seguida para criarmos nossa primeira imagem no AWS.</p>

<p><code>
$ packer validate ubuntuaws.json
Template validated successfully.
</code></p>

<p><strong>C</strong>ódigo validado e sem erros.</p>

<p><strong>É</strong> importante entender o que realmente acontece durante a criação de uma imagem. O Packer não tem como executar as instruções e rodar o que queremos para criar a imagem de forma estática e mágica, portanto o que vai acontecer na verdade será o seguinte:</p>

<ol>
<li>Primeiramente o Packer irá buscar a imagem que definimos que será utilizada como fonte;</li>
<li>O packer irá criar literalmente uma instância no AWS utilizando as propriedades que definimos em nosso código para executar nossas instruções e garantir que tudo funcionará. Uma vez que todas as instruções sejam realizadas com sucesso, ele irá desligar e remover esta instância ou máquina virtual e irá salvar a imagem gerada;</li>
</ol>


<p><strong>S</strong>e durante a execução do Packer build você verificar o painel de instâncias EC2 no AWS, ficará claro que o Packer cria uma instância temporária durante a criação da imagem.</p>

<p><strong>H</strong>ora do build:</p>

<p>```
$ packer build ubuntuaws.json
amazon-ebs output will be in this color.</p>

<p>==> amazon-ebs: Prevalidating AMI Name: packer-example 1534022746</p>

<pre><code>amazon-ebs: Found Image ID: ami-5c150e23
</code></pre>

<p>==> amazon-ebs: Creating temporary keypair: packer_5b6f545a-8955-2f4f-b66a-8fd752d75bee
==> amazon-ebs: Creating temporary security group for this instance: packer_5b6f545c-0f04-553a-7944-a70d081be39d
==> amazon-ebs: Authorizing access to port 22 from 0.0.0.0/0 in the temporary security group&hellip;
==> amazon-ebs: Launching a source AWS instance&hellip;
==> amazon-ebs: Adding tags to source instance</p>

<pre><code>amazon-ebs: Adding tag: "Name": "Packer Builder"
amazon-ebs: Instance ID: i-0ef4a6036aebd0d56
</code></pre>

<p>==> amazon-ebs: Waiting for instance (i-0ef4a6036aebd0d56) to become ready&hellip;
==> amazon-ebs: Waiting for SSH to become available&hellip;
==> amazon-ebs: Connected to SSH!
==> amazon-ebs: Stopping the source instance&hellip;</p>

<pre><code>amazon-ebs: Stopping instance, attempt 1
</code></pre>

<p>==> amazon-ebs: Waiting for the instance to stop&hellip;
==> amazon-ebs: Creating the AMI: packer-example 1534022746</p>

<pre><code>amazon-ebs: AMI: ami-0bbd7494d2e6cee71
</code></pre>

<p>==> amazon-ebs: Waiting for AMI to become ready&hellip;
==> amazon-ebs: Terminating the source AWS instance&hellip;
==> amazon-ebs: Cleaning up any extra volumes&hellip;
==> amazon-ebs: No volumes to clean up, skipping
==> amazon-ebs: Deleting temporary security group&hellip;
==> amazon-ebs: Deleting temporary keypair&hellip;
Build &lsquo;amazon-ebs&rsquo; finished.</p>

<p>==> Builds finished. The artifacts of successful builds are:
&mdash;> amazon-ebs: AMIs were created:
us-east-1: ami-0bbd7494d2e6cee71
```</p>

<p><strong>V</strong>erificando em minha interface de instâncias da região que escolhi (us-east-1) posso ver que existe uma instância que foi criada mas que já foi terminada ou deletada. Esta é a instância que o Packer criou automaticamente para dar início à criação de nossa imagem:</p>

<p><img class="center" src="/imgs/packer_aws_instance1.png" title="&lsquo;Packer Instance&rsquo;" ></p>

<p><strong>D</strong>a mesma forma, se formos na interface de imagens (AMI), veremos a nossa imagem recém criada:</p>

<p><img class="center" src="/imgs/packer_aws_image1.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p><strong>D</strong>e certa forma não fizemos nada aqui, visto que utilizamos uma imagem base do Ubuntu com o Packer e salvamos uma nova imagem sem mudar absolutamente nada neste Ubuntu, portanto basicamente criamos apenas uma cópia da imagem original. Nada empolgante&hellip;</p>

<p><strong>V</strong>amos incrementar um pouco nossa imagem realizando mudanças em nosso Ubuntu. De nada nos valeria criar uma imagem se ela não tiver nenhuma customização, certo?!</p>

<p><strong>C</strong>omeçaremos criando um simples shell script chamado <em>setup.sh</em> com o seguinte conteúdo:</p>

<p>```</p>

<h1>!/bin/bash</h1>

<p>sudo apt-get update</p>

<p>sudo apt-get upgrade -y</p>

<p>sudo apt-get install puppet -y
```</p>

<p><strong>T</strong>rata-se de um simples script que basicamente irá atualizar o sistema operacional e em seguida instalar o Puppet no mesmo.</p>

<p><strong>V</strong>oltando ao nosso arquivo ubuntuaws.json, vamos incluir um bloco de código <em>provisioner</em> ou provisionador. Existem diversos tipos de provisioners, mas para este momento utilizaremos apenas um, chamado <em>shell</em> pois desejamos executar um shell script. Nosso código agora estará assim:</p>

<p>```
{
  &ldquo;variables&rdquo;: {</p>

<pre><code>"aws_access_key": "{{env `AWS_ACCESS_KEY_ID`}}",
"aws_secret_key": "{{env `AWS_SECRET_ACCESS_KEY`}}",
"region": "us-east-1"
</code></pre>

<p>  },
  &ldquo;builders&rdquo;: [{</p>

<pre><code>"type": "amazon-ebs",
"access_key": "{{user `aws_access_key`}}",
"secret_key": "{{user `aws_secret_key`}}",
"region": "{{user `region`}},
"source_ami_filter": {
  "filters": {
  "virtualization-type": "hvm",
  "name": "ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*",
  "root-device-type": "ebs"
  },
  "owners": ["099720109477"],
  "most_recent": true
},
"instance_type": "t2.micro",
"ssh_username": "ubuntu",
"ami_name": "packer-example {{timestamp}}"
</code></pre>

<p>  }],
  &ldquo;provisioners&rdquo;: [</p>

<pre><code>{
  "type": "shell",
  "script": "./setup.sh"
}
</code></pre>

<p>  ]
}
```</p>

<p><strong>A</strong>ntes de entrarmos em maiores detalhes e na utilização do Puppet em si para nossa imagem, vamos testar nosso código e aplicá-lo novamente:</p>

<p><strong>I</strong>ncluímos aqui:</p>

<p><em>provisioners:</em> Para indicar que utilizaremos provisioners</p>

<p><em>type:</em> Tipo de provisioner. Neste exemplo, será <em>bash</em></p>

<p><em>script:</em> Com o provisioner bash nós podemos declarar diretamente os comandos que queremos executar na imagem ou indicar um script com os comandos. Neste caso, optei por utilizar um script.</p>

<p><strong>V</strong>alidando e executando nosso código:
(PS: Como a saída dos comandos apt-get update e apt-get upgrade são muito extensas, cortarei a maior parte aqui&hellip;)</p>

<p>```
$ packer validate ubuntuaws.json
Template validated successfully.</p>

<p>$ packer build ubuntuaws.json
amazon-ebs output will be in this color.</p>

<p>==> amazon-ebs: Prevalidating AMI Name: packer-example 1534024952</p>

<pre><code>amazon-ebs: Found Image ID: ami-5c150e23
</code></pre>

<p>==> amazon-ebs: Creating temporary keypair: packer_5b6f5cf9-dedc-aec2-ad77-acb29d37e8f9
==> amazon-ebs: Creating temporary security group for this instance: packer_5b6f5cfa-d35c-ff6c-aaad-cf02cedf8e74
==> amazon-ebs: Authorizing access to port 22 from 0.0.0.0/0 in the temporary security group&hellip;
==> amazon-ebs: Launching a source AWS instance&hellip;
==> amazon-ebs: Adding tags to source instance</p>

<pre><code>amazon-ebs: Adding tag: "Name": "Packer Builder"
amazon-ebs: Instance ID: i-0bbf230a251f76393
</code></pre>

<p>==> amazon-ebs: Waiting for instance (i-0bbf230a251f76393) to become ready&hellip;
==> amazon-ebs: Waiting for SSH to become available&hellip;
==> amazon-ebs: Connected to SSH!</p>

<h5>#</h5>

<p>&mdash;&ndash;>>> REPARE A SEGUIR QUANDO O PACKER COMEÇA A EXECUTAR NOSSO SCRIPT SETUP.SH &lt;&lt;&lt;&mdash;&ndash;</p>

<h5>#</h5>

<p>==> amazon-ebs: Provisioning with shell script: ./setup.sh</p>

<pre><code>amazon-ebs: Hit:1 https://us-east-1.ec2.archive.ubuntu.com/ubuntu xenial InRelease
amazon-ebs: Get:2 https://us-east-1.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
</code></pre>

<h5>#</h5>

<p>&mdash;&ndash;>>> NESTE MOMENTO O COMANDO &ldquo;SUDO APT-GET UPDATE&rdquo; ESTÁ SENDO EXECUTADO &lt;&lt;&lt;&mdash;&ndash;</p>

<h5>#</h5>

<p>&hellip;
&hellip;</p>

<h5>#</h5>

<p>&mdash;&ndash;>>> A PARTIR DAQUI O COMANDO &ldquo;SUDO APT-GET UPGRADE -Y&rdquo; ESTÁ SENDO EXECUTADO &lt;&lt;&lt;&mdash;&ndash;</p>

<h5>#</h5>

<p>amazon-ebs: Calculating upgrade&hellip;
amazon-ebs: The following packages will be upgraded:
amazon-ebs:   cloud-init gnupg gpgv grub-legacy-ec2
amazon-ebs: 4 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
amazon-ebs: Need to get 1,188 kB of archives.
amazon-ebs: After this operation, 76.8 kB of additional disk space will be used.
amazon-ebs: Get:1 <a href="https://us-east-1.ec2.archive.ubuntu.com/ubuntu">https://us-east-1.ec2.archive.ubuntu.com/ubuntu</a> xenial-updates/main amd64 gpgv amd64 1.4.20-1ubuntu3.3 [165 kB]
amazon-ebs: Get:2 <a href="https://us-east-1.ec2.archive.ubuntu.com/ubuntu">https://us-east-1.ec2.archive.ubuntu.com/ubuntu</a> xenial-updates/main amd64 gnupg amd64 1.4.20-1ubuntu3.3 [626 kB]</p>

<p>&hellip;
&hellip;</p>

<h5>#</h5>

<p>&mdash;&ndash;>>> A PARTIR DAQUI O COMANDO &ldquo;SUDO APT-GET INSTALL PUPPET -Y&rdquo; ESTÁ SENDO EXECUTADO &lt;&lt;&lt;&mdash;&ndash;</p>

<h5>#</h5>

<p>amazon-ebs: The following additional packages will be installed:
 amazon-ebs:   augeas-lenses debconf-utils facter fonts-lato hiera javascript-common
 amazon-ebs:   libaugeas0 libjs-jquery libruby2.3 puppet-common rake ruby ruby-augeas
 amazon-ebs:   ruby-deep-merge ruby-did-you-mean ruby-json ruby-minitest ruby-net-telnet
 amazon-ebs:   ruby-nokogiri ruby-power-assert ruby-rgen ruby-safe-yaml ruby-selinux
 amazon-ebs:   ruby-shadow ruby-test-unit ruby2.3 rubygems-integration unzip virt-what zip
 amazon-ebs: Suggested packages:
 amazon-ebs:   augeas-doc mcollective-common apache2 | lighttpd | httpd augeas-tools
 amazon-ebs:   puppet-el vim-puppet etckeeper ruby-rrd ri ruby-dev bundler
 amazon-ebs: The following NEW packages will be installed:
 amazon-ebs:   augeas-lenses debconf-utils facter fonts-lato hiera javascript-common
 amazon-ebs:   libaugeas0 libjs-jquery libruby2.3 puppet puppet-common rake ruby
 amazon-ebs:   ruby-augeas ruby-deep-merge ruby-did-you-mean ruby-json ruby-minitest
 amazon-ebs:   ruby-net-telnet ruby-nokogiri ruby-power-assert ruby-rgen ruby-safe-yaml
 amazon-ebs:   ruby-selinux ruby-shadow ruby-test-unit ruby2.3 rubygems-integration unzip
 amazon-ebs:   virt-what zip
 amazon-ebs: 0 upgraded, 31 newly installed, 0 to remove and 0 not upgraded.
 amazon-ebs: Need to get 8,267 kB of archives.
 amazon-ebs: After this operation, 38.2 MB of additional disk space will be used.
 amazon-ebs: Get:1 <a href="https://us-east-1.ec2.archive.ubuntu.com/ubuntu">https://us-east-1.ec2.archive.ubuntu.com/ubuntu</a> xenial/main amd64 fonts-lato all 2.0-1 [2,693 kB]
&hellip;
&hellip;</p>

<h5>#</h5>

<p>&mdash;&ndash;>>>  E O PROCESSO SE ENCERRA &lt;&lt;&lt;&mdash;&ndash;</p>

<h5>#</h5>

<p>==> amazon-ebs: Stopping the source instance&hellip;</p>

<pre><code>amazon-ebs: Stopping instance, attempt 1
</code></pre>

<p>==> amazon-ebs: Waiting for the instance to stop&hellip;
==> amazon-ebs: Creating the AMI: packer-example 1534024952</p>

<pre><code>amazon-ebs: AMI: ami-06fe27bd22afcaa71
</code></pre>

<p>==> amazon-ebs: Waiting for AMI to become ready&hellip;
==> amazon-ebs: Terminating the source AWS instance&hellip;
==> amazon-ebs: Cleaning up any extra volumes&hellip;
==> amazon-ebs: No volumes to clean up, skipping
==> amazon-ebs: Deleting temporary security group&hellip;
==> amazon-ebs: Deleting temporary keypair&hellip;
Build &lsquo;amazon-ebs&rsquo; finished.</p>

<p>==> Builds finished. The artifacts of successful builds are:
&mdash;> amazon-ebs: AMIs were created:
us-east-1: ami-06fe27bd22afcaa71
```</p>

<p><strong>A</strong> partir deste momento já temos duas imagens criadas. Uma vez que a primeira não tinha nada de diferente do Ubuntu convencional e padrão do AWS, poderíamos muito bem deletá-la. Já a segunda imagem, é um pouco diferente da imagem padrão, visto que ela já conta com um sistema mais atualizado (apt-get upgrade), bem como possui o puppet já instalado nela.</p>

<p><strong>D</strong>esta mesma maneira seria possível fazer um deployment bem mais complexo de acordo com suas necessidades e, sempre que lhe fosse necessário atualizar ou modificar algo, você poderia gerar uma nova imagem e aplicá-la onde desejasse.</p>

<p><strong>M</strong>as vamos incrementar um pouco mais nossa imagem, desta vez com o puppet como segundo provisioner.</p>

<p><strong>Puppet</strong></p>

<p><strong>U</strong>ma vez que o objetivo deste post não é apresentar o <a href="https://puppet.com">Puppet</a> em si, por hora ficaremos apenas com a informação de que o Puppet é uma ferramenta open source para gerenciamento de configurações (CM Tool &ndash; Configuration Management Tool) muito robusta e flexível.</p>

<p><strong>E</strong>m futuros posts pretendo apresentar mais detalhes e explicações sobre o Puppet em si, mas para este post o objetivo é apenas demonstrar a flexibilidade do Packer para a criação de imagens, mesmo quando integramos diversos elementos a ele, como bash script e Puppet.</p>

<p><strong>C</strong>rie um novo arquivo chamado <em>deployment.pp</em>. O Puppet chama seus arquivos de configuração ou instruções de manifests (manifestos) e estes sempre possuem a extensão .pp.</p>

<p><strong>I</strong>nsira o seguinte conteúdo em seu arquivo <em>deployment.pp</em>:</p>

<p>```
exec { &lsquo;apt-update&rsquo;:
  command => &lsquo;/usr/bin/apt-get update&rsquo;
}</p>

<p>package { &lsquo;apache2&rsquo;:
  ensure => installed,
  before => Service[&lsquo;apache2&rsquo;],
}</p>

<p>service { &lsquo;apache2&rsquo;:
  ensure => running,
  before => Package[&lsquo;mysql-server&rsquo;],
}</p>

<p>package { &lsquo;mysql-server&rsquo;:
  ensure => installed,
  before => Service[&lsquo;mysql&rsquo;],
}</p>

<p>service { &lsquo;mysql&rsquo;:
  ensure => running,
  before => Package[&lsquo;php&rsquo;],
}</p>

<p>package { &lsquo;php&rsquo;:
  ensure => installed,
  before => File[&lsquo;/var/www/html/info.php&rsquo;],
}</p>

<p>file { &lsquo;/var/www/html/info.php&rsquo;:
  ensure => file,
  content => &lsquo;&lt;?php  phpinfo(); ?>&rsquo;,
  require => Package[&lsquo;apache2&rsquo;],
}
```</p>

<p><strong>E</strong>ste manifesto Puppet tem a tarefa de instalar um servidor web LAMP em nossa imagem Ubuntu, com Apache, Mysql e PHP, bem como expor uma página de informações do php default (php.info).</p>

<p><strong>C</strong>omo puppet não é o foco para este post, não entrarei em detalhes sobre as linhas contidas neste manifesto <em>deployment.pp</em>.</p>

<p><strong>PS:</strong> Também estou assumindo que você já possui o puppet instalado em sua máquina. ;] (sudo apt-get install puppet -y)</p>

<p><strong>V</strong>amos primeiramente validar nosso código puppet para garantirmos que está tudo em ordem:</p>

<p><code>
$ puppet parser validate deployment.pp
</code></p>

<p><strong>S</strong>e nada for apresentado na tela, significa que está tudo certo.</p>

<p><strong>A</strong>gora vamos voltar ao nosso código packer e editar o arquivo <em>ubuntuaws.json</em> para inserir nosso segundo provisioner (Puppet):</p>

<p>```
{
  &ldquo;variables&rdquo;: {</p>

<pre><code>"aws_access_key": "{{env `AWS_ACCESS_KEY_ID`}}",
"aws_secret_key": "{{env `AWS_SECRET_ACCESS_KEY`}}",
"region": "us-east-1"
</code></pre>

<p>  },
  &ldquo;builders&rdquo;: [{</p>

<pre><code>"type": "amazon-ebs",
"access_key": "{{user `aws_access_key`}}",
"secret_key": "{{user `aws_secret_key`}}",
"region": "{{user `region`}},
"source_ami_filter": {
  "filters": {
  "virtualization-type": "hvm",
  "name": "ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*",
  "root-device-type": "ebs"
  },
  "owners": ["099720109477"],
  "most_recent": true
},
"instance_type": "t2.micro",
"ssh_username": "ubuntu",
"ami_name": "packer-example {{timestamp}}"
</code></pre>

<p>  }],
  &ldquo;provisioners&rdquo;: [</p>

<pre><code>{
  "type": "shell",
  "script": "./setup.sh"
},
{
  "type": "puppet-masterless",
  "manifest_file": "deployment.pp"
}
</code></pre>

<p>  ]
}
```</p>

<p><strong>O</strong> que incluímos? Apenas mais um item dentro do bloco provisioners, porém desta vez com o tipo <em>puppet-masterless</em>:</p>

<p><em>type:</em> Indicamos que o tipo deste provisioner é <em>puppet-masterless</em>. O Puppet pode funcionar de forma cliente/servidor, ou de forma autônoma, sem um master. Aqui queremos que ele funcione de forma autônoma e independente, portanto utilizaremos <em>puppet-masterless</em> (puppet sem master).</p>

<p><em>manifest_file:</em> Indicamos que arquivo(s) de manifesto(s) do puppet devem ser executados. Neste caso, iremos apenas apontar para nosso <em>deployment.pp</em>.</p>

<p><strong>V</strong>alidando nosso código:</p>

<p><code>
$ packer validate ubuntuaws.json
Template validated successfully.
</code></p>

<p><strong>T</strong>udo certo com nosso código, portanto vamos executar novamente nosso build. Desta vez o Packer irá criar nossa imagem Ubuntu executando ambos, o shell script e o manifesto puppet, portanto nossa saída será bastante extensa. Como já vimos os detalhes nas execuções anteriores, irei cortar a saída aqui para focar na execução do manifesto puppet em si:</p>

<p>```
$ packer build ubuntuaws.json
amazon-ebs output will be in this color.</p>

<p>==> amazon-ebs: Prevalidating AMI Name: packer-example 1534028156</p>

<pre><code>amazon-ebs: Found Image ID: ami-5c150e23
</code></pre>

<p>==> amazon-ebs: Creating temporary keypair: packer_5b6f697c-9aa2-4a5b-0554-255f223460ce
==> amazon-ebs: Creating temporary security group for this instance: packer_5b6f697e-92da-f29d-8688-92b3d787afff
==> amazon-ebs: Authorizing access to port 22 from 0.0.0.0/0 in the temporary security group&hellip;
==> amazon-ebs: Launching a source AWS instance&hellip;
==> amazon-ebs: Adding tags to source instance</p>

<pre><code>amazon-ebs: Adding tag: "Name": "Packer Builder"
amazon-ebs: Instance ID: i-01b0ccb4a7d4462ae
</code></pre>

<p>&hellip;
&hellip;
&hellip;</p>

<h4>#</h4>

<p>&mdash;&ndash;>>> A PARTIR DAQUI O PACKER INICIA A EXECUÇÃO DO MANIFESTO COM O PUPPET &lt;&lt;&lt;&mdash;&ndash;</p>

<h4>#</h4>

<p>==> amazon-ebs: Provisioning with Puppet&hellip;</p>

<pre><code>amazon-ebs: Creating Puppet staging directory...
amazon-ebs: Creating directory: /tmp/packer-puppet-masterless
amazon-ebs: Uploading manifests...
amazon-ebs: Creating directory: /tmp/packer-puppet-masterless/manifests
amazon-ebs: Uploading manifest file from: deployment.pp
amazon-ebs: Running Puppet: cd /tmp/packer-puppet-masterless &amp;&amp; FACTER_packer_build_name='amazon-ebs' FACTER_packer_builder_type='amazon-ebs' sudo -E puppet apply --detailed-exitcodes /tmp/packer-puppet-masterless/manifests/deployment.pp
amazon-ebs: Notice: Compiled catalog for ip-172-31-91-36.ec2.internal in environment production in 0.43 seconds
amazon-ebs: Notice: /Stage[main]/Main/Exec[apt-update]/returns: executed successfully
amazon-ebs: Notice: /Stage[main]/Main/Package[apache2]/ensure: ensure changed 'purged' to 'present'
amazon-ebs: Notice: /Stage[main]/Main/Package[mysql-server]/ensure: ensure changed 'purged' to 'present'
amazon-ebs: Notice: /Stage[main]/Main/Package[php]/ensure: ensure changed 'purged' to 'present'
amazon-ebs: Notice: /Stage[main]/Main/File[/var/www/html/info.php]/ensure: defined content as '{md5}d9c0c977ee96604e48b81d795236619a'
amazon-ebs: Notice: Finished catalog run in 35.64 seconds
</code></pre>

<h4>#</h4>

<p>&mdash;&ndash;>>> FINALIZOU A EXECUÇÃO DO MANIFESTO PUPPET &lt;&lt;&lt;&mdash;&ndash;</p>

<h4>#</h4>

<p>==> amazon-ebs: Stopping the source instance&hellip;</p>

<pre><code>amazon-ebs: Stopping instance, attempt 1
</code></pre>

<p>==> amazon-ebs: Waiting for the instance to stop&hellip;
==> amazon-ebs: Creating the AMI: packer-example 1534031735</p>

<pre><code>amazon-ebs: AMI: ami-04b480ee18474759c
</code></pre>

<p>==> amazon-ebs: Waiting for AMI to become ready&hellip;
==> amazon-ebs: Terminating the source AWS instance&hellip;
==> amazon-ebs: Cleaning up any extra volumes&hellip;
==> amazon-ebs: No volumes to clean up, skipping
==> amazon-ebs: Deleting temporary security group&hellip;
==> amazon-ebs: Deleting temporary keypair&hellip;
Build &lsquo;amazon-ebs&rsquo; finished.</p>

<p>==> Builds finished. The artifacts of successful builds are:
&mdash;> amazon-ebs: AMIs were created:
us-east-1: ami-04b480ee18474759c
```</p>

<p><strong>E</strong> nossa imagem foi criada com sucesso.</p>

<p><strong>A</strong> partir deste momento você decide o que fazer. As possibilidades são infinitas, dependendo do que se deseja conseguir ou arquitetar e como deseja que sua pipeline funcione.</p>

<p><strong>P</strong>or exemplo, você poderia ter uma pipeline no <em>Jenkins</em> que iniciasse o build de uma nova imagem atualizada, que por sua vez chamasse shell script e puppet para provisionamento e configuração desta imagem, em seguida o Jenkins poderia chamar o terraform para criar uma instância ou múltiplas instâncias em um cluster por trás de um load balancer utilizando a imagem que foi criada pelo Packer, etc..etc..etc.. Sua criatividade será o seu limite.</p>

<p><strong>P</strong>ara confirmarmos que nosso código completo funcionou e que nossa imagem foi gerada com sucesso, você pode criar manualmente uma instância a partir do AWS com esta sua nova imagem.</p>

<h2>Testando sua imagem</h2>

<p>1- Efetue login em sua conta do AWS;</p>

<p>2- Vá ao menu de Serviços/Services &ndash;> Imagens/Images &ndash;> AMIs;</p>

<p>3- Na lista de imagens disponíveis, selecione a sua mais recente, para ter certeza de que está escolhendo a que foi criada por último, pois ela será a imagem que contém o deployment via puppet por completo (Repare a data de criação para ter certeza);</p>

<p>4- Ao selecionar a imagem, clique em Lançar/Launch, conforme imagem abaixo:</p>

<p><img class="center" src="/imgs/packer_aws_image2.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p>5- Selecione o tipo de instância padrão que pode ser utilizada gratuitamente para este exemplo, <em>t2.micro</em>, em seguida clique em <em>Próximo/Next</em>, conforme imagem abaixo:</p>

<p><img class="center" src="/imgs/packer_aws_image3.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p>6- Na tela seguinte, deixe tudo como está <strong>exceto</strong> a opção de <em>Atribuir Ip Público/Auto-Assign Public IP</em>. Ative esta opção, em seguida clique em <em>Próximo</em>, conforme imagem abaixo:</p>

<p><img class="center" src="/imgs/packer_aws_image4.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p>7- Na tela seguinte, pode manter o padrão de 8GB de disco/storage e clicar em <em>Próximo</em>;</p>

<p>8- Na parte de Tags, pode novamente manter tudo vazio para este exemplo e clicar em <em>Próximo</em>;</p>

<p>9- Nas configurações de Grupo de Segurança/Security Group, pode manter o padrão, mas certifique-se de <strong>inserir mais uma regra de firewall</strong> para que possamos testar o servidor web. Por padrão o AWS já apresentará a porta 22 (SSH) aberta, portanto vamos abrir também a porta 80, conforme imagem abaixo. Em seguida, clique em Revisar e Lançar/Review and Launch;</p>

<p><img class="center" src="/imgs/packer_aws_image5.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p>10- Em seguida, confirme novamente e clique em <em>Lançar/Launch</em>;</p>

<p>11- Uma janela popup será apresentada lhe perguntando se você deseja criar um par de chaves. Fica a seu critério. Caso deseje se conectar a esta instância via ssh, crie uma chave, do contrário, pode prosseguir sem criar uma chave. Como eu apenas quero testar se o servidor web estará rodando, e já abrimos a porta 80 no firewall, poderemos confirmar isto através de nosso navegador, portanto ignorarei a chave e clicarei em Lançar Instância/Launch Instance;</p>

<p>12- O AWS lhe informará que sua instância está sendo criada. Como se trata de uma instância Linux, costuma ser um processo rápido, geralmente leva algo entre 1 e 2 minutos. Você pode ir para a página principal de instâncias e aguardar sua instância estar com status <em>running</em>;</p>

<p>13- Copie o IP público ou externo que o AWS atribuiu à sua instância conforme imagem abaixo:</p>

<p><img class="center" src="/imgs/packer_aws_image6.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p>14- Agora cole o ip em qualquer browser e você deverá ver uma página default do apache que está rodando em seu novo servidor web:</p>

<p><img class="center" src="/imgs/packer_aws_image7.png" title="&lsquo;Packer Image&rsquo;" ></p>

<p><strong>F</strong>inalizado.</p>

<p><strong>L</strong>embre-se de excluir os recursos no AWS para evitar ser cobrado:</p>

<ul>
<li>Instâncias</li>
<li>Volumes</li>
<li>Imagens</li>
<li>Security Groups</li>
</ul>


<p>&hellip; ou o que mais você tiver criado em seus testes caso não os vá mais utilizar.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recebendo Alarmes do AWS Diretamente no Slack]]></title>
    <link href="https://kalib.github.io/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack/"/>
    <updated>2017-03-11T12:03:00-05:00</updated>
    <id>https://kalib.github.io/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/aws_slack.png" title="&lsquo;AWS_Slack&rsquo;" ></p>

<p><strong>A</strong>ntes de entrar na configuração dos serviços, talvez seja necessário apresentar o <a href="https://www.slack.com">Slack</a>, visto que muitos ainda não conhecem ou utilizam esta poderosa e versátil ferramenta de comunicação instantânea para times.</p>

<p><strong>S</strong>lack é uma plataforma para comunicação entre times que desejam um ambiente mais dinâmico e ágil. Diferentemente de muitas plataformas de chat disponíveis, como o Google Hangouts, o Slack nos permite criar canais distintos com membros distintos de um mesmo time fazendo parte daquele canal específico. Não, não estou falando de chat em grupo, mas sim canais específicos que permitem integrações com serviços distintos, como receber notificações sobre commits feitos em um repositório ou branch específico no github, notificações de tickets abertos em ferramentas como o Jira, por exemplo, etc. O Slack é completamente programável e escalável, o que nos permite ter inúmeras funcionalidas.</p>

<p><strong>P</strong>rovavelmente não seja necessário apresentar o AWS, ou Amazon Web Services, visto que já está no mercado desde 2006, no entanto cabe um resumo para os que não estão familiarizados com o mesmo (embora o público alvo deste post seja quem já possui alguma familiaridade com AWS).</p>

<p><strong>A</strong>ws ou Amazon Web Services é uma plataforma de serviços em nuvem segura, oferecendo poder computacional, armazentamento de banco de dados, distribuição de conteúdo e outras funcionalidades.</p>

<p><strong>P</strong>or que eu deveria ter alarmes e notificações do AWS em um serviço de chat como o Slack quando já recebo estas notificações por email?</p>

<p><strong>É</strong> verdade que o uso mais comum para envio de alarmes e notificações do AWS costuma ser via email, no entanto fica fácil identificar alguns problemas com este método. O principal e mais recorrente que vejo é o caso de as notificações caírem em um email específico visto por poucas pessoas (na maioria das vezes) ou nem visto sequer, pois geralmente as pessoas ficam cansadas de olhar notificações e ter sua caixa de entrada entupida com eles portanto criam filtros que jogam os emails de notificação para um diretório que dificilmente será checado.</p>

<p><strong>O</strong>utro problema comum com esta prática é a demora até que alguém leia a notificação no meio de tantos outros na pasta ou filtro criado e, muitas vezes, quando se vê a notificação, o problema já está aguardando uma solução há horas.</p>

<p><strong>D</strong>eixando claro, não estou defendendo a ideia de abolir as notificações por email. Eu mesmo utilizo ambos, afinal o email continua bastante eficiente para fins de armazenamento e checagem histórica, por exemplo.</p>

<p><strong>U</strong>ma vez que nos dias atuais os times de TI estão cada vez mais unificados e dinâmicos, buscando incorporar uma mentalidade DevOps e Agile, a comunicação rápida e eficiente se torna um fator primordial para o sucesso de qualquer projeto. Ter um local centralizado para conversar com os demais membros do time, trocar arquivos, detalhes de projetos, receber notificações de commits, prazos, tickets, documentação e, por que não, notificações de monitoramento e alarmes, torna-se essencial.</p>

<p><strong>V</strong>amos então entender como funcionaria uma solução para enviar as notificações e alarmes do AWS para o Slack.</p>

<p><strong>O</strong> que utilizaremos:</p>

<ol>
<li>No Slack:

<ul>
<li>Um plugin ou Slack App chamado <strong>Incoming WebHooks</strong></li>
<li>O nome de um canal para envio das notificações</li>
</ul>
</li>
<li>No AWS:

<ul>
<li>Serviço <strong>SNS Topic</strong></li>
<li>Serviço <strong>CloudWatch</strong></li>
<li>Serviço <strong>Lambda Function</strong></li>
</ul>
</li>
</ol>


<p><strong>V</strong>amos lá&hellip;</p>

<p><strong>Slack</strong></p>

<p><strong>V</strong>amos começar escolhendo o canal no Slack no qual desejo receber a minha notificação ou alarme: #devops</p>

<p><em>Estou supondo que você já utiliza o Slack e já possui um time criado no mesmo. Caso ainda não, crie um time no Slack seguindo os passos descritos no <a href="https://slack.com/">site oficial</a> antes de seguir em frente&hellip; ;]</em></p>

<p><strong>O</strong> próximo passo é configurar a integração instalando o Plugin ou Slack App <strong>Incoming WebHooks</strong>. Para isto, acesse a página de apps de seu time no Slack: <a href="https://SEUTIME.slack.com/apps">https://SEUTIME.slack.com/apps</a></p>

<p><strong>P</strong>esquise por Incoming WebHooks e você terá apenas um resultado, portanto clique sem medo.</p>

<p><img class="center" src="/imgs/slack1.png" title="&lsquo;Incoming WebHook&rsquo;" ></p>

<p><strong>C</strong>lique no pequeno lápis que se encontrará no canto direito para editar as configurações do Incoming WebHook. Os únicos campos que precisaremos editar neste momento são os seguintes:
  * Post to Channel &ndash; Aqui indicarei o meu canal: #devops
  * Customize Name &ndash; Aqui indicarei um nome qualquer: AWS-Alerts</p>

<p><strong>Importante:</strong> Repare que nesta página de configurações ele lhe passará uma entrada ou URL com o código para o seu WebHook. Esta informação estará listada em <strong>Webhook URL</strong> e será algo como: *<a href="https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.">https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.</a> Copie esta informação em algum local de fácil acesso pois precisaremos desta URL para a configuração que faremos a seguir no AWS.</p>

<p><strong>S</strong>alve suas configurações e vamos configurar os serviços do AWS para que nosso WebHook possa receber as informações devidamente.</p>

<p><strong>Amazon Web Services</strong></p>

<p><strong>S</strong>e você já possui alguma familiaridade com o AWS, sabe que existem duas formas principais para administração e gerenciamento de nossos serviços: Pela interface web de gerenciamento (GUI) OU pela linha de comandos através da AWS CLI Tool que se comunica com a API do AWS. Este procedimento, assim como praticamente todos os outros, pode ser realizado por ambos os meios.</p>

<p><strong>S</strong>e você também gosta de automação, provavelmente prefere utilizar a CLI, no entanto irei listar aqui o procedimento em ambos os meios.</p>

<p><strong>Passo 1: Criando um SNS Topic para receber os alarmes</strong></p>

<p><strong>1.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço SNS;</li>
<li>Crie um novo SNS Topic:

<ul>
<li>No menu da lateral esquerda, clique em <strong>Topics</strong>;</li>
<li>Clique em <strong>Create new topic</strong>;</li>
<li>Preencha os campos <strong>Name</strong> (obrigatório) e <strong>Display Name</strong> (opcional) para o seu tópico. Para este exemplo utilizarei <em>aws-slack-alerts</em> como <strong>Name</strong> e <em>aws-slack</em> como <strong>Display Name</strong>; <em>(O Display Name só é necessário em caso de você também desejar enviar notificações por SMS)</em></li>
<li>Clique em <strong>Create Topic</strong></li>
</ul>
</li>
<li>Agora você já deve ser capaz de ver seu SNS Topic na lista.</li>
</ul>


<p><strong>1.2 &ndash; Pela AWS CLI Tool</strong></p>

<p><em>Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando a região na qual você deseja criar seu tópico e o nome desejado:</li>
</ul>


<p>```python
aws sns create-topic</p>

<pre><code>--region us-west-1
--name aws-slack-alerts
</code></pre>

<p>```
  * <strong>IMPORTANTE:</strong> Você receberá um identificador (TopicArn) para este alarme. Você precisará dele no passo seguinte.
  * Caso queira ter certeza, você pode listar seus tópicos utilizando:</p>

<p><code>python
aws sns list-topics
</code></p>

<p><strong>Passo 2: Criando um Alarme no serviço CloudWatch</strong></p>

<p><strong>2.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>CloudWatch</strong>;</li>
<li>Crie um novo Alarme:

<ul>
<li>Clique em <strong>Alarms</strong>;</li>
<li>Clique no botão <strong>Create Alarm</strong>;</li>
<li>Escolha a categoria do alarme desejado. Para este exemplo utilizarei <strong>ELB Metric > Per-LB Metrics</strong> <em>(Dentre as várias categorias disponíveis, esta se refere à Load Balancers)</em>;</li>
<li>Selecione a métrica exata desejada. No caso deste exemplo, preciso selecionar a métrica e o Load Balancer desejado. Ao escolher a métrica e o alvo (em meu caso um Load Balancer) clique em <strong>Next</strong>. Neste exemplo eu escolhi a métrica <strong>HTTPCode_Backend_5XX</strong> <em>(para monitorar 500 errors)</em> e um Load Balancer chamado <strong>LB-GuySpyV3</strong>;</li>
<li>O próximo passo é definir um nome e uma descrição para este <strong>Alarme</strong>, bem como definir as triggers e períodos de monitoramento. Neste exemplo utilizei o nome <strong>LB-GuySpyV3-ELB_500</strong> para meu alarme; <em>(Não entrarei em detalhes quanto ao uso das triggers, visto que para cada tipo ou categoria de métrica, as triggers serão diferentes, bem como o cenário de seu ambiente e nível de criticidade. Em resumo, se você deseja monitorar o uso de CPU de um determinado servidor, a trigger seria o gatilho que ativaria o alarme, por exemplo: Só quero ser alarmado se o uso de CPU neste servidor ou instância for >= 90% e assim permanecer por pelo menos 60 segundos, ou por dois períodos seguidos de 60seg.)</em></li>
<li>Na seção <strong>Actions</strong> da configuração do Alarme defina o <strong>State</strong> e indique que a notificação deverá ser enviada <strong>(Send notification to)</strong> para o <strong>SNS Topic</strong> que criamos anteriormente. Para este exemplo optei por <strong>State is ALARM</strong> e decidi enviar as notificações para <strong>aws-slack-alerts</strong>, sendo este o SNS Topic que criei no início;</li>
<li>Finalize clicando em <strong>Create Alarm</strong>.</li>
</ul>
</li>
</ul>


<p>  <strong>2.2 &ndash; Pela AWS CLI Tool</strong></p>

<p>  <em>Novamente&hellip; Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando os atributos abaixo:

<ul>
<li><strong>region</strong> <em>(Região)</em>;</li>
<li><strong>alarm-name</strong> <em>(Nome do alarme)</em>;</li>
<li><strong>alarm-description</strong> <em>(Descrição do alarme)</em>;</li>
<li><strong>alarm-actions</strong> <em>(Definir a ação do alarme &ndash; Apontar para o TopicArn do SNS Topic que criamos anteriormente)</em>;</li>
<li><strong>metric-name</strong> <em>(Nome da Métrica desejada)</em>;</li>
<li><strong>namespace AWS/ELB &mdash;statistic</strong> <em>(Estatística desejada para aquela métrica, neste caso utilizarei Sum (Soma) ao invés de Average (Média))</em>;</li>
<li><strong>dimensions</strong> <em>(O alvo desta métrica de monitoramento, no nosso caso um Load Balancer)</em>;</li>
<li><strong>period</strong> e <strong>evaluation-periods</strong> <em>(Períodos desejados para a trigger)</em>;</li>
<li><strong>threshold</strong> <em>(O valor desejado: Neste exemplo estou colocando o valor como 1, portanto receberei o alarme caso seja >= 1. Sim, eu sei que receberei o alarme a cada minuto, mas estou fazendo isto de propósito para recebermos a notificação a fim de teste. Nunca utilize um threshold desses em produção. :p)</em>;</li>
<li><strong>comparison-operator</strong> <em>(Operador de comparação desejado, neste caso >=)</em>;</li>
</ul>
</li>
</ul>


<p>```python
aws cloudwatch put-metric-alarm &mdash;region us-west-1</p>

<pre><code>--alarm-name "LB-GuySpyV3-ELB_500"
--alarm-description "Sends 500-errors to Slack"
--actions-enabled
--alarm-actions "TheTopicArn from last step"
--metric-name "HTTPCode_Backend_5XX"
--namespace AWS/ELB --statistic "Sum"
--dimensions "Name=LoadBalancerName,Value=LB-GuySpyV3"
--period 60
--evaluation-periods 60
--threshold 1
--comparison-operator "GreaterThanOrEqualToThreshold"
</code></pre>

<p>```</p>

<p><strong>Passo 3: Criando uma Função Lambda como Assinante (Subscriber) do nosso SNS Topic</strong></p>

<p><strong>3.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>Lambda</strong>;</li>
<li>Crie uma <strong>Nova Função Lambda</strong>:

<ul>
<li>Clique em <strong>Create a Lambda Function</strong>;</li>
<li>Na tela <strong>Select Blueprint</strong> clique na opção <strong>cloudwatch-alarm-to-slack</strong>; <em>(Você poderá precisar buscar por esta opção)</em></li>
<li>O próximo passo será a tela <strong>Configure Triggers</strong>. Selecione o <strong>SNS Topic</strong> que foi criado anteriormente (aws-slack-alerts neste exemplo) e marque a opção <strong>Enable Trigger</strong> e clique em Next;</li>
<li>Em <strong>Configure Function</strong> dê um Nome e uma Descrição para a função e escolha <strong>Node.js.4.3</strong> como <strong>Runtime</strong>;</li>
<li>No campo <strong>Lambda Function Code</strong> cole o seguinte código: <a href="https://gist.github.com/tomfa/b33f768908b0a83987d26f269e377e95">Disponível no github</a>

<ul>
<li>(Você deverá setar os valores das variáveis <strong>CHANNEL</strong> e <strong>PATH</strong>, onde CHANNEL é o canal do Slack para o qual você deseja mandar as notificações e PATH é a URL de seu WebHook, recebida quando configuramos o Incoming WebHook no Slack)</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>```python
var https = require(&lsquo;https&rsquo;);
var util = require(&lsquo;util&rsquo;);</p>

<p>var CHANNEL = &ldquo;#devops&rdquo;;
var PATH = &ldquo;/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv&rdquo;;</p>

<p>exports.handler = function(event, context) {</p>

<pre><code>console.log(JSON.stringify(event, null, 2));
console.log('From SNS:', event.Records[0].Sns.Message);

var postData = {
    "channel": CHANNEL,
    "username": "AWS SNS",
    "text": "*" + event.Records[0].Sns.Subject + "*",
    "icon_emoji": ":aws:"
};

var message = event.Records[0].Sns.Message;
var severity = "good";

var dangerMessages = [
    " but with errors",
    " to RED",
    "During an aborted deployment",
    "Failed to deploy application",
    "Failed to deploy configuration",
    "has a dependent object",
    "is not authorized to perform",
    "Pending to Degraded",
    "Stack deletion failed",
    "Unsuccessful command execution",
    "You do not have permission",
    "Your quota allows for 0 more running instance"];

var warningMessages = [
    " aborted operation.",
    " to YELLOW",
    "Adding instance ",
    "Degraded to Info",
    "Deleting SNS topic",
    "is currently running under desired capacity",
    "Ok to Info",
    "Ok to Warning",
    "Pending Initialization",
    "Removed instance ",
    "Rollback of environment"       
    ];

for(var dangerMessagesItem in dangerMessages) {
    if (message.indexOf(dangerMessages[dangerMessagesItem]) != -1) {
        severity = "danger";
        break;
    }
}

// Only check for warning messages if necessary
if (severity == "good") {
    for(var warningMessagesItem in warningMessages) {
        if (message.indexOf(warningMessages[warningMessagesItem]) != -1) {
            severity = "warning";
            break;
        }
    }       
}

postData.attachments = [
    {
        "color": severity,
        "text": message
    }
];

var options = {
    method: 'POST',
    hostname: 'hooks.slack.com',
    port: 443,
    path: PATH
};

var req = https.request(options, function(res) {
  res.setEncoding('utf8');
  res.on('data', function (chunk) {
    context.done(null, postData);
  });
});

req.on('error', function(e) {
  console.log('problem with request: ' + e.message);
});   

req.write(util.format("%j", postData));
req.end();
</code></pre>

<p>};
```</p>

<ul>
<li>O <strong>Handler</strong> deverá ser o default <code>index.handler</code>;

<ul>
<li>Para <strong>role</strong> selecione <strong>Create a custom role</strong>; <em>(Isto será necessário apenas para a sua primeira função)</em></li>
<li>Na tela seguinte selecione <strong>lambda_basic_execution</strong> como <strong>IAM role</strong> e deixe o <strong>Policy Name</strong> com seu valor default. O AWS irá criar uma política de segurança padrão que nos dará os privilégios necessários. Clique em <strong>Allow</strong>;</li>
<li>Certifique-se de que o valor para <strong>VPC</strong> na seção <strong>Advanced Settings</strong> seja <strong>No VPC</strong>;
Clique em <strong>Next</strong>, reveja suas configurações e clique em <strong>Create Function</strong>;</li>
</ul>
</li>
<li>Aguarde seu alarme acontecer e receba a notificação no Slack. :D</li>
</ul>


<p>O resultado em seu Slack será algo assim&hellip;</p>

<p><img class="center" src="/imgs/slack2.png" title="&lsquo;Notification_Slack&rsquo;" ></p>

<p><strong>P</strong>arabéns, você já está recebendo suas notificações via Slack. Basta criar outros alarmes no AWS utilizando a mesma Lambda Function e o mesmo SNS Topic.</p>

<p><strong>H</strong>appy Hacking!</p>
]]></content>
  </entry>
  
</feed>
