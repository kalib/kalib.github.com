
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Marcelo Cavalcante Rocha ~</title>
  <meta name="author" content="Marcelo Cavalcante Rocha - Kalib">

  
  <meta name="description" content="Uma coisa de cada vez Chef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. O Chef é desenvolvido &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://kalib.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Marcelo Cavalcante Rocha ~" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42903485-1']);
    _gaq.push(['_setDomainName','marcelocavalcante.net']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:kalib.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            Marcelo Cavalcante Rocha ~
        </span>
       
           <span class="blue_dark">
             Hacking the damn life...
           </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Arquivos</a></li>
  <li><a href="/about">Sobre mim</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/04/01/chef-aautomacao-e-gerenciamento-de-configuracao/">Chef: Automação E Gerenciamento De Configuração</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2018-04-01T11:22:00-04:00" pubdate data-updated="true">Apr 1<span>st</span>, 2018</time>
        
         | <a href="/blog/2018/04/01/chef-aautomacao-e-gerenciamento-de-configuracao/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img class="center" src="/imgs/cheflogo.png" title="'Chef'" ></p>

<h2>Uma coisa de cada vez</h2>

<p><strong>C</strong>hef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. O <a href="https://www.chef.io">Chef</a> é desenvolvido em <a href="http://www.ruby-lang.org">Ruby</a> e <a href="https://www.erlang.org">Erlang</a>, e utiliza uma linguagem DSL (domain-specific language) em Ruby puro para escrever arquivos de configuração de sistemas chamados &ldquo;recipes&rdquo; (receitas).</p>

<p><strong>A</strong>ntes de falarmos sobre o Chef é importante entender primeiramente o conceito e a utilidade de ferramentas de Gerenciamento de Configuração.</p>

<h2>Gerenciamento de Configuração</h2>

<p><strong>G</strong>erenciamento de Configuração, ou CM (Configuration Management), é um processo de engenharia de sistemas que visa garantir a consistência entre ativos físicos e lógicos em um ambiente operacional. O processo de gerenciamento de configuração busca identificar e rastrear itens individuais de configuração, documentando capacidades funcionais e interdependências. Administradores, técnicos e desenvolvedores de sistemas podem utilizar ferramentas de Gerenciamento de Configuração para verificar o efeito que uma mudança em um item de configuração terá em outros sistemas.</p>

<p><strong>E</strong>m palavras simples, o objetivo de uma ferramenta de gerenciamento de configuração é simplificar a vida de quem administra serviços e sistemas garantindo uma uniformidade no quesito configuração.</p>

<p><strong>C</strong>omo exemplo prático e simplista, imagine um servidor web que será responsável por hospedar um pequeno site em php. Este servidor possuirá alguns atributos/aplicativos/configurações, tais como:</p>

<ul>
<li>Apache instalado;</li>
<li>Alterações específicas nos arquivos de configuração do Apache;</li>
<li>Serviço do Apache ativo e iniciado;</li>
<li>Arquivos referentes ao site em si em um diretório específico;</li>
<li>Permissões específicas atribuídas ao diretório específico do site;</li>
<li>etc&hellip;</li>
</ul>


<p><strong>C</strong>onfigurar tudo isso manualmente em um único servidor é simples. Você poderia conectar-se via SSH no servidor, instalar o apache com o gerenciador de pacotes da distribuição utilizada, configurar o que for necessário no apache, iniciar o serviço, etc, etc, etc. Mas o que fazer quando sua infraestrutura cresce? Quando se quer maior disponibilidade do site, quando agora você roda este site em um cluster com 5 servidores?</p>

<p><strong>B</strong>asicamente a mesma coisa, certo? Você pode se conectar em cada um dos servidores e repetir os mesmos passos. O problema se dá justamente nessa repetição de passos, onde você pode cometer erros, perder tempo, etc. Além disso, o que acontece se um colega seu modificar algo em um dos servidores e não lhe avisar? E se ele esquecer de replicar esta mudança nos demais?</p>

<p><strong>É</strong> fácil achar diversas razões pelas quais torna-se difícil administrar e gerenciar configurações em ambientes mais complexos. A ideia por trás de uma ferramenta de Gerenciamento de Configuração é justamente reduzir esta complexidade, eliminando a necessidade de conectar-se manualmente à diversos servidores para aplicar as mesmas rotinas, passos e configurações.</p>

<p><strong>A</strong>través de arquivos de texto podemos literalmente descrever o estado e as ações desejadas para nossos serviços e sistemas. Por exemplo: Posso dizer que possuo um grupo de servidores chamado WebServer, o qual contém 10 servidores com o Sistema Operacional CentOS 7. Posso incluir a informação de que preciso que todos eles estejam com a versão X do Apache instalada e que o serviço esteja ativo e rodando. Além disso, posso dizer que desejo que exista no diretório /var/www/meusite/ todo o conteúdo que está em um mapeamento de rede específico, ou mesmo em um repositório que possuo no github.</p>

<p><strong>A</strong>o invés de me conectar em cada um dos 10 servidores para fazer tudo isso, um simples comando será o suficiente. O comando em específico dependerá da solução adotada, visto que existem diversas ferramentas de CM (Gerenciamento de Configuração). Mas, basicamente, ele irá ler o(s) arquivo(s) de &ldquo;instruções&rdquo; que nós definimos e saberá em quais servidores ele deverá instalar o Apache e configurar de acordo com o especificado, nos dando apenas o resultado final em forma de relatório simples.</p>

<p><strong>E</strong> se alguém da equipe alterar um arquivo de configuração diretamente em um dos servidores? A ferramenta, em sua próxima execucação, irá identificar que o estado desejado para aquele meu grupo de servidores está diferente em um dos servidores. Ela então modificará aquele arquivo específico naquele servidor para que ele volte ao seu estado desejado.</p>

<p><strong>A</strong>lém desta segurança, nós agora passamos a ter um ponto único de modificação. Ao desejarmos mudar algo, o faremos apenas no nosso &ldquo;código&rdquo;, ao invés de o fazer nos 10 servidores manualmente.</p>

<p><strong>O</strong> mesmo benefício se dá em caso de erros e falhas: um ponto único de correção.</p>

<p><strong>C</strong>om este mecanismo de descrever o estado de nossa infraestrutura em arquivos de texto/código, entramos em um novo conceito: Infrastructure as Code, ou Infraestrutura como Código. Uma vez que temos nossa infraestrutura em formato de código, podemos literalmente versionar e gerenciar nossa infraestrutura com repositórios Git, por exemplo.</p>

<h2>O que é Chef?</h2>

<p><strong>C</strong>onforme dito mais acima, Chef é uma das mais populares ferramentas de Gerenciamento de Configuração disponíveis atualmente. É compatível e facilmente integrado à plataformas de computação em nuvem, tais como Internap, Amazon EC2, Google Cloud Platform, OpenStack, SoftLayer, Microsoft Azure e Rackspace, provendo e configurando servidores automaticamente.</p>

<p><strong>O</strong> usuário escreve &ldquo;recipes&rdquo; (receitas) que descrevem como o Chef deve gerenciar aplicações, servidores e utilitários. Estas &ldquo;recipes&rdquo;, as quais podem ser agrupadas em &ldquo;cookbooks&rdquo; (livros de receitas) descrevem uma série de recursos que devem estar em um determinado estado. Este recursos podem ser pacotes, serviços ou mesmo arquivos.</p>

<p><strong>C</strong>hef pode rodar em um modo cliente/servidor ou standalone, com o chamado &ldquo;chef-solo&rdquo;. No modo cliente/servidor, o cliente Chef envia uma série de atributos sobre o node ou cliente/host para o Chef server. O Chef server utiliza-se da ferramenta <a href="https://lucene.apache.org/solr">Solr</a> para indexar estes atributos e provê uma API na qual os clientes podem fazer consultas. As recipes podem fazer requisições à esta base de atributos e utilizar os dados resultantes para configurar o cliente ou node.</p>

<p><strong>E</strong>mbora inicialmente o Chef fosse utilizado para gerenciar exclusivamente máquinas Linux, as versões mais atuais também suportam máquinas Windows.</p>

<p><strong>A</strong> ideia para este post é dar uma breve introdução ao Chef, portanto não vou entrar em maiores detalhes do funcionamento por hora.</p>

<h3>Resources</h3>

<p><strong>C</strong>omo dito antes, um Resource é uma descrição de estado desejado para um determinado item. Estes resources são gerenciados através de recipes.</p>

<p><strong>U</strong>m resource possui basicamente 4 componentes fundamentais que são definidos em um bloco de código Ruby:</p>

<ul>
<li>Resource Type &ndash; Tipo de resource (Pode ser um pacote, serviço, arquivo&hellip;)</li>
<li>Resource Name &ndash; Nome do resource</li>
<li>Resource Properties &ndash; Propriedades do resource</li>
<li>Actions &ndash; Ações a serem aplicadas ao resource</li>
</ul>


<p><strong>U</strong>m exemplo de recipe para instalar o Apache em um servidor Ubuntu, por exemplo, seria o seguinte:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package 'httpd' do
</span><span class='line'>    action :install
</span><span class='line'>end</span></code></pre></td></tr></table></div></figure>


<p>No exemplo acima temos o tipo de resource como sendo &ldquo;package&rdquo;, o nome do resource como sendo &ldquo;httpd&rdquo; e a ação &ldquo;install&rdquo;.</p>

<p><strong>O</strong> que vai acontecer aqui? Simples de entender, certo? O pacote httpd (Apache) será instalado. Mas o que acontece caso o pacote httpd já esteja instalado?</p>

<p><strong>N</strong>ada. Uma das características do Chef é a <strong>idempotência</strong>. Na matemática e ciência da computação, a idempotência é a propriedade que algumas operações têm de poderem ser aplicadas várias vezes sem que o valor do resultado se altere após a aplicação inicial. Ou seja, O Chef primeiramente confere se o estado desejado já está aplicado e, caso sim, ignora aquela instrução.</p>

<p><strong>N</strong>ovamente&hellip; A ideia para este post é dar uma breve introdução ao Chef, portanto não vou entrar em maiores detalhes sobre os tipos de resources e suas possíveis ações. Vamos ao que interessa&hellip;</p>

<h2>Instalando o Chef</h2>

<p><strong>C</strong>onforme explicado acima, o Chef pode ser utilizado em modo cliente/servidor ou standalone. Para esta introdução utilizaremos o modo standalone ou local para simplificar as coisas.</p>

<p><strong>P</strong>ara instalar podemos utilizar o gerenciador de pacotes da distribuição Linux que utilizamos ou baixando o chefdk (Development Kit) através da página de <a href="https://downloads.chef.io/chefdk">downloads do chef</a>.</p>

<h3>Arch Linux</h3>

<p><strong>N</strong>o meu caso, utilizarei o pacote <a href="https://aur.archlinux.org/packages/chef-dk/">chef-dk</a> existente para o Arch Linux, mas sinta-se livre para baixar diretamente no site e executar o pacote de acordo com sua distribuição.</p>

<p><strong>1- Baixar o pacote do AUR:</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wget https://aur.archlinux.org/cgit/aur.git/snapshot/chef-dk.tar.gz</span></code></pre></td></tr></table></div></figure>


<p><strong>2- Descompactar e Compilar:</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tar -xvzf chef-dk.tar.gz
</span><span class='line'>
</span><span class='line'>$ cd chef-dk
</span><span class='line'>
</span><span class='line'>$ makepkg</span></code></pre></td></tr></table></div></figure>


<p><strong>3- Instalar o pacote:</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo pacman -U chef-dk-2.5.3-1-x86_64.pkg.tar.xz</span></code></pre></td></tr></table></div></figure>


<p><strong>4- Confirmar que deu tudo certo:</strong>*</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ chef --version
</span><span class='line'>
</span><span class='line'>Chef Development Kit Version: 2.5.3
</span><span class='line'>chef-client version: 13.8.5
</span><span class='line'>delivery version: master (73ebb72a6c42b3d2ff5370c476be800fee7e5427)
</span><span class='line'>berks version: 6.3.1
</span><span class='line'>kitchen version: 1.20.0
</span><span class='line'>inspec version: 1.51.21</span></code></pre></td></tr></table></div></figure>


<h3>Centos, Debian, Ubuntu&hellip;</h3>

<p><strong>N</strong>o CentOS, Ubuntu, Debian ou outras distribuições, o procedimento será relativamente parecido, portanto vejamos como seria no caso do CentOS baixando o arquivo diretamente do site de downloads:</p>

<p><strong>1- Baixar o arquivo .rpm para Red Hat:</strong> <a href="https://downloads.chef.io/chefdk">Aqui</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wget https://packages.chef.io/files/stable/chefdk/2.5.3/el/7/chefdk-2.5.3-1.el7.x86_64.rpm</span></code></pre></td></tr></table></div></figure>


<p><strong>2- Instalar via RPM:</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo rpm -ivh chefdk-2.5.3-1.el7.x86_64.rpm</span></code></pre></td></tr></table></div></figure>


<p><strong>3- Confirmar que deu tudo certo:</strong>*</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ chef --version
</span><span class='line'>
</span><span class='line'>Chef Development Kit Version: 2.5.3
</span><span class='line'>chef-client version: 13.8.5
</span><span class='line'>delivery version: master (73ebb72a6c42b3d2ff5370c476be800fee7e5427)
</span><span class='line'>berks version: 6.3.1
</span><span class='line'>kitchen version: 1.20.0
</span><span class='line'>inspec version: 1.51.21</span></code></pre></td></tr></table></div></figure>


<h2>Testando o Chef Localmente</h2>

<p><strong>P</strong>ara facilitar o entendimento, vamos criar uma recipe simples para aplicarmos localmente.</p>

<p><strong>V</strong>amos começar criando um arquivo chamado <strong>exemplo.rb</strong> com o seguinte conteúdo:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package 'apache' do
</span><span class='line'>        package_name 'httpd'
</span><span class='line'>        action :install
</span><span class='line'>end</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> que temos aqui?</p>

<ul>
<li>Resource Type: package (Pois queremos instalar o pacote httpd)</li>
<li>Resource Name: apache (Embora o nome do pacote no CentOS seja httpd, o nome do nosso resource aqui é apache, mas poderia ser qualquer coisa que desejarmos)</li>
<li>Resource Properties: Aqui temos apenas <em>package_name</em> como propriedade, no qual damos o nome do pacote desejado. OBS: Caso não utilizemos a propriedade <em>package_name</em>, ele buscará por um pacote com mesmo nome do resource. No nosso caso, demos o nome <em>apache</em> para nosso resource, portanto ele buscaria por um pacote chamado <em>apache</em> e falharia, pois no CentOS este pacote não existe.</li>
<li>Actions: install (Temos apenas uma ação para esta recipe, que é justamente a de instalar o pacote, CASO já não esteja instalado (idempotência))</li>
</ul>


<p><strong>S</strong>alve o arquivo e verifique o mesmo com os dois passos a seguir:</p>

<p><strong>1-</strong> Verifique se a sintaxe ruby está correta:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># ruby -c exemplo.rb
</span><span class='line'>
</span><span class='line'>Syntax OK</span></code></pre></td></tr></table></div></figure>


<p><strong>2-</strong> Utilize uma ferramenta do chef para verificar se a recipe está de acordo com o esperado pelo Chef:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># foodcritic exemplo.rb
</span><span class='line'>Checking 1 files
</span><span class='line'>x
</span><span class='line'>FC011: Missing README in markdown format: ../README.md:1
</span><span class='line'>FC031: Cookbook without metadata.rb file: ../metadata.rb:1
</span><span class='line'>FC071: Missing LICENSE file: ../LICENSE:1</span></code></pre></td></tr></table></div></figure>


<p>PS: Não se espante por enquanto com estes Warnings. Ele apenas está indicando que não possuímos um metadata, um readme e uma licença, pois não os criamos para este exemplo.</p>

<p><strong>V</strong>erificado o código e aprovado, vamos executar esta recipe localmente.
<em>(Repare no retorno que será apresentado, onde ele verifica o tipo de resource e identifica que estamos rodando em uma máquina CentoOS, portanto ele utiliza por padrão o yum para instalar o pacote desejado.)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># chef-client --local-mode exemplo.rb
</span><span class='line'>
</span><span class='line'>[2018-04-01T19:18:00+00:00] WARN: No config file found or specified on command line, using command line options.
</span><span class='line'>[2018-04-01T19:18:00+00:00] WARN: No cookbooks directory found at or above current directory.  Assuming /root.
</span><span class='line'>Starting Chef Client, version 13.8.5
</span><span class='line'>resolving cookbooks for run list: []
</span><span class='line'>Synchronizing Cookbooks:
</span><span class='line'>Installing Cookbook Gems:
</span><span class='line'>Compiling Cookbooks...
</span><span class='line'>[2018-04-01T19:18:03+00:00] WARN: Node kalib6.mylabserver.com has an empty run list.
</span><span class='line'>Converging 1 resources
</span><span class='line'>Recipe: @recipe_files::/root/exemplo.rb
</span><span class='line'>  * yum_package[apache] action install
</span><span class='line'>    - install version 2.4.6-67.el7.centos.6 of package httpd
</span><span class='line'>
</span><span class='line'>Running handlers:
</span><span class='line'>Running handlers complete
</span><span class='line'>Chef Client finished, 1/1 resources updated in 16 seconds
</span><span class='line'>[2018-04-01T19:18:17+00:00] WARN: No config file found or specified on command line, using command line options.</span></code></pre></td></tr></table></div></figure>


<p><strong>S</strong>imples, certo? O pacote httpd (Apache) foi instalado em nosso CentOS. Verificando o status do serviço httpd, veremos que o serviço não está rodando e também não está ativo.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl status httpd
</span><span class='line'>● httpd.service - The Apache HTTP Server
</span><span class='line'>   Loaded: loaded (/usr/lib/systemd/system/httpd.service; disabled; vendor preset: disabled)
</span><span class='line'>   Active: inactive (dead)
</span><span class='line'>     Docs: man:httpd(8)
</span><span class='line'>           man:apachectl(8)</span></code></pre></td></tr></table></div></figure>


<p><strong>I</strong>sto está correto, afinal o Chef vai deixar a máquina no estado que determinamos. E o determinado foi apenas instalar o pacote httpd. Mas de nada ele serve sem estar rodando como serviço, portanto vamos editar nossa recipe exemplo.rb e incluir nela um novo resource, desta vez um resource do tipo <em>service</em>, ou serviço. Sim, podemos ter diversos resources em uma mesma recipe. ;]</p>

<p><strong>E</strong>dite sua recipe para que ela possua o seguinte conteúdo:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package 'apache' do
</span><span class='line'>        package_name 'httpd'
</span><span class='line'>        action :installchef_httpd_default.png
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>service 'httpd' do
</span><span class='line'>        action [:enable, :start]
</span><span class='line'>end</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> que adicionamos aqui?</p>

<ul>
<li>Resource Type: service (Pois queremos gerenciar o serviço httpd)</li>
<li>Resource Name: httpd (Poderíamos ter utilizado qualquer nome, mas para simplificar e não precisarmos utilizar uma propriedade de nome, deixaremos o resource com o nome do serviço, <em>httpd</em>)</li>
<li>Actions: enable e start (Como nosso objetivo é não apenas iniciar o serviço, mas também deixá-lo habilitado para ser iniciado automaticamente após reinicialização, utilizaremos o <em>enable</em> e o <em>start</em>) &ndash;> equivalente aos comandos <em>systemctl enable httpd</em> e <em>systemctl start httpd</em></li>
</ul>


<p><strong>N</strong>ovamente vamos verificar nosso código via ruby e foodcritic:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># ruby -c exemplo.rb && foodcritic exemplo.rb</span></code></pre></td></tr></table></div></figure>


<p><strong>E</strong> executar nossa recipe. (Novamente, uma vez que o pacote httpd já está instalado, esta parte da recipe será ignorada automaticamente pelo Chef.)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># chef-client --local-mode exemplo.rb
</span><span class='line'>[2018-04-01T19:32:26+00:00] WARN: No config file found or specified on command line, using command line options.
</span><span class='line'>[2018-04-01T19:32:26+00:00] WARN: No cookbooks directory found at or above current directory.  Assuming /root.
</span><span class='line'>Starting Chef Client, version 13.8.5
</span><span class='line'>resolving cookbooks for run list: []
</span><span class='line'>Synchronizing Cookbooks:
</span><span class='line'>Installing Cookbook Gems:
</span><span class='line'>Compiling Cookbooks...
</span><span class='line'>[2018-04-01T19:32:28+00:00] WARN: Node kalib6.mylabserver.com has an empty run list.
</span><span class='line'>Converging 2 resources
</span><span class='line'>Recipe: @recipe_files::/root/exemplo.rb
</span><span class='line'>  * yum_package[apache] action install (up to date)
</span><span class='line'>  * service[httpd] action enable
</span><span class='line'>    - enable service service[httpd]
</span><span class='line'>  * service[httpd] action start
</span><span class='line'>    - start service service[httpd]
</span><span class='line'>
</span><span class='line'>Running handlers:
</span><span class='line'>Running handlers complete
</span><span class='line'>Chef Client finished, 2/3 resources updated in 06 seconds
</span><span class='line'>[2018-04-01T19:32:33+00:00] WARN: No config file found or specified on command line, using command line options.</span></code></pre></td></tr></table></div></figure>


<p><strong>A</strong>gora podemos verificar que nosso serviço httpd está de fato rodando.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl status httpd && ps aux | grep httpd
</span><span class='line'>● httpd.service - The Apache HTTP Server
</span><span class='line'>   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)
</span><span class='line'>   Active: active (running) since Sun 2018-04-01 19:32:33 UTC; 1min 17s ago
</span><span class='line'>     Docs: man:httpd(8)
</span><span class='line'>           man:apachectl(8)
</span><span class='line'> Main PID: 2409 (httpd)
</span><span class='line'>   Status: "Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec"
</span><span class='line'>   CGroup: /system.slice/httpd.service
</span><span class='line'>           ├─2409 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>           ├─2410 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>           ├─2411 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>           ├─2412 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>           ├─2413 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>           └─2414 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>
</span><span class='line'>Apr 01 19:32:33 kalib6.mylabserver.com systemd[1]: Starting The Apache HTTP Server...
</span><span class='line'>Apr 01 19:32:33 kalib6.mylabserver.com systemd[1]: Started The Apache HTTP Server.
</span><span class='line'>root      2409  0.0  0.2 226040  4948 ?        Ss   19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>apache    2410  0.0  0.1 226040  2872 ?        S    19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>apache    2411  0.0  0.1 226040  2872 ?        S    19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>apache    2412  0.0  0.1 226040  2872 ?        S    19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>apache    2413  0.0  0.1 226040  2872 ?        S    19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>apache    2414  0.0  0.1 226040  2872 ?        S    19:32   0:00 /usr/sbin/httpd -DFOREGROUND
</span><span class='line'>root      2425  0.0  0.0 112660   976 pts/0    R+   19:33   0:00 grep --color=auto httpd</span></code></pre></td></tr></table></div></figure>


<p><strong>A</strong>lém disso, você pode testar seu novo servidor web diretamente em seu browser. Caso esteja executando tudo em localhost, pode utilizar <em>localhost</em> como endereço. Caso contrário, pode utilizar o endereço ip da máquina em questão.</p>

<p><img class="center" src="/imgs/chef_httpd_default.png" title="'Chef'" ></p>

<p><strong>A</strong> página padrão do Apache não é algo que queremos, portanto vamos criar nosso próprio site (Hello World) para exemplificar melhor. Para isto editaremos novamente nossa recipe e incluiremos mais um resource, do tipo <em>file</em>, ou arquivo. O conteúdo de sua recipe deverá ficar assim:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package 'apache' do
</span><span class='line'>        package_name 'httpd'
</span><span class='line'>        action :install
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>service 'httpd' do
</span><span class='line'>        action [:enable, :start]
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>file '/var/www/html/index.html' do
</span><span class='line'>        content 'Hello World!'
</span><span class='line'>        mode '0755'
</span><span class='line'>        owner 'root'
</span><span class='line'>        group 'apache'
</span><span class='line'>end</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> que adicionamos aqui?</p>

<ul>
<li>Resource Type: file (Pois queremos gerenciar o nosso arquivo index.html, o quão, caso não exista, será criado)</li>
<li>Resource Name: /var/www/html/index.html (Poderíamos ter utilizado qualquer nome, mas para simplificar e não precisarmos utilizar uma propriedade de nome, deixaremos o resource com o nome do arquivo que vamos utilizar, <em>/var/www/html/index.html</em>)</li>
<li>Content: Hello World! (Para simplificar teremos uma simples string <em>Hello World!</em> como conteúdo de nosso site)</li>
<li>Mode: Permissão que desejamos atribuir ao arquivo index.html</li>
<li>Owner: Dono que deve ser atribuído ao arquivo index.html</li>
<li>Group: Grupo que deve ser atribuído ao arquivo index.html</li>
</ul>


<p><strong>N</strong>ovamente vamos verificar nosso código via ruby e foodcritic:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># ruby -c exemplo.rb && foodcritic exemplo.rb</span></code></pre></td></tr></table></div></figure>


<p><strong>E</strong> executar nossa recipe. (Assim como anteriormente, o Chef ignorará as instruções referentes aos resources que já se encontram no estado desejado)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># chef-client --local-mode exemplo.rb          
</span><span class='line'>[2018-04-01T19:48:00+00:00] WARN: No config file found or specified on command line, using command line options.
</span><span class='line'>[2018-04-01T19:48:00+00:00] WARN: No cookbooks directory found at or above current directory.  Assuming /root.
</span><span class='line'>Starting Chef Client, version 13.8.5
</span><span class='line'>resolving cookbooks for run list: []
</span><span class='line'>Synchronizing Cookbooks:
</span><span class='line'>Installing Cookbook Gems:
</span><span class='line'>Compiling Cookbooks...
</span><span class='line'>[2018-04-01T19:48:02+00:00] WARN: Node kalib6.mylabserver.com has an empty run list.
</span><span class='line'>Converging 3 resources
</span><span class='line'>Recipe: @recipe_files::/root/exemplo.rb
</span><span class='line'>  * yum_package[apache] action install (up to date)
</span><span class='line'>  * service[httpd] action enable (up to date)
</span><span class='line'>  * service[httpd] action start (up to date)
</span><span class='line'>  * file[/var/www/html/index.html] action create
</span><span class='line'>    - create new file /var/www/html/index.html
</span><span class='line'>    - update content in file /var/www/html/index.html from none to 7f83b1
</span><span class='line'>    --- /var/www/html/index.html        2018-04-01 19:48:06.829566745 +0000
</span><span class='line'>    +++ /var/www/html/.chef-index20180401-2631-164958p.html     2018-04-01 19:48:06.829566745 +0000
</span><span class='line'>    @@ -1 +1,2 @@
</span><span class='line'>    +Hello World!
</span><span class='line'>    - change mode from '' to '0755'
</span><span class='line'>    - change owner from '' to 'root'
</span><span class='line'>    - change group from '' to 'apache'
</span><span class='line'>    - restore selinux security context
</span><span class='line'>
</span><span class='line'>Running handlers:
</span><span class='line'>Running handlers complete
</span><span class='line'>Chef Client finished, 1/4 resources updated in 06 seconds
</span><span class='line'>[2018-04-01T19:48:07+00:00] WARN: No config file found or specified on command line, using command line options.</span></code></pre></td></tr></table></div></figure>


<p>E</p>

<p><strong>P</strong>odemos verificar que o Chef criou o nosso arquivo index.html, atribuindo o dono, grupo e permissão que indicamos:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># ls -lh /var/www/html/
</span><span class='line'>total 4.0K
</span><span class='line'>-rwxr-xr-x. 1 root apache 12 Apr  1 19:48 index.html</span></code></pre></td></tr></table></div></figure>


<p>Também podemos voltar em nosso navegador e atualizar a página para que vejamos o nosso Hello World ao invés da página padrão do Apache.</p>

<p><img class="center" src="/imgs/chef_httpd_hw.png" title="'Chef'" ></p>

<h2>Vale a pena?</h2>

<p><strong>P</strong>ara realizarmos este mesmo processo todo manualmente, na mesma máquina CentoOS seria mais rápido do que utilizando o Chef. Vamos rever:</p>

<p><strong>O</strong> que precisamos?</p>

<ul>
<li>Instalar o pacote httpd</li>
<li>Habilitar e Iniciar o serviço httpd</li>
<li>Criar o arquivo index.html com o conteúdo &ldquo;Hello World!&rdquo;</li>
</ul>


<p><strong>F</strong>azendo manualmente seria apenas uma questão de executarmos X comandos:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install httpd
</span><span class='line'>
</span><span class='line'># systemctl enable httpd && systemctl start httpd
</span><span class='line'>
</span><span class='line'># echo "Hello World!" &gt; /var/www/html/index.html
</span><span class='line'>
</span><span class='line'># chmod 0755 /var/www/html/index.html && chown root:apache /var/www/html/index.html</span></code></pre></td></tr></table></div></figure>


<p><strong>S</strong>im, é verdade que fazendo manualmente neste caso seria MUITO mais rápido. O importante é lembrar do que falamos anteriormente. E se não for apenas 1 servidor? E se for um grupo? E se você ao invés de apEenas 3 resources, tiver 15? ou 40? E se alguém modificar algo em algum dos resources? Como você saberá? Vai verificar todos um a um para identificar o que precisa ser corrigido?</p>

<h1>Vantagens:</h1>

<p><strong>I</strong>magine que algum membro de sua equipe alterou a permissão do arquivo index.html sem lhe avisar, por exemplo ele foi lá e&hellip;</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># chmod 0666 /var/www/html/index.html</span></code></pre></td></tr></table></div></figure>


<p><strong>L</strong>embrando que em nossa recipe exemplo.rb, definimos a permissão 0755. Neste caso, sempre que executarmos a recipe, ela vai verificar todos os resources e corrigir o que quer que tenha sido alterado.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># chef-client --local-mode exemplo.rb
</span><span class='line'>[2018-04-01T20:04:08+00:00] WARN: No config file found or specified on command line, using command line options.
</span><span class='line'>[2018-04-01T20:04:08+00:00] WARN: No cookbooks directory found at or above current directory.  Assuming /root.
</span><span class='line'>Starting Chef Client, version 13.8.5
</span><span class='line'>resolving cookbooks for run list: []
</span><span class='line'>Synchronizing Cookbooks:
</span><span class='line'>Installing Cookbook Gems:
</span><span class='line'>Compiling Cookbooks...
</span><span class='line'>[2018-04-01T20:04:10+00:00] WARN: Node kalib6.mylabserver.com has an empty run list.
</span><span class='line'>Converging 3 resources
</span><span class='line'>Recipe: @recipe_files::/root/exemplo.rb
</span><span class='line'>  * yum_package[apache] action install (up to date)
</span><span class='line'>  * service[httpd] action enable (up to date)
</span><span class='line'>  * service[httpd] action start (up to date)
</span><span class='line'>  * file[/var/www/html/index.html] action create
</span><span class='line'>    - change mode from '0666' to '0755'
</span><span class='line'>    - restore selinux security context
</span><span class='line'>
</span><span class='line'>Running handlers:
</span><span class='line'>Running handlers complete
</span><span class='line'>Chef Client finished, 1/4 resources updated in 06 seconds
</span><span class='line'>[2018-04-01T20:04:14+00:00] WARN: No config file found or specified on command line, using command line options.</span></code></pre></td></tr></table></div></figure>


<p><strong>R</strong>epare na linha *&ndash; change mode from &lsquo;0666&rsquo; to &lsquo;0755&rsquo;. O Chef acabou de corrigir automaticamente sem que nós tenhamos de vasculhar cada componente e arquivo em nosso servidor para saber o que foi alterado ou o que está fora do desejado. Novamente, aqui foi em um servidor único, com apenas um arquivo. Imagine ter que varrer manualmente diversos servidores e diversos arquivos e diretórios?</p>

<p><strong>N</strong>este exemplo, provavelmente o site poderia continuar funcionando, pois foi alterada apenas a permissão de um único arquivo, certo? Mas imagine que sem querer ele acabou parando o serviço httpd, ou até desinstalou o mesmo? Em uma instalação padrão com Chef Server, existem agendamentos que fazem com que o Chef execute as recipes a cada X minutos, portanto o serviço seria inicializado novamente automaticamente, ou mesmo instalado caso necessário.</p>

<p><strong>É</strong> fácil imaginar diversos cenários em que é útil ter a sua infraestrutura em formato de código, certo?</p>

<p><strong>I</strong>magine uma catástrofe em que seu servidor simplesmente parou de funcionar e você precisará criar outro. Novamente você teria que executar aqueles comandos. Se desde o início tivesse utilizado o Chef, ou outra ferramenta de Gerenciamento de Configuração, você poderia ter a sua recipe armazenada em um repositório Git, por exemplo, conforme mencionado no início deste post, e bastaria apenas executar o seu chef-client para instalar os pacotes necessários, habilitar e inicializar serviços necessários, criar arquivos necessários, etc.</p>

<p><strong>A</strong> imaginação é o seu limite. ;]</p>

<p><strong>E</strong>m posts futuros pretendo explorar mais a fundo o Chef, bem como outras ferramentas.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/06/24/conhecendo-o-kubernetes-clusters-de-containers/">Conhecendo O Kubernetes - Clusters De Containers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2017-06-24T09:32:00-04:00" pubdate data-updated="true">Jun 24<span>th</span>, 2017</time>
        
         | <a href="/blog/2017/06/24/conhecendo-o-kubernetes-clusters-de-containers/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img class="center" src="/imgs/kubernetes_logo.png" title="'Kubernetes'" ></p>

<h2>O que é Kubernetes</h2>

<p><strong>K</strong>ubernetes é uma solução Open Source desenvolvida pelo Google, originalmente chamada de K8s, como uma ferramenta para gerenciar clusters de containers (ou containeres, como prefira). Em 2005, quando a ferramenta foi desenvolvida, originalmente para uso interno, o Google doou o código à recém fundada <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>, em parceria com a <a href="https://www.linuxfoundation.org/">The Linux Foundation</a>.</p>

<p><strong>O</strong> motivo do leme em sua logomarca é devido à origem grega da palavra, que vem de Kuvernetes, que representa a pessoa que pilota o navio, timoneiro.</p>

<p><strong>C</strong>omo objetivo primário o Kubernetes provê uma plataforma de automação para deployments, escalonamento e operações de containers de aplicações em um cluster de hosts ou nodes.</p>

<p><strong>A</strong>ntes de seguir com a explicação, instalação e configuração do Kubernetes, estou supondo que você já possui algum conhecimento básico sobre o que sejam containers e tenha alguma familiaridade com o <a href="https://www.docker.com">Docker</a>. Caso não possua um entendimento básico sobre containers e Docker, sugiro que leia algo antes de seguir com este artigo. Possuo um post introdutório sobre containers com um exemplo básico e prático sobre como criar containers com Docker, bem como iniciar uma simples aplicação web &ndash;  <a href="/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">aqui</a>.</p>

<p><strong>O</strong> Kubernetes é formado por uma série de componentes ou blocos que, quando utilizados coletivamente, fornecem um método de deployment, manutenção e escalonamento de clusters de aplicações baseadas em containers. Estes componentes, ou primitives como o Kubernetes os chama, foram desenvolvidos com o intuito de serem independentes, de forma que quase não se faz necessário ter conhecimento entre si para que possam funcionar e trabalhar juntos, visto que todos se comunicam e interligam através de uma API, sejam componentes internos do Kubernetes ou mesmo extensões e containers.</p>

<p><strong>E</strong>mbora tenha sido inicialmente desenvolvido para o deployment e utilização de <strong>bilhões de containers</strong> internamente no Google, desde que seu código passou a ser distribuído abertamente com a licença <a href="http://commons.apache.org/proper/commons-daemon/license.html">Apache Commons</a> o Kubernetes tem sido adotado formalmente por praticamente todos os grandes provedores de serviços em nuvem.</p>

<h2>Arquitetura do Kubernetes</h2>

<p><img class="center" src="/imgs/kubernetes_architecture.png" title="'Kubernetes Architecture'" ></p>

<p><strong>D</strong>entre os principais componentes do Kubernetes, vamos destacar os seguintes:</p>

<ul>
<li><p><strong>Master ou Master Controller</strong> &ndash; Host que será o gerenciador principal do Kubernetes, responsável por gerenciar os Minions ou Nodes do Cluster;</p></li>
<li><p><strong>Nodes ou Minions</strong> &ndash; Embora normalmente a nomenclatura em diversos serviços de tecnolocia seja Node, o Kubernetes prefere chamar de Minions os hosts que fazem parte de um Cluster gerenciado pelo próprio Kubernetes. Este minion pode ser um servidor físico ou virtual, necessitando possuir um serviço de gerenciamento de containers, como o Docker, por exemplo;</p></li>
<li><p><strong>ETCD</strong> &ndash; Embora este seja um serviço independente, estou listando-o aqui pois este será fundamental em seu ciclo de desenvolvimento com o Kubernetes. Cada Minion deverá rodar o <a href="https://coreos.com/etcd/docs/latest/">ETCD</a> (serviço de comunicação e gerenciamento de configurações no formato par de Chave/Valor). O ETCD é utilizado para troca e armazenamento de informações sobre os containers, pods, minions, etc.</p></li>
<li><p><strong>Pods</strong> &ndash; São grupos de containers (um ou mais) rodando em um único minion do cluster. Cada Pod receberá um endereço IP único no Cluster como forma de possibilitar a utilização de portas sem a necessidade de se preocupar com conflitos;</p></li>
<li><p><strong>Labels</strong> &ndash; São informações de identificação na configuração e gerenciamento dos objetos (como Pods ou Minions) formados de pares &ldquo;chave:valor&rdquo;;</p></li>
<li><p><strong>Controllers</strong> &ndash; Além do Master Controller, dependendo do tamanho de sua infraestrutura e quantidade de Pods e Minions, você pode optar por ter mais de um Controller para dividir a carga e tarefas de gerenciamento. Os Controllers gerenciam um grupo de pods e, dependendo do estado de configuração desejada, podem acionar outros Controllers para lidar com as replicações e escalonamento. Os Controllers também são responsáveis pela substituiçao de Pods, caso um entre em estado de falha.</p></li>
</ul>


<h2>Instalação</h2>

<p><strong>V</strong>amos ao que interessa&hellip;</p>

<p><strong>N</strong>ovamente estou supondo que você já possui alguma familiaridade com Containers, Docker e, por consequência, com GNU/Linux.</p>

<p><strong>E</strong>estarei utilizando 4 servidores virtuais rodando CentOS 7 nos exemplos a seguir, mas fica a seu critério decidir quantos utilizar.</p>

<p><em>Certamente você optar por utilizar outra distribuição, seja Debian, Ubuntu, etc.. Uma vez que optei pelo CentOS 7, estarei utilizando comandos voltados para esta distro, mas sinta-se livre para adaptar seus comandos, como substituir o &ldquo;yum&rdquo; pelo &ldquo;apt-get&rdquo;, &ldquo;pacman&rdquo;, etc..</em></p>

<p><strong>E</strong>m minha configuração chamarei os servidores da seguinte forma:</p>

<ul>
<li>centos-master</li>
<li>centos-minion1</li>
<li>centos-minion2</li>
<li>centos-minion3</li>
</ul>


<p><strong>A</strong> primeira coisa que se deve fazer sempre que se pensa em trabalhar com clusters, independente de ser um cluster de containers ou não, é ter a certeza de que os servidores terão uma correta sincronização de relógios entre si. A forma mais simples e eficiente no nosso contexto é com a utilização do NTP, portanto comece instalando o NTP nos 4 servidores, bem como habilitando o serviço e iniciando-o:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install -y ntp</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl enable ntpd && systemctl start ntpd</span></code></pre></td></tr></table></div></figure>


<p><strong>C</strong>aso queira certificar-se de que o serviço está realmente rodando:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl status ntpd
</span><span class='line'>
</span><span class='line'>● ntpd.service - Network Time Service
</span><span class='line'>   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled)
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 17:46:02 UTC; 3s ago
</span><span class='line'>  Process: 1586 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)
</span><span class='line'> Main PID: 1587 (ntpd)
</span><span class='line'>   Memory: 2.1M
</span><span class='line'>   CGroup: /system.slice/ntpd.service
</span><span class='line'>           └─1587 /usr/sbin/ntpd -u ntp:ntp -g</span></code></pre></td></tr></table></div></figure>


<p><strong>P</strong>inga?</p>

<p><strong>É</strong> importante nos certificarmos de que os servidores conseguem se comunicar e de que conseguem resolver nomes corretamente.</p>

<p><strong>N</strong>este exemplo, conforme informado mais acima, estamos utilizando 4 servidores com os seguintes nomes: <em>centos-master</em>, <em>centos-minion1</em>, <em>centos-minion2</em> e <em>centos-minion3</em>, portanto vamos editar o arquivo <strong>/etc/hosts</strong> de cada um deles para que possam se comunicar pelos nomes que desejamos:</p>

<p><strong>Insira as seguintes linhas no arquivo /etc/hosts dos 4 servidores:</strong></p>

<p><em>Lembre-se de substituir os IPs pelos IPs dos servidores em seu ambiente</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Ip local do servidor master
</span><span class='line'>172.31.22.126   centos-master
</span><span class='line'>
</span><span class='line'># Ip local do minion1
</span><span class='line'>172.31.120.16   centos-minion1
</span><span class='line'>
</span><span class='line'># Ip local do minion2
</span><span class='line'>172.31.25.6     centos-minion2
</span><span class='line'>
</span><span class='line'># Ip local do minion3
</span><span class='line'>172.31.123.22   centos-minion3</span></code></pre></td></tr></table></div></figure>


<p>Feito isto, tente pingar do master para os 3 minions utilizando os nomes especificados no /etc/hosts:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# ping centos-minion1
</span><span class='line'>PING centos-minion1 (172.31.120.16) 56(84) bytes of data.
</span><span class='line'>64 bytes from centos-minion1 (172.31.120.16): icmp_seq=1 ttl=64 time=1.06 ms
</span><span class='line'>
</span><span class='line'>[root@kalib1 ~]# ping centos-minion2
</span><span class='line'>PING centos-minion2 (172.31.25.6) 56(84) bytes of data.
</span><span class='line'>64 bytes from centos-minion2 (172.31.25.6): icmp_seq=1 ttl=64 time=0.588 ms
</span><span class='line'>
</span><span class='line'>[root@kalib1 ~]# ping centos-minion3
</span><span class='line'>PING centos-minion3 (172.31.123.22) 56(84) bytes of data.
</span><span class='line'>64 bytes from centos-minion3 (172.31.123.22): icmp_seq=1 ttl=64 time=1.24 ms</span></code></pre></td></tr></table></div></figure>


<p><strong>V</strong>ocê pode realizar o mesmo teste a partir dos minions, pingando entre si e também para o centos-master.</p>

<p><strong>U</strong>ma vez que tenhamos certeza de que todos os hosts se comunicam, é hora de instalar mais alguns pacotes necessários.</p>

<p><strong>P</strong>rimeiramente, vamos configurar o repositório do Docker para o CentOS 7:</p>

<ul>
<li>Configurações de repositório retiradas dos repositórios CBS do Centos: <a href="http://cbs.centos.org/repos/virt7-docker-common-release/">http://cbs.centos.org/repos/virt7-docker-common-release/</a></li>
</ul>


<p><strong>V</strong>amos criar o seguinte arquivo de repositório:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># vim /etc/yum.repos.d/virt7-docker-common-release.repos</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> conteúdo deste arquivo será o seguinte:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[virt7-docker-common-release]
</span><span class='line'>name=virt7-docker-common-release
</span><span class='line'>baseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
</span><span class='line'>gpgcheck=0</span></code></pre></td></tr></table></div></figure>


<p><em>Este arquivo deverá ser criado nos 4 servidores.</em></p>

<p><strong>E</strong>m seguida, vamos atualizar a nossa base de repositórios e pacotes, também <strong>nos 4 servidores</strong>, bem como habilitar o novo repositório para instalar os pacotes docker e kubernetes:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum update</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install -y --enablerepo=virt7-docker-common-release docker kubernetes</span></code></pre></td></tr></table></div></figure>


<p><strong>C</strong>omo dito na introdução, também precisaremos do etcd para o armazenamento e troca de configurações, portanto vamos instalá-lo também nos 4 hosts:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum instal -y etcd</span></code></pre></td></tr></table></div></figure>


<h2>Configuração</h2>

<p><strong>V</strong>amos começar com a configuração básica dos serviços envolvidos. Primeiramente, vamos abrir o arquivo de configuração do kubernetes e fazer algumas alterações:</p>

<p><em>/etc/kubernetes/config</em></p>

<p><strong>N</strong>o arquivo config altere as seguintes linhas:</p>

<p><em>Edite o valor do parâmetro KUBE_MASTER, de forma que nosso master possa ser encontrado pelo nome que definimos no hosts file. O valor original é &ldquo;&mdash;master=<a href="http://127.0.0.1:8080">http://127.0.0.1:8080</a>&rdquo;, portanto mudaremos para o seguinte:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBE_MASTER="--master=http://centos-master:8080"</span></code></pre></td></tr></table></div></figure>


<p><strong>A</strong>inda neste arquivo de configuração, vamos inserir a configuração do serviço ETCD, portanto inclua a seguinte linha ao final do arquivo:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBE_ETCD_SERVERS="--etcd-servers=http://centos-master:2379"</span></code></pre></td></tr></table></div></figure>


<p><strong>S</strong>eu arquivo de configuração deverá estar similar a este:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>###
</span><span class='line'># kubernetes system config
</span><span class='line'>#
</span><span class='line'># The following values are used to configure various aspects of all
</span><span class='line'># kubernetes services, including
</span><span class='line'>#
</span><span class='line'>#   kube-apiserver.service
</span><span class='line'>#   kube-controller-manager.service
</span><span class='line'>#   kube-scheduler.service
</span><span class='line'>#   kubelet.service
</span><span class='line'>#   kube-proxy.service
</span><span class='line'># logging to stderr means we get it in the systemd journal
</span><span class='line'>KUBE_LOGTOSTDERR="--logtostderr=true"
</span><span class='line'>
</span><span class='line'># journal message level, 0 is debug
</span><span class='line'>KUBE_LOG_LEVEL="--v=0"
</span><span class='line'>
</span><span class='line'># Should this cluster be allowed to run privileged docker containers
</span><span class='line'>KUBE_ALLOW_PRIV="--allow-privileged=false"
</span><span class='line'>
</span><span class='line'># How the controller-manager, scheduler, and proxy find the apiserver
</span><span class='line'>KUBE_MASTER="--master=http://centos-master:8080"
</span><span class='line'>
</span><span class='line'>KUBE_ETCD_SERVERS="--etcd-servers=http://centos-master:2379"</span></code></pre></td></tr></table></div></figure>


<p><strong>R</strong>epita esta mesma configuração nos 4 hosts. Todos eles devem utilizar exatamente os mesmos valores utilizados aqui, apontando KUBE_MASTER e KUBE_ETCD_SERVERS para centos-master, visto que este será o responsável por gerenciar todos os nossos minions.</p>

<p><strong>U</strong>ma vez que o arquivo de configuração do kubernetes esteja pronto nos 4 hosts, vamos configurar o serviço de API do kubernetes:</p>

<p><em>/etc/kubernetes/apiserver</em></p>

<p><strong>Esta configuração abaixo será apenas para o Master.</strong></p>

<p><em>Edite o valor do parâmetro KUBE_API_ADDRESS, que originalmente é &ldquo;&mdash;insecure-bind-address=127.0.0.1&rdquo;, de forma que possamos novamente receber comunicação dos demais hosts.</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBE_API_ADDRESS="--address=0.0.0.0"</span></code></pre></td></tr></table></div></figure>


<p><em>Descomente as linhas KUBE_API_PORT e KUBELET_PORT, para que possamos estabelecer as portas de comunicação com a API:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># The port on the local server to listen on.
</span><span class='line'>KUBE_API_PORT="--port=8080"
</span><span class='line'>
</span><span class='line'># Port minions listen on
</span><span class='line'>KUBELET_PORT="--kubelet-port=10250"</span></code></pre></td></tr></table></div></figure>


<p><em>Em nosso exemplo não utilizaremos o parâmetro KUBE_ADMISSION_CONTROL, o qual nos permite ter mais controles e restrições sobre quais nodes ou minios podem entrar em nosso ambiente, portanto vamos apenas comentar esta linha por enquanto:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># default admission control policies
</span><span class='line'># KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota"</span></code></pre></td></tr></table></div></figure>


<p><em>Nosso arquivo /etc/kubernetes/apiserver deverá estar assim:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>##
</span><span class='line'># kubernetes system config
</span><span class='line'>#
</span><span class='line'># The following values are used to configure the kube-apiserver
</span><span class='line'>#
</span><span class='line'>
</span><span class='line'># The address on the local server to listen to.
</span><span class='line'>KUBE_API_ADDRESS="--address=0.0.0.0"
</span><span class='line'>
</span><span class='line'># The port on the local server to listen on.
</span><span class='line'>KUBE_API_PORT="--port=8080"
</span><span class='line'>
</span><span class='line'># Port minions listen on
</span><span class='line'>KUBELET_PORT="--kubelet-port=10250"
</span><span class='line'>
</span><span class='line'># Comma separated list of nodes in the etcd cluster
</span><span class='line'>KUBE_ETCD_SERVERS="--etcd-servers=http://127.0.0.1:2379"
</span><span class='line'>
</span><span class='line'># Address range to use for services
</span><span class='line'>KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"
</span><span class='line'>
</span><span class='line'># default admission control policies
</span><span class='line'># KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota"
</span><span class='line'>
</span><span class='line'># Add your own!
</span><span class='line'>KUBE_API_ARGS=""</span></code></pre></td></tr></table></div></figure>


<p><strong>S</strong>alve e feche o arquivo. Novamente, esta configuração deve ser feita apenas para o Master.</p>

<p><strong>A</strong>gora vamos configurar o serviço ETCD:</p>

<p><em>/etc/etcd/etcd.conf</em></p>

<p><strong>Esta configuração abaixo será apenas para o Master.</strong></p>

<p><em>Edite os valores dos parâmetros ETCD_LISTEN_CLIENT_URLS e ETCD_ADVERTISE_CLIENT_URLS, que originalmente apontam para localhost. Como desejamos que nosso etcd escute requisições dos demais hosts, altere para o seguinte:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
</span><span class='line'>...
</span><span class='line'>...
</span><span class='line'>ETCD_ADVERTISE_CLIENT_URLS="http://0.0.0.0:2379"</span></code></pre></td></tr></table></div></figure>


<p><strong>N</strong>ovamente, não é necessário alterar a configuração do etcd nos demais hosts, apenas no Master.</p>

<p><strong>U</strong>ma vez que as configurações iniciais foram feitas, vamos habilitar e iniciar os serviços necessários <strong>no Master</strong>, sendo eles:</p>

<ul>
<li>etcd</li>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-scheduler</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl enable etcd kube-apiserver kube-controller-manager kube-scheduler</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl start etcd kube-apiserver kube-controller-manager kube-scheduler</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong>s 4 serviços devem estar rodando. Para termos certeza, vamos checar o status dos mesmos:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl status etcd kube-apiserver kube-controller-manager kube-scheduler | grep "(running)"
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:45:37 UTC; 1min ago
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:46:13 UTC; 1min ago
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:44:25 UTC; 1min ago
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:44:25 UTC; 1min ago</span></code></pre></td></tr></table></div></figure>


<p><strong>N</strong>ovamente, estes serviços serão iniciados no Master, e não nos nodes/minions, visto que estes utilizarão outros serviços.</p>

<p><strong>A</strong>gora vamos configurar o seguinte arquivo nos nodes/minions:</p>

<p><em>/etc/kubernetes/kubelet</em></p>

<p><strong>Este arquivo apenas deverá ser editado nos nodes/minions, não no Master.</strong></p>

<p><em>Vamos alterar o valor do parâmetro KUBELET_ADDRESS para que aceite comunicação não apenas do localhost:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBELET_ADDRESS="--address=0.0.0.0"</span></code></pre></td></tr></table></div></figure>


<p><em>Descomentaremos também a linha KUBELET_PORT, para que possamos ter uma porta definida para a comunicação do kubelet:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># The port for the info server to serve on
</span><span class='line'>KUBELET_PORT="--port=10250"</span></code></pre></td></tr></table></div></figure>


<p><em>Vamos alterar o valor do parâmetro KUBELET_HOSTNAME para o nome que definimos <strong>para cada um dos minions</strong>, portanto em cada um deles este será um valor diferente. Supondo que este seja o minion1, utilizaremos:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBELET_HOSTNAME="--hostname-override=centos-minion1"</span></code></pre></td></tr></table></div></figure>


<p><em>Vamos também alterar o valor para KUBELET_API_SERVER, apontando para o nosso Master:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>KUBELET_API_SERVER="--api-servers=http://centos-master:8080"</span></code></pre></td></tr></table></div></figure>


<p><em>Vamos comentar a linha KUBELET_POD_INFRA_CONTAINER, visto que não utilizaremos uma infraestrutura de containers externa, pois estaremos utilizando nossos próprios PODs e containers:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># pod infrastructure container
</span><span class='line'>#KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest"</span></code></pre></td></tr></table></div></figure>


<p><em>Nosso arquivo deverá estar assim: (Lembrando que o parâmetro KUBELET_HOSTNAME deverá ser diferente para cada um dos 3 minions, respectivamente: centos-minion1, centos-minion2 e centos-minion3)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>###
</span><span class='line'># kubernetes kubelet (minion) config
</span><span class='line'>
</span><span class='line'># The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
</span><span class='line'>KUBELET_ADDRESS="--address=0.0.0.0"
</span><span class='line'>
</span><span class='line'># The port for the info server to serve on
</span><span class='line'>KUBELET_PORT="--port=10250"
</span><span class='line'>
</span><span class='line'># You may leave this blank to use the actual hostname
</span><span class='line'>KUBELET_HOSTNAME="--hostname-override=centos-minion1"
</span><span class='line'>
</span><span class='line'># location of the api-server
</span><span class='line'>KUBELET_API_SERVER="--api-servers=http://centos-master:8080"
</span><span class='line'>
</span><span class='line'># pod infrastructure container
</span><span class='line'>#KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest"
</span><span class='line'>
</span><span class='line'># Add your own!
</span><span class='line'>KUBELET_ARGS=""</span></code></pre></td></tr></table></div></figure>


<p><strong>U</strong>ma vez que estas configurações também estão feitas nos 3 minions, vamos habilitar e iniciar os serviços necessários nos minions:</p>

<ul>
<li>kube-proxy</li>
<li>kube-kubelet</li>
<li>docker</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl enable kube-proxy kubelet docker</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl start kube-proxy kubelet docker</span></code></pre></td></tr></table></div></figure>


<p><strong>N</strong>ovamente, vamos ter certeza de que os 3 serviços estão rodando:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># systemctl status kube-proxy kubelet docker | grep "(running)"
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:44:23 UTC; 1h 16min ago
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:44:27 UTC; 1h 16min ago
</span><span class='line'>   Active: active (running) since Sat 2017-06-24 21:44:27 UTC; 1h 16min ago</span></code></pre></td></tr></table></div></figure>


<p><strong>N</strong>ovamente, estes 3 serviços devem ser habilitados e iniciados nos 3 minions.</p>

<p><strong>N</strong>este momento já temos nosso cluster rodando, com um master e 3 minions. :D</p>

<h2>Testando o Cluster com o Kubernetes</h2>

<p><strong>A</strong>gora que temos a configuração básica de nosso Master Controller e de 3 minions, vamos testar nosso cluster.</p>

<p><strong>U</strong>tilizaremos o utilitário kubectl (KubeControl) disponível com o kubernetes. Caso tenha interesse em ver os parâmetros e funções do mesmo&hellip; <em>$ man kubectl</em></p>

<p><strong>V</strong>amos verificar a lista dos nodes ou minions que temos neste momento registrados em nosso Cluster. Vamos digitar alguns comandos em nosso Master Controller (centos-master):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# kubectl get nodes
</span><span class='line'>NAME             STATUS    AGE
</span><span class='line'>centos-minion1   Ready     17m
</span><span class='line'>centos-minion2   Ready     15m
</span><span class='line'>centos-minion3   Ready     10m</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong>s três nodes criados e configurados anteriormente já são reconhecidos pelo nosso Kubernetes através do Master Controller. Além de registrados, estão com o status Ready, o que indica que estão prontos para funcionar e executar o que precisarmos.</p>

<p><em>Caso deseje conhecer mais parâmetros que a função <strong>get</strong> do kubectl possui, podemos invocar o manual desta função: $ man kubectl-get</em></p>

<p><strong>A</strong>lém do status, podemos conseguir diversas outras informações dos nodes através do <em>kubectl</em>: <em>(Ex: kubectl describe nodes)</em> Isto lhe daria informações sobre todos os nodes. Vamos experimentar com um node em específico.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# kubectl describe node centos-minion1
</span><span class='line'>Name:                   centos-minion1
</span><span class='line'>Role:
</span><span class='line'>Labels:                 beta.kubernetes.io/arch=amd64
</span><span class='line'>                        beta.kubernetes.io/os=linux
</span><span class='line'>                        kubernetes.io/hostname=centos-minion1
</span><span class='line'>Taints:                 &lt;none&gt;
</span><span class='line'>CreationTimestamp:      Tue, 20 Jun 2017 19:27:31 +0000
</span><span class='line'>Phase:
</span><span class='line'>Conditions:
</span><span class='line'>  Type                  Status  LastHeartbeatTime                       LastTransitionTime                      Reason     Message
</span><span class='line'>  ----                  ------  -----------------                       ------------------                      ------     -------
</span><span class='line'>  OutOfDisk             False   Sun, 25 Jun 2017 01:39:38 +0000         Fri, 23 Jun 2017 17:31:44 +0000         KubeletHasSufficientDisk    kubelet has sufficient disk space available
</span><span class='line'>  MemoryPressure        False   Sun, 25 Jun 2017 01:39:38 +0000         Tue, 20 Jun 2017 19:27:31 +0000         KubeletHasSufficientMemory  kubelet has sufficient memory available
</span><span class='line'>  DiskPressure          False   Sun, 25 Jun 2017 01:39:38 +0000         Tue, 20 Jun 2017 19:27:31 +0000         KubeletHasNoDiskPressure    kubelet has no disk pressure
</span><span class='line'>  Ready                 True    Sun, 25 Jun 2017 01:39:38 +0000         Fri, 23 Jun 2017 17:31:54 +0000         KubeletReady                        kubelet is posting ready status
</span><span class='line'>Addresses:              172.31.120.16,172.31.120.16,centos-minion1
</span><span class='line'>Capacity:
</span><span class='line'> alpha.kubernetes.io/nvidia-gpu:        0
</span><span class='line'> cpu:                                   1
</span><span class='line'> memory:                                1015348Ki
</span><span class='line'> pods:                                  110
</span><span class='line'>Allocatable:
</span><span class='line'> alpha.kubernetes.io/nvidia-gpu:        0
</span><span class='line'> cpu:                                   1
</span><span class='line'> memory:                                1015348Ki
</span><span class='line'> pods:                                  110
</span><span class='line'>System Info:
</span><span class='line'> Machine ID:                    f9afeb75a5a382dce8269887a67fbf58
</span><span class='line'> System UUID:                   EC2C8A0E-91D6-F54E-5A49-534A6A903FDA
</span><span class='line'> Boot ID:                       20961efd-c946-481a-97cb-7788209551ae
</span><span class='line'> Kernel Version:                3.10.0-327.28.2.el7.x86_64
</span><span class='line'> OS Image:                      CentOS Linux 7 (Core)
</span><span class='line'> Operating System:              linux
</span><span class='line'> Architecture:                  amd64
</span><span class='line'> Container Runtime Version:     docker://1.12.6
</span><span class='line'> Kubelet Version:               v1.5.2
</span><span class='line'> Kube-Proxy Version:            v1.5.2
</span><span class='line'>ExternalID:                     centos-minion1
</span><span class='line'>Non-terminated Pods:            (0 in total)
</span><span class='line'>  Namespace                     Name            CPU Requests    CPU Limits      Memory Requests Memory Limits
</span><span class='line'>  ---------                     ----            ------------    ----------      --------------- -------------
</span><span class='line'>Allocated resources:
</span><span class='line'>  (Total limits may be over 100 percent, i.e., overcommitted.
</span><span class='line'>  CPU Requests  CPU Limits      Memory Requests Memory Limits
</span><span class='line'>  ------------  ----------      --------------- -------------
</span><span class='line'>  0 (0%)        0 (0%)          0 (0%)          0 (0%)
</span><span class='line'>Events:
</span><span class='line'>  FirstSeen     LastSeen        Count   From                            SubObjectPath   Type            Reason             Message
</span><span class='line'>  ---------     --------        -----   ----                            -------------   --------        ------             -------
</span><span class='line'>  15m           15m             1       {kubelet centos-minion1}                        Normal          Starting           Starting kubelet.
</span><span class='line'>  15m           15m             1       {kubelet centos-minion1}                        Warning         ImageGCFailed      unable to find data for container /
</span><span class='line'>  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasSufficientDisk       Node centos-minion1 status is now: NodeHasSufficientDisk
</span><span class='line'>  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasSufficientMemory     Node centos-minion1 status is now: NodeHasSufficientMemory
</span><span class='line'>  15m           15m             2       {kubelet centos-minion1}                        Normal          NodeHasNoDiskPressure       Node centos-minion1 status is now: NodeHasNoDiskPressure
</span><span class='line'>  15m           15m             1       {kubelet centos-minion1}                        Warning         Rebooted           Node centos-minion1 has been rebooted, boot id: 20961efd-c946-481a-97cb-7788209551ae</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong>bviamente recebemos um retorno com muitas informações em formato Json, o que nem sempre é como esperamos. Existem formas de filtrar os resultados e conseguir informações mais precisas, como o bom e velho grep:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# kubectl describe node centos-minion1 | grep Addresses
</span><span class='line'>Addresses:              172.31.120.16,172.31.120.16,centos-minion1</span></code></pre></td></tr></table></div></figure>


<p><strong>V</strong>ocê também pode utilizar expressões regulares e a sintaxe do próprio Kubernetes para consultas mais complexas, como por exemplo, formatar a minha saída Json de forma a pegar apenas a listagem de status dos meus nodes que estão com Ready = True:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# kubectl get nodes -o jsonpath='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}'| tr ';' "\n" | grep "Ready=True"
</span><span class='line'>
</span><span class='line'>Ready=True
</span><span class='line'>Ready=True
</span><span class='line'>Ready=True</span></code></pre></td></tr></table></div></figure>


<p><strong>A</strong> sua criatividade é o limite. ;]</p>

<p><strong>N</strong>ão temos nenhum pod configurado, mas também poderíamos utilizar <em>kubectl get</em> para conseguir a listagem de nossos pods:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 ~]# kubectl get pods
</span><span class='line'>
</span><span class='line'>No resources found.</span></code></pre></td></tr></table></div></figure>


<h2>Criando pods</h2>

<p><strong>A</strong>ssim como com o Docker, Ansible e algumas outras ferramentas, utilizaremos a linguagem <a href="https://pt.wikipedia.org/wiki/YAML">YAML</a> para criar nossos arquivos de configuração.</p>

<p><strong>C</strong>riaremos um diretório chamado <em>Builds</em> em nosso Master Controller apenas para melhor organizar nossos arquivos de configuração e ficar mais fácil encontrá-los no futuro:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># mkdir Builds
</span><span class='line'>
</span><span class='line'># cd Builds</span></code></pre></td></tr></table></div></figure>


<p><strong>P</strong>ara criarmos Pods, o que fazemos na verdade é criar arquivos de configuração que vão dizer ao Kubernetes qual o estado em que desejamos nossa infraestrutura. O papel do Kubernetes é ler esta configuração e assegurar que o estado de nossa infraestrutura reflita o estado desejado.</p>

<p><strong>P</strong>ara facilitar, vamos utilizar exemplos encontrados na própria documentação do Kubernetes. Comecemos com a criação de um Pod para um servidor web Nginx.</p>

<p><strong>V</strong>amos criar um arquivo chamado nginx.yaml dentro do diretório Builds que criamos anteriormente:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># vim nginx.yaml</span></code></pre></td></tr></table></div></figure>


<p><strong>N</strong>o arquivo indicaremos alguns atributos ou variáveis, bem como seus respectivos valores:</p>

<ul>
<li>apiVersion &ndash; Indica a versão da API do kubernetes utilizada</li>
<li>kind &ndash; o tipo de recurso que desejamos</li>
<li>metadata &ndash; dados referentes ao recurso desejado</li>
<li>spec &ndash; especificações sobre o que este recurso irá conter</li>
</ul>


<p><strong>V</strong>amos criar um Pod contendo um único container rodando a versão 1.7.9 do nginx bem como disponibilizando a porta 80 para receber conexões. Este deverá ser o conteúdo do arquivo <em>nginx.yaml</em>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: nginx
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>    - name: nginx
</span><span class='line'>      image: nginx:1.7.9
</span><span class='line'>      ports:
</span><span class='line'>      - containerPort: 80</span></code></pre></td></tr></table></div></figure>


<p><strong>A</strong>ntes de executarmos, vamos nos certificar novamente de duas coisas:</p>

<ul>
<li>Que realmente não temos nenhum Pod criado e ativo;</li>
<li>Que não temos nenhum container rodando em nossos nodes.</li>
</ul>


<p><em>No centos-master:</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 Builds]# kubectl get pods
</span><span class='line'>
</span><span class='line'>No resources found.</span></code></pre></td></tr></table></div></figure>


<p><em>No centos-minion1: (Execute o mesmo comando nos demais nodes (centos-minion2 e centos-minion3))</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib2 ~]# docker ps
</span><span class='line'>
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span></code></pre></td></tr></table></div></figure>


<p><em>Novamente: Se você não faz ideia do que acabei de digitar, (docker ps) volte e leia um pouco sobre <a href="/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">Docker</a> antes de seguir com este artigo.</em></p>

<p><strong>C</strong>omo podemos ver, não temos nenhum Pod, bem como nenhum container rodando em nossos nodes.</p>

<p><strong>V</strong>amos utilizar <em>kubectl create</em> para criar o Pod utilizando o arquivo que criamos <em>nginx.yaml</em>: <em>Executaremos este comando no Master Controller &ndash; centos-master</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 Builds]# kubectl create -f nginx.yaml
</span><span class='line'>
</span><span class='line'>pod "nginx" created</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> Kubernetes está dizendo que nosso Pod &ldquo;nginx&rdquo; foi criado. Vamos verificar:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 Builds]# kubectl get pods
</span><span class='line'>
</span><span class='line'>NAME      READY     STATUS    RESTARTS   AGE
</span><span class='line'>nginx     1/1       Running   0          1m</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong> pod está criado e rodando. Agora, execute novamente <em>docker ps</em> nos 3 nodes para identificar em qual deles o container foi criado. Sim, como não especificamos nada, o Kubernetes vai verificar os recursos disponíveis no momento e vai lançar onde ele achar mais adequado.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib4 ~]# docker ps
</span><span class='line'>
</span><span class='line'>CONTAINER ID        IMAGE                                      COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>6de8e22e1536        nginx:1.7.9                                "nginx -g 'daemon off"   2 minutes ago       Up 2 minutes                            k8s_nginx.b0df00ef_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_583881e0
</span><span class='line'>ae49b36ae11b        gcr.io/google_containers/pause-amd64:3.0   "/pause"                 2 minutes ago       Up 2 minutes                            k8s_POD.b2390301_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_fb5c834f</span></code></pre></td></tr></table></div></figure>


<p><strong>S</strong>im, existem dois containers rodando. Um deles é o nosso &ldquo;nginx&rdquo;, enquanto que o outro é um container padrão do google chamado &ldquo;/pause&rdquo;, o qual será responsável pela manutenção de alguns recursos de nosso cluster.</p>

<p><strong>P</strong>odemos novamente pedir a descrição deste pod que acabamos de criar:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kalib1 Builds]# kubectl describe pod nginx
</span><span class='line'>
</span><span class='line'>Name:           nginx
</span><span class='line'>Namespace:      default
</span><span class='line'>Node:           centos-minion3/172.31.123.22
</span><span class='line'>Start Time:     Sun, 25 Jun 2017 02:20:18 +0000
</span><span class='line'>Labels:         &lt;none&gt;
</span><span class='line'>Status:         Running
</span><span class='line'>IP:             172.17.0.2
</span><span class='line'>Controllers:    &lt;none&gt;
</span><span class='line'>Containers:
</span><span class='line'>  nginx:
</span><span class='line'>    Container ID:               docker://6de8e22e153618271bb6e8095c68070126541331c8acfc3f5d1a654f4b978454
</span><span class='line'>    Image:                      nginx:1.7.9
</span><span class='line'>    Image ID:                   docker-pullable://docker.io/nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451
</span><span class='line'>    Port:                       80/TCP
</span><span class='line'>    State:                      Running
</span><span class='line'>      Started:                  Sun, 25 Jun 2017 02:20:27 +0000
</span><span class='line'>    Ready:                      True
</span><span class='line'>    Restart Count:              0
</span><span class='line'>    Volume Mounts:              &lt;none&gt;
</span><span class='line'>    Environment Variables:      &lt;none&gt;
</span><span class='line'>Conditions:
</span><span class='line'>  Type          Status
</span><span class='line'>  Initialized   True
</span><span class='line'>  Ready         True
</span><span class='line'>  PodScheduled  True
</span><span class='line'>No volumes.
</span><span class='line'>QoS Class:      BestEffort
</span><span class='line'>Tolerations:    &lt;none&gt;
</span><span class='line'>Events:
</span><span class='line'>  FirstSeen     LastSeen        Count   From                            SubObjectPath           Type            Reason     Message
</span><span class='line'>  ---------     --------        -----   ----                            -------------           --------        ------     -------
</span><span class='line'>  6m            6m              1       {default-scheduler }                                    Normal          Scheduled  Successfully assigned nginx to centos-minion3
</span><span class='line'>  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Pulling    pulling image "nginx:1.7.9"
</span><span class='line'>  6m            6m              2       {kubelet centos-minion3}                                Warning         MissingClusterDNS   kubelet does not have ClusterDNS IP configured and cannot create Pod using "ClusterFirst" policy. Falling back to DNSDefault policy.
</span><span class='line'>  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Pulled     Successfully pulled image "nginx:1.7.9"
</span><span class='line'>  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Created    Created container with docker id 6de8e22e1536; Security:[seccomp=unconfined]
</span><span class='line'>  6m            6m              1       {kubelet centos-minion3}        spec.containers{nginx}  Normal          Started    Started container with docker id 6de8e22e1536</span></code></pre></td></tr></table></div></figure>


<p><strong>O</strong>bviamente que isto é apenas a configuração mais básica que se possa imaginar, sem storage, mapeamentos de portas, redirecionamentos, rotas, etc. A ideia é apenas uma apresentação inicial..o que é o Kubernetes.</p>

<p><strong>H</strong>appy Hacking</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack/">Recebendo Alarmes Do AWS Diretamente No Slack</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2017-03-11T12:03:00-05:00" pubdate data-updated="true">Mar 11<span>th</span>, 2017</time>
        
         | <a href="/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img class="center" src="/imgs/aws_slack.png" title="'AWS_Slack'" ></p>

<p><strong>A</strong>ntes de entrar na configuração dos serviços, talvez seja necessário apresentar o <a href="http://www.slack.com">Slack</a>, visto que muitos ainda não conhecem ou utilizam esta poderosa e versátil ferramenta de comunicação instantânea para times.</p>

<p><strong>S</strong>lack é uma plataforma para comunicação entre times que desejam um ambiente mais dinâmico e ágil. Diferentemente de muitas plataformas de chat disponíveis, como o Google Hangouts, o Slack nos permite criar canais distintos com membros distintos de um mesmo time fazendo parte daquele canal específico. Não, não estou falando de chat em grupo, mas sim canais específicos que permitem integrações com serviços distintos, como receber notificações sobre commits feitos em um repositório ou branch específico no github, notificações de tickets abertos em ferramentas como o Jira, por exemplo, etc. O Slack é completamente programável e escalável, o que nos permite ter inúmeras funcionalidas.</p>

<p><strong>P</strong>rovavelmente não seja necessário apresentar o AWS, ou Amazon Web Services, visto que já está no mercado desde 2006, no entanto cabe um resumo para os que não estão familiarizados com o mesmo (embora o público alvo deste post seja quem já possui alguma familiaridade com AWS).</p>

<p><strong>A</strong>ws ou Amazon Web Services é uma plataforma de serviços em nuvem segura, oferecendo poder computacional, armazentamento de banco de dados, distribuição de conteúdo e outras funcionalidades.</p>

<p><strong>P</strong>or que eu deveria ter alarmes e notificações do AWS em um serviço de chat como o Slack quando já recebo estas notificações por email?</p>

<p><strong>É</strong> verdade que o uso mais comum para envio de alarmes e notificações do AWS costuma ser via email, no entanto fica fácil identificar alguns problemas com este método. O principal e mais recorrente que vejo é o caso de as notificações caírem em um email específico visto por poucas pessoas (na maioria das vezes) ou nem visto sequer, pois geralmente as pessoas ficam cansadas de olhar notificações e ter sua caixa de entrada entupida com eles portanto criam filtros que jogam os emails de notificação para um diretório que dificilmente será checado.</p>

<p><strong>O</strong>utro problema comum com esta prática é a demora até que alguém leia a notificação no meio de tantos outros na pasta ou filtro criado e, muitas vezes, quando se vê a notificação, o problema já está aguardando uma solução há horas.</p>

<p><strong>D</strong>eixando claro, não estou defendendo a ideia de abolir as notificações por email. Eu mesmo utilizo ambos, afinal o email continua bastante eficiente para fins de armazenamento e checagem histórica, por exemplo.</p>

<p><strong>U</strong>ma vez que nos dias atuais os times de TI estão cada vez mais unificados e dinâmicos, buscando incorporar uma mentalidade DevOps e Agile, a comunicação rápida e eficiente se torna um fator primordial para o sucesso de qualquer projeto. Ter um local centralizado para conversar com os demais membros do time, trocar arquivos, detalhes de projetos, receber notificações de commits, prazos, tickets, documentação e, por que não, notificações de monitoramento e alarmes, torna-se essencial.</p>

<p><strong>V</strong>amos então entender como funcionaria uma solução para enviar as notificações e alarmes do AWS para o Slack.</p>

<p><strong>O</strong> que utilizaremos:</p>

<ol>
<li>No Slack:

<ul>
<li>Um plugin ou Slack App chamado <strong>Incoming WebHooks</strong></li>
<li>O nome de um canal para envio das notificações</li>
</ul>
</li>
<li>No AWS:

<ul>
<li>Serviço <strong>SNS Topic</strong></li>
<li>Serviço <strong>CloudWatch</strong></li>
<li>Serviço <strong>Lambda Function</strong></li>
</ul>
</li>
</ol>


<p><strong>V</strong>amos lá&hellip;</p>

<p><strong>Slack</strong></p>

<p><strong>V</strong>amos começar escolhendo o canal no Slack no qual desejo receber a minha notificação ou alarme: #devops</p>

<p><em>Estou supondo que você já utiliza o Slack e já possui um time criado no mesmo. Caso ainda não, crie um time no Slack seguindo os passos descritos no <a href="https://slack.com/">site oficial</a> antes de seguir em frente&hellip; ;]</em></p>

<p><strong>O</strong> próximo passo é configurar a integração instalando o Plugin ou Slack App <strong>Incoming WebHooks</strong>. Para isto, acesse a página de apps de seu time no Slack: <a href="https://SEUTIME.slack.com/apps">https://SEUTIME.slack.com/apps</a></p>

<p><strong>P</strong>esquise por Incoming WebHooks e você terá apenas um resultado, portanto clique sem medo.</p>

<p><img class="center" src="/imgs/slack1.png" title="'Incoming WebHook'" ></p>

<p><strong>C</strong>lique no pequeno lápis que se encontrará no canto direito para editar as configurações do Incoming WebHook. Os únicos campos que precisaremos editar neste momento são os seguintes:
  * Post to Channel &ndash; Aqui indicarei o meu canal: #devops
  * Customize Name &ndash; Aqui indicarei um nome qualquer: AWS-Alerts</p>

<p><strong>Importante:</strong> Repare que nesta página de configurações ele lhe passará uma entrada ou URL com o código para o seu WebHook. Esta informação estará listada em <strong>Webhook URL</strong> e será algo como: *<a href="https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.">https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv*.</a> Copie esta informação em algum local de fácil acesso pois precisaremos desta URL para a configuração que faremos a seguir no AWS.</p>

<p><strong>S</strong>alve suas configurações e vamos configurar os serviços do AWS para que nosso WebHook possa receber as informações devidamente.</p>

<p><strong>Amazon Web Services</strong></p>

<p><strong>S</strong>e você já possui alguma familiaridade com o AWS, sabe que existem duas formas principais para administração e gerenciamento de nossos serviços: Pela interface web de gerenciamento (GUI) OU pela linha de comandos através da AWS CLI Tool que se comunica com a API do AWS. Este procedimento, assim como praticamente todos os outros, pode ser realizado por ambos os meios.</p>

<p><strong>S</strong>e você também gosta de automação, provavelmente prefere utilizar a CLI, no entanto irei listar aqui o procedimento em ambos os meios.</p>

<p><strong>Passo 1: Criando um SNS Topic para receber os alarmes</strong></p>

<p><strong>1.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço SNS;</li>
<li>Crie um novo SNS Topic:

<ul>
<li>No menu da lateral esquerda, clique em <strong>Topics</strong>;</li>
<li>Clique em <strong>Create new topic</strong>;</li>
<li>Preencha os campos <strong>Name</strong> (obrigatório) e <strong>Display Name</strong> (opcional) para o seu tópico. Para este exemplo utilizarei <em>aws-slack-alerts</em> como <strong>Name</strong> e <em>aws-slack</em> como <strong>Display Name</strong>; <em>(O Display Name só é necessário em caso de você também desejar enviar notificações por SMS)</em></li>
<li>Clique em <strong>Create Topic</strong></li>
</ul>
</li>
<li>Agora você já deve ser capaz de ver seu SNS Topic na lista.</li>
</ul>


<p><strong>1.2 &ndash; Pela AWS CLI Tool</strong></p>

<p><em>Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando a região na qual você deseja criar seu tópico e o nome desejado:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">aws</span> <span class="n">sns</span> <span class="n">create</span><span class="o">-</span><span class="n">topic</span>
</span><span class='line'>    <span class="o">--</span><span class="n">region</span> <span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="o">--</span><span class="n">name</span> <span class="n">aws</span><span class="o">-</span><span class="n">slack</span><span class="o">-</span><span class="n">alerts</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><strong>IMPORTANTE:</strong> Você receberá um identificador (TopicArn) para este alarme. Você precisará dele no passo seguinte.</li>
<li>Caso queira ter certeza, você pode listar seus tópicos utilizando:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">aws</span> <span class="n">sns</span> <span class="nb">list</span><span class="o">-</span><span class="n">topics</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Passo 2: Criando um Alarme no serviço CloudWatch</strong></p>

<p><strong>2.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>CloudWatch</strong>;</li>
<li>Crie um novo Alarme:

<ul>
<li>Clique em <strong>Alarms</strong>;</li>
<li>Clique no botão <strong>Create Alarm</strong>;</li>
<li>Escolha a categoria do alarme desejado. Para este exemplo utilizarei <strong>ELB Metric > Per-LB Metrics</strong> <em>(Dentre as várias categorias disponíveis, esta se refere à Load Balancers)</em>;</li>
<li>Selecione a métrica exata desejada. No caso deste exemplo, preciso selecionar a métrica e o Load Balancer desejado. Ao escolher a métrica e o alvo (em meu caso um Load Balancer) clique em <strong>Next</strong>. Neste exemplo eu escolhi a métrica <strong>HTTPCode_Backend_5XX</strong> <em>(para monitorar 500 errors)</em> e um Load Balancer chamado <strong>LB-GuySpyV3</strong>;</li>
<li>O próximo passo é definir um nome e uma descrição para este <strong>Alarme</strong>, bem como definir as triggers e períodos de monitoramento. Neste exemplo utilizei o nome <strong>LB-GuySpyV3-ELB_500</strong> para meu alarme; <em>(Não entrarei em detalhes quanto ao uso das triggers, visto que para cada tipo ou categoria de métrica, as triggers serão diferentes, bem como o cenário de seu ambiente e nível de criticidade. Em resumo, se você deseja monitorar o uso de CPU de um determinado servidor, a trigger seria o gatilho que ativaria o alarme, por exemplo: Só quero ser alarmado se o uso de CPU neste servidor ou instância for >= 90% e assim permanecer por pelo menos 60 segundos, ou por dois períodos seguidos de 60seg.)</em></li>
<li>Na seção <strong>Actions</strong> da configuração do Alarme defina o <strong>State</strong> e indique que a notificação deverá ser enviada <strong>(Send notification to)</strong> para o <strong>SNS Topic</strong> que criamos anteriormente. Para este exemplo optei por <strong>State is ALARM</strong> e decidi enviar as notificações para <strong>aws-slack-alerts</strong>, sendo este o SNS Topic que criei no início;</li>
<li>Finalize clicando em <strong>Create Alarm</strong>.</li>
</ul>
</li>
</ul>


<p>  <strong>2.2 &ndash; Pela AWS CLI Tool</strong></p>

<p>  <em>Novamente&hellip; Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a <a href="https://aws.amazon.com/pt/cli/?sc_channel=PS&amp;sc_campaign=acquisition_CA&amp;sc_publisher=google&amp;sc_medium=command_line_b&amp;sc_content=aws_cli_bmm&amp;sc_detail=%2Baws%20%2Bcli&amp;sc_category=command_line&amp;sc_segment=161196437429&amp;sc_matchtype=b&amp;sc_country=CA&amp;s_kwcid=AL!4422!3!161196437429!b!!g!!%2Baws%20%2Bcli&amp;ef_id=V8jOHQAABelSRAnr:20170311204146:s">documentação oficial</a> para isto.</em></p>

<ul>
<li>Pela CLI tool, digite o seguinte comando, indicando os atributos abaixo:

<ul>
<li><strong>region</strong> <em>(Região)</em>;</li>
<li><strong>alarm-name</strong> <em>(Nome do alarme)</em>;</li>
<li><strong>alarm-description</strong> <em>(Descrição do alarme)</em>;</li>
<li><strong>alarm-actions</strong> <em>(Definir a ação do alarme &ndash; Apontar para o TopicArn do SNS Topic que criamos anteriormente)</em>;</li>
<li><strong>metric-name</strong> <em>(Nome da Métrica desejada)</em>;</li>
<li><strong>namespace AWS/ELB &mdash;statistic</strong> <em>(Estatística desejada para aquela métrica, neste caso utilizarei Sum (Soma) ao invés de Average (Média))</em>;</li>
<li><strong>dimensions</strong> <em>(O alvo desta métrica de monitoramento, no nosso caso um Load Balancer)</em>;</li>
<li><strong>period</strong> e <strong>evaluation-periods</strong> <em>(Períodos desejados para a trigger)</em>;</li>
<li><strong>threshold</strong> <em>(O valor desejado: Neste exemplo estou colocando o valor como 1, portanto receberei o alarme caso seja >= 1. Sim, eu sei que receberei o alarme a cada minuto, mas estou fazendo isto de propósito para recebermos a notificação a fim de teste. Nunca utilize um threshold desses em produção. :p)</em>;</li>
<li><strong>comparison-operator</strong> <em>(Operador de comparação desejado, neste caso >=)</em>;</li>
</ul>
</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">aws</span> <span class="n">cloudwatch</span> <span class="n">put</span><span class="o">-</span><span class="n">metric</span><span class="o">-</span><span class="n">alarm</span> <span class="o">--</span><span class="n">region</span> <span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="o">--</span><span class="n">alarm</span><span class="o">-</span><span class="n">name</span> <span class="s">&quot;LB-GuySpyV3-ELB_500&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">alarm</span><span class="o">-</span><span class="n">description</span> <span class="s">&quot;Sends 500-errors to Slack&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">actions</span><span class="o">-</span><span class="n">enabled</span>
</span><span class='line'>    <span class="o">--</span><span class="n">alarm</span><span class="o">-</span><span class="n">actions</span> <span class="s">&quot;TheTopicArn from last step&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">metric</span><span class="o">-</span><span class="n">name</span> <span class="s">&quot;HTTPCode_Backend_5XX&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">namespace</span> <span class="n">AWS</span><span class="o">/</span><span class="n">ELB</span> <span class="o">--</span><span class="n">statistic</span> <span class="s">&quot;Sum&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">dimensions</span> <span class="s">&quot;Name=LoadBalancerName,Value=LB-GuySpyV3&quot;</span>
</span><span class='line'>    <span class="o">--</span><span class="n">period</span> <span class="mi">60</span>
</span><span class='line'>    <span class="o">--</span><span class="n">evaluation</span><span class="o">-</span><span class="n">periods</span> <span class="mi">60</span>
</span><span class='line'>    <span class="o">--</span><span class="n">threshold</span> <span class="mi">1</span>
</span><span class='line'>    <span class="o">--</span><span class="n">comparison</span><span class="o">-</span><span class="n">operator</span> <span class="s">&quot;GreaterThanOrEqualToThreshold&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>Passo 3: Criando uma Função Lambda como Assinante (Subscriber) do nosso SNS Topic</strong></p>

<p><strong>3.1 &ndash; Pela Interface Web de Gerenciamento (GUI)</strong></p>

<ul>
<li>A partir da Dashboard principal, clique ou busque pelo serviço <strong>Lambda</strong>;</li>
<li>Crie uma <strong>Nova Função Lambda</strong>:

<ul>
<li>Clique em <strong>Create a Lambda Function</strong>;</li>
<li>Na tela <strong>Select Blueprint</strong> clique na opção <strong>cloudwatch-alarm-to-slack</strong>; <em>(Você poderá precisar buscar por esta opção)</em></li>
<li>O próximo passo será a tela <strong>Configure Triggers</strong>. Selecione o <strong>SNS Topic</strong> que foi criado anteriormente (aws-slack-alerts neste exemplo) e marque a opção <strong>Enable Trigger</strong> e clique em Next;</li>
<li>Em <strong>Configure Function</strong> dê um Nome e uma Descrição para a função e escolha <strong>Node.js.4.3</strong> como <strong>Runtime</strong>;</li>
<li>No campo <strong>Lambda Function Code</strong> cole o seguinte código: <a href="https://gist.github.com/tomfa/b33f768908b0a83987d26f269e377e95">Disponível no github</a>

<ul>
<li>(Você deverá setar os valores das variáveis <strong>CHANNEL</strong> e <strong>PATH</strong>, onde CHANNEL é o canal do Slack para o qual você deseja mandar as notificações e PATH é a URL de seu WebHook, recebida quando configuramos o Incoming WebHook no Slack)</li>
</ul>
</li>
</ul>
</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">var</span> <span class="n">https</span> <span class="o">=</span> <span class="n">require</span><span class="p">(</span><span class="s">&#39;https&#39;</span><span class="p">);</span>
</span><span class='line'><span class="n">var</span> <span class="n">util</span> <span class="o">=</span> <span class="n">require</span><span class="p">(</span><span class="s">&#39;util&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">var</span> <span class="n">CHANNEL</span> <span class="o">=</span> <span class="s">&quot;#devops&quot;</span><span class="p">;</span>
</span><span class='line'><span class="n">var</span> <span class="n">PATH</span> <span class="o">=</span> <span class="s">&quot;/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv&quot;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="n">exports</span><span class="o">.</span><span class="n">handler</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">JSON</span><span class="o">.</span><span class="n">stringify</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">null</span><span class="p">,</span> <span class="mi">2</span><span class="p">));</span>
</span><span class='line'>    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;From SNS:&#39;</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">Records</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Sns</span><span class="o">.</span><span class="n">Message</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">postData</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>        <span class="s">&quot;channel&quot;</span><span class="p">:</span> <span class="n">CHANNEL</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;username&quot;</span><span class="p">:</span> <span class="s">&quot;AWS SNS&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;text&quot;</span><span class="p">:</span> <span class="s">&quot;*&quot;</span> <span class="o">+</span> <span class="n">event</span><span class="o">.</span><span class="n">Records</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Sns</span><span class="o">.</span><span class="n">Subject</span> <span class="o">+</span> <span class="s">&quot;*&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;icon_emoji&quot;</span><span class="p">:</span> <span class="s">&quot;:aws:&quot;</span>
</span><span class='line'>    <span class="p">};</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">message</span> <span class="o">=</span> <span class="n">event</span><span class="o">.</span><span class="n">Records</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Sns</span><span class="o">.</span><span class="n">Message</span><span class="p">;</span>
</span><span class='line'>    <span class="n">var</span> <span class="n">severity</span> <span class="o">=</span> <span class="s">&quot;good&quot;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">dangerMessages</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>        <span class="s">&quot; but with errors&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot; to RED&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;During an aborted deployment&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Failed to deploy application&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Failed to deploy configuration&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;has a dependent object&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;is not authorized to perform&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Pending to Degraded&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Stack deletion failed&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Unsuccessful command execution&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;You do not have permission&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Your quota allows for 0 more running instance&quot;</span><span class="p">];</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">warningMessages</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>        <span class="s">&quot; aborted operation.&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot; to YELLOW&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Adding instance &quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Degraded to Info&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Deleting SNS topic&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;is currently running under desired capacity&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Ok to Info&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Ok to Warning&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Pending Initialization&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Removed instance &quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="s">&quot;Rollback of environment&quot;</span>
</span><span class='line'>        <span class="p">];</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span><span class="p">(</span><span class="n">var</span> <span class="n">dangerMessagesItem</span> <span class="ow">in</span> <span class="n">dangerMessages</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">if</span> <span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">indexOf</span><span class="p">(</span><span class="n">dangerMessages</span><span class="p">[</span><span class="n">dangerMessagesItem</span><span class="p">])</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="n">severity</span> <span class="o">=</span> <span class="s">&quot;danger&quot;</span><span class="p">;</span>
</span><span class='line'>            <span class="k">break</span><span class="p">;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="o">//</span> <span class="n">Only</span> <span class="n">check</span> <span class="k">for</span> <span class="n">warning</span> <span class="n">messages</span> <span class="k">if</span> <span class="n">necessary</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="n">severity</span> <span class="o">==</span> <span class="s">&quot;good&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">for</span><span class="p">(</span><span class="n">var</span> <span class="n">warningMessagesItem</span> <span class="ow">in</span> <span class="n">warningMessages</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="k">if</span> <span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">indexOf</span><span class="p">(</span><span class="n">warningMessages</span><span class="p">[</span><span class="n">warningMessagesItem</span><span class="p">])</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>                <span class="n">severity</span> <span class="o">=</span> <span class="s">&quot;warning&quot;</span><span class="p">;</span>
</span><span class='line'>                <span class="k">break</span><span class="p">;</span>
</span><span class='line'>            <span class="p">}</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">postData</span><span class="o">.</span><span class="n">attachments</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>            <span class="s">&quot;color&quot;</span><span class="p">:</span> <span class="n">severity</span><span class="p">,</span>
</span><span class='line'>            <span class="s">&quot;text&quot;</span><span class="p">:</span> <span class="n">message</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">];</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">method</span><span class="p">:</span> <span class="s">&#39;POST&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="n">hostname</span><span class="p">:</span> <span class="s">&#39;hooks.slack.com&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="n">port</span><span class="p">:</span> <span class="mi">443</span><span class="p">,</span>
</span><span class='line'>        <span class="n">path</span><span class="p">:</span> <span class="n">PATH</span>
</span><span class='line'>    <span class="p">};</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">var</span> <span class="n">req</span> <span class="o">=</span> <span class="n">https</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="n">res</span><span class="o">.</span><span class="n">setEncoding</span><span class="p">(</span><span class="s">&#39;utf8&#39;</span><span class="p">);</span>
</span><span class='line'>      <span class="n">res</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="s">&#39;data&#39;</span><span class="p">,</span> <span class="n">function</span> <span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">context</span><span class="o">.</span><span class="n">done</span><span class="p">(</span><span class="n">null</span><span class="p">,</span> <span class="n">postData</span><span class="p">);</span>
</span><span class='line'>      <span class="p">});</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">req</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="s">&#39;error&#39;</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;problem with request: &#39;</span> <span class="o">+</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">);</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">req</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%j&quot;</span><span class="p">,</span> <span class="n">postData</span><span class="p">));</span>
</span><span class='line'>    <span class="n">req</span><span class="o">.</span><span class="n">end</span><span class="p">();</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>O <strong>Handler</strong> deverá ser o default <code>index.handler</code>;

<ul>
<li>Para <strong>role</strong> selecione <strong>Create a custom role</strong>; <em>(Isto será necessário apenas para a sua primeira função)</em></li>
<li>Na tela seguinte selecione <strong>lambda_basic_execution</strong> como <strong>IAM role</strong> e deixe o <strong>Policy Name</strong> com seu valor default. O AWS irá criar uma política de segurança padrão que nos dará os privilégios necessários. Clique em <strong>Allow</strong>;</li>
<li>Certifique-se de que o valor para <strong>VPC</strong> na seção <strong>Advanced Settings</strong> seja <strong>No VPC</strong>;
Clique em <strong>Next</strong>, reveja suas configurações e clique em <strong>Create Function</strong>;</li>
</ul>
</li>
<li>Aguarde seu alarme acontecer e receba a notificação no Slack. :D</li>
</ul>


<p>O resultado em seu Slack será algo assim&hellip;</p>

<p><img class="center" src="/imgs/slack2.png" title="'Notification_Slack'" ></p>

<p><strong>P</strong>arabéns, você já está recebendo suas notificações via Slack. Basta criar outros alarmes no AWS utilizando a mesma Lambda Function e o mesmo SNS Topic.</p>

<p><strong>H</strong>appy Hacking!</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Anteriores</a>
    
    <a href="/blog/archives">Arquivos do Blog</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1 align="left">Marcelo Cavalcante</h1>
  <p><img class="right" src="http://www.marcelocavalcante.net/imgs/kalib_picture_pq_circle_pq.png" title="'kalib'" ><p align=rght>Sysadmin dinâmico, escrupulosamente curioso, reservadamente convencional, multitarefa, command line heavy-user, estudante e pesquisador, surfista por prazer, leitor inquieto e apaixonado por vinhos.<br>Me conheça melhor <a href="http://blog.marcelocavalcante.net/about">clicando aqui</a>.</p></p>
</section><section>
  <h1>Posts Recentes</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2018/04/01/chef-aautomacao-e-gerenciamento-de-configuracao/">Chef: Automação e Gerenciamento de Configuração</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/06/24/conhecendo-o-kubernetes-clusters-de-containers/">Conhecendo o Kubernetes - Clusters de Containers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/03/11/recebendo-alarmes-do-aws-diretamente-no-slack/">Recebendo Alarmes do AWS Diretamente no Slack</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/20/docker-uma-alternativa-elegante-para-containers-no-linux/">Docker - Uma alternativa elegante para containers no Linux</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/08/03/assista-ao-documentario-sobre-aaron-swartz-o-menino-da-internet/">Assista ao documentário sobre Aaron Swartz: O menino da internet</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Estou lendo</h1>
  <img align="center" src="/imgs/livros/spiritprophecy.jpg">
</section>
<section>
  <h1> Eu apoio
</h1>
  <span>
    <a href='http://ansible.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/ansible.com.png'></a><a href='http://archlinux.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/archlinux.org.png'></a><a href='http://asterisk.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/asterisk.org.png'></a><a href='http://atom.io'><img style='padding: .5em; margin: .5em;' src='/images/stickers/atom.io.png'></a><a href='http://chef.io'><img style='padding: .5em; margin: .5em;' src='/images/stickers/chef.io.png'></a><a href='http://djangoproject.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/djangoproject.com.png'></a><a href='http://docker.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/docker.com.png'></a><a href='http://github.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/github.com.png'></a><img style='padding: .5em; margin: .5em;' src='/images/stickers/glider.png' ><a href='http://jenkins.io'><img style='padding: .5em; margin: .5em;' src='/images/stickers/jenkins.io.png'></a><a href='http://kde.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/kde.org.png'></a><a href='http://kubernetes.io'><img style='padding: .5em; margin: .5em;' src='/images/stickers/kubernetes.io.png'></a><a href='http://linux.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/linux.org.png'></a><a href='http://octopress.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/octopress.org.png'></a><a href='http://opensource.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/opensource.org.png'></a><a href='http://puppet.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/puppet.com.png'></a><a href='http://python.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/python.org.png'></a><a href='http://raspberrypi.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/raspberrypi.org.png'></a><a href='http://ruby-lang.org'><img style='padding: .5em; margin: .5em;' src='/images/stickers/ruby-lang.org.png'></a><a href='http://vagrantup.com'><img style='padding: .5em; margin: .5em;' src='/images/stickers/vagrantup.com.png'></a>
  </span>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2018 - Marcelo Cavalcante Rocha - Kalib -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'marcelocavalcante';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
